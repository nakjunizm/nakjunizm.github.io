{"meta":{"title":"nakjunizm's dev note","subtitle":"","description":"for my memory...","author":"NJ SUNG","url":"https://www.nakjunizm.com","root":"/"},"pages":[],"posts":[{"title":"minikube 에서 loadbalancer type의 service의 external ip가 pending 상태 일때","slug":"Minikube_ExternalIP_Pending","date":"2021-10-05T13:33:00.000Z","updated":"2021-10-07T13:47:52.230Z","comments":true,"path":"2021/10/05/Minikube_ExternalIP_Pending/","link":"","permalink":"https://www.nakjunizm.com/2021/10/05/Minikube_ExternalIP_Pending/","excerpt":"","text":"상황local (mac os)에 minikube으로 k8s 클러스터 구성해 놓고, nginx-ingress helm chart를 install 했으나 LoadBalncer type의 service의 EXTERNAL-IP 가 상태로 더이상 진행이 안됨. 1234🌈 ~/workspace/Charts$ kubectl get servicesNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.XXX.0.1 &lt;none&gt; 443/TCP 22hnakjunizm-front-nginx-ingress LoadBalancer 10.XXX.249.157 &lt;pending&gt; 80:32003/TCP,443:31274/TCP 46m 솔루션external ip를 제공하는 퍼블릭 클라우드 제공자 (AWS, Azure GCP등) 에서 kubernates를 서비스 형으로 사용 하는경우에는 문제가 되지 않으나 로컬에 minikube이나 kubeadm 등으로 설치 한 경우는 해당 현상이 발생 합니다.minikube의 경우 별도의 터미널을 더 열어서 minikube tunnel 명령어를 사용하면 LoadBalancer type의 서비스를 사용 가능 합니다. 새 터미널에서 터널 한 모습 123456789101112🌈 ~$ minikube tunnelPassword:Status: machine: minikube pid: 42342 route: 10.XXX.0.0/12 -&gt; 172.XXX.110.3 minikube: Running services: [nakjunizm-front-nginx-ingress] errors: minikube: no errors router: no errors loadbalancer emulator: no errors 터널 후 원래 터미널에서 로드밸런서 다시 확인 1234🌈 ~/workspace/Charts$ kubectl get servicesNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.XXX.0.1 &lt;none&gt; 443/TCP 22hnakjunizm-front-nginx-ingress LoadBalancer 10.XXX.249.157 10.XXX.249.157 80:32003/TCP,443:31274/TCP 60m 위와같이 EXTERNAL-IP 에 IP가 할당 된 것을 확인 할 수 있습니다. 2020-10-07 추가.위 내용은 (라이센스 문제 등으로) Docker desktop 이 아닌 minikube으로 설치한 경우에 해당 하며,LoadBalancer Type이 아닌 NodePort Type의 서비스도 터널을 해야 내 로컬호스트에서 접속 가능 합니다. 참조 https://stackoverflow.com/questions/44110876/kubernetes-service-external-ip-pending https://minikube.sigs.k8s.io/docs/handbook/accessing/#using-minikube-tunnel","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://www.nakjunizm.com/categories/DevOps/"},{"name":"Kubernetes","slug":"DevOps/Kubernetes","permalink":"https://www.nakjunizm.com/categories/DevOps/Kubernetes/"}],"tags":[{"name":"minikube","slug":"minikube","permalink":"https://www.nakjunizm.com/tags/minikube/"},{"name":"loadbalancer","slug":"loadbalancer","permalink":"https://www.nakjunizm.com/tags/loadbalancer/"}]},{"title":"오래된 (특정 기간 이상 된) 파일 찾아서 지우기 How to find old (aged more than specific days) files and remove","slug":"Find_Old_Files_And_Delete","date":"2020-06-17T12:37:00.000Z","updated":"2021-10-06T15:33:17.467Z","comments":true,"path":"2020/06/17/Find_Old_Files_And_Delete/","link":"","permalink":"https://www.nakjunizm.com/2020/06/17/Find_Old_Files_And_Delete/","excerpt":"","text":"특정 기간 이상 지난 파일 삭제 하기운영계는 보통 로그 보관 정책이 있고, 압축/백업 등이 자동화 되어 있으므로 특별히 신경 쓸 일이 없지만가끔 개발계나 검증계에서 디스크가 부족하여 로그파일등을 한꺼번에 지워야 하는 경우가 있습니다.매번 검색해서 지우곤 하는데 이것저것 해 보고 가장 편했던 방식을 기록용으로 적어 놓는 포스트 입니다. TL;DR현재 디렉토리에서 14일이 지난 파일을 일괄 삭제 하는 명령어 1find ./ -mtime +14 -type f | xargs rm ctime, mtime, atime리눅스에서 파일과 관련된 시간은 ctime mtime atime 이 있습니다. ctime: 마지막 변경 시간 (inode 관련 변경이 일어난 경우) mtime: 마지막으로 파일 내용이 변경된 시간 atime: 마지막으로 접근된 시간 (read 포함) 특정 기간 이상 지난 파일들 찾아내기find 명령어와 mtime 을 이용하면 원하는 폴더내에 특정 기간 이상 지난 파일들을 찾아낼수 있습니다. 1find /nakjunizm/mylogfile-path/ -mtime +7 /nakjunizm/mylogfile-path/ 안에 있는 7일 지난 파일들을 찾아내는 예 입니다. 찾아낸 파일 삭제하기찾아낸 파일을 삭제하기 위해서는 여러 방법이 있겠지만 가장 간단하게 사용 할 수 있는 xargs 를 이용해서 지워보겠습니다. 1find /nakjunizm/mylogfile-path/ -mtime +7 | xargs rm 이렇게 하면 파일/디렉토리 구분없이 find에 걸리게 됩니다. 어짜피 삭제를 rm 으로 했기 때문에 디렉토리는 삭제되지 않습니다만더 깔끔하게 아래와 같이 삭제 해 보겠습니다. 1find /nakjunizm/mylogfile-path/ -mtimt +7 -type f | xargs rm 그런데 이제 저는 log 로 끝나는 파일만 삭제 하고 싶어 졌습니다. 1find /nakjunizm/mylogfile-path/ -mtime +7 -type f -name &quot;*.log&quot; | xargs rm 이런식으로 find 와 mtime을 적절히 조합하면 원하는 파일을 일괄적으로 삭제 가능 합니다.","categories":[{"name":"Operations","slug":"Operations","permalink":"https://www.nakjunizm.com/categories/Operations/"},{"name":"Linux","slug":"Operations/Linux","permalink":"https://www.nakjunizm.com/categories/Operations/Linux/"}],"tags":[{"name":"find","slug":"find","permalink":"https://www.nakjunizm.com/tags/find/"},{"name":"mtime","slug":"mtime","permalink":"https://www.nakjunizm.com/tags/mtime/"}]},{"title":"주키퍼 오래된 스냅샷 및 트랜잭션 로그 삭제하기 zookeeper delete old snapshot and transactional log","slug":"Zookeeper_Cleanup_Transactional_Log","date":"2020-05-19T12:14:00.000Z","updated":"2021-10-06T15:33:17.491Z","comments":true,"path":"2020/05/19/Zookeeper_Cleanup_Transactional_Log/","link":"","permalink":"https://www.nakjunizm.com/2020/05/19/Zookeeper_Cleanup_Transactional_Log/","excerpt":"","text":"Ongoing Data Directory CleanupZookeeper data directory에는 znode들의 복사데이터드이 특정한 형식으로 쌓여 있습니다. 이것들은 스냅샷(snapshot) 과 트랜잭션로그(transactional log) 라고 부르는데 znode들에 변화가 생길 때 마다 Zookeeper는 이 변화된 내용을 스냅샷과 트랜잭션 로그에 추가(append) 합니다.스냅샷과 트랜잭션 로그의 크기가 점점 커지면 현재 상태의 znode값으로 새로운 스냅샷과 트랜잭션 로그 파일이 생성 됩니다.스냅샷이 생성되는 동안 들어오는 값의 변화에 대해서는 이전 로그 파일에 그대로 추가 합니다. 이러한 이유로 어떤 트랜잭션은 새로생긴 스냅샷보다 더 오래된 예전 스냅샷에 최신 정보가 있을 수 도 있습니다. 특별한 설정을 하지 않았으면 Zookeeper를 사용한다고 있다면 오래된 스냅샷과 트랜잭션 로그 파일들을 삭제 하지 않습니다.ZooKeeper document를 읽어 보면 오래된 파일을 삭제하는것을 운영자의 책임이라고 명시하고 있습니다.PurgeTxnLog 라는 클래스를 제공해 주고 있고, 운영자는 어느 시점에는 반드시 이 클래스를 이용해서 오래된 스냅샷과 트랜잭션 로그 파일을 지워야 할 때가 옵니다. (snapRetainCount와 autopurge 를 별도로 설정하지 않은 경우) zookeeper 공식 도큐먼트에 나와있는 방식은 아래와 같고,각각의 환경에 맞게 zookeeper, slf4j, slf4j-log4jl2, log4j 라이브러리 버전 및 패스를 맞춰주면 무리 없이 돌아 갑니다. 1java -cp zookeeper.jar:lib/slf4j-api-1.7.5.jar:lib/slf4j-log4j12-1.7.5.jar:lib/log4j-1.2.17.jar:conf org.apache.zookeeper.server.PurgeTxnLog &lt;dataDir&gt; &lt;snapDir&gt; -n &lt;count&gt; 저는 제 환경(zookeeper-3.4.6)에서 3개만 남겨놓고 모두 삭제해 봤습니다. 1java -cp /nakjunizm/platform/zookeeper/zookeeper-3.4.6.jar:/nakjunizm/platform/zookeeper/lib/slf4j-api-1.6.1.jar:/nakjunizm/platform/zookeeper/lib/slf4j-log4j12-1.6.1.jar:/nakjunizm/platform/zookeeper/lib/log4j-1.2.16.jar:/nakjunizm/platform/zookeeper/conf org.apache.zookeeper.server.PurgeTxnLog /data/zookeeper /data/zookeeper -n 3 ** ZooKeeper 클러스터 중 한개 노드에서 실행 하면 모든 노드가 다 적용 될 것 처럼 생각 될 수 있는데 않습니다. 직접 실행 해 보니 명령어를 실행 한 노드에만 유효 합니다. ** 자동으로 삭제할순 없을까?3.4.0 이상에서는 이 과정을 자동으로 할 수 있게 autupurge.snapRetainCount 와 autopurge.purgeInterval 이라는 옵션을 제공해 줍니다. autopurge.snapRetainCount : (No Java system property) 가지고 있을 스냅샷과 트랜잭션로그의 갯수. 디폴트3, 최소3 autopurge.purgeInterval : (No Java system property) purge 할 시간. 디폴트0. 1 이상의 양의정수로 설정 할 경우 해당 숫자의 시간 단위로 실행. 제 zoo.cfg 파일에 24시간 마다 purge하고 마지막 세개의 스냅샷만 남기도록 해당 설정을 넣어 봤습니다. 12autopurge.snapRetainCount=3autopurge.purgeInterval=24 ** 재기동을 하지 않으면 해당 설정은 적용되지 않습니다. ** Referencehttps://zookeeper.apache.org/doc/r3.6.0/zookeeperAdmin.html","categories":[{"name":"Operations","slug":"Operations","permalink":"https://www.nakjunizm.com/categories/Operations/"},{"name":"Zookeeper","slug":"Operations/Zookeeper","permalink":"https://www.nakjunizm.com/categories/Operations/Zookeeper/"}],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://www.nakjunizm.com/tags/zookeeper/"},{"name":"autopurge","slug":"autopurge","permalink":"https://www.nakjunizm.com/tags/autopurge/"},{"name":"snapRetain","slug":"snapRetain","permalink":"https://www.nakjunizm.com/tags/snapRetain/"}]},{"title":"레디스 모니터링 시 주의사항 (Redis monitoring/single thread)","slug":"Redis_Monitoring","date":"2020-03-24T13:14:00.000Z","updated":"2021-10-06T15:33:17.460Z","comments":true,"path":"2020/03/24/Redis_Monitoring/","link":"","permalink":"https://www.nakjunizm.com/2020/03/24/Redis_Monitoring/","excerpt":"","text":"TL;DRRedis는 싱글 쓰레드로 동작 하므로 CPU 모니터링을 할때 redis 프로세스를 따로 모니터링 해 줘야 합니다. 그렇지 않으면 redis의 cpu가 100을 치고 hang 걸린 상황에서 전체 코어 중 하나의 코어만 다 쓰는 상황이라 알람이 발생 하지 않을 수 있습니다. CPU 사용량 모니터링대부분의 사이트에서는 zabbix 나 prometheus 혹은 ELK stack 등의 오픈소스를 활용하던지 혹은 자체적으로 개발한 툴을 이용하던지 어떤 식으로든 안정적인 서비스를 위해 인프라와 어플리케이션을 모니터링 하고 임계치를 설정하여 알람을 받고 있을 것 입니다. 이때 가장 기본적으로 모니터링 하는 것중 하나가 CPU Usage 인데 보통은 CPU user time + system time + iowait time 더한 값을 usage로 보고 각 운영 환경에 맞는 임계치를 두고 알람을 받습니다.70% 이상 warning, 90% 이상 high, 100% critical 등의 기준을 잡고 10분간 3회 이상 연속으로 발생시 알람을 발생 시키는 트리거를 예로 들 수 있겠네요. Redis가 올라가 있는 인프라 (VM 혹은 서버) 의 CPU 모니터링 할 때 주의 할점redis 홈페이지에 올라와 있는 벤치마크관련 포스트 를 보면 아래와 같이 나와 있습니다. Redis is, mostly, a single-threaded server from the POV of commands execution (actually modern versions of Redis use threads for different things). It is not designed to benefit from multiple CPU cores. People are supposed to launch several Redis instances to scale out on several cores if needed. It is not really fair to compare one single Redis instance to a multi-threaded data store. Redis는 ** 싱글 쓰레드로 동작 ** 하고 멀리 코어의 이득을 볼 수 있게 설계 되어 있지 않다고 쓰여 있는데 이게 굉장히 중요 합니다.요즘 운영서버에 올리는 VM들은 못해도 4core 이상은 될 것인데(서버를 직접 사서 베어메탈 장비를 그대로 데이터 센터에 놓고 쓰고 싶다면 8core 이하는 주문하기도 거의 불가능 합니다.)예를 들어서 redis를 4 vcore vm에 올렸다고 가정 해 보겠습니다. redis에 엄청난 부하가 몰려서 cpu를 100% 다 쓰는 상황이 발생 합니다. 모니터링 시스템에는 cpu usage가 70% 이상일 때만 알람을 받게 설정 되어 있습니다. redis는 싱글 쓰레드로 동작 하기 때문에 한개의 core만 100% 점유하고 있습니다. 같은 서버에 올라가 있는 나머지 시스템들의 CPU 사용량이 미미하다면 CPU usage는 25% 정도로 높지 않습니다. (전체의 1/4) 위와 같은 상황이 발생하면 redis에서 응답을 늦게 주거나 아예 튕겨 내게 될 것이고 이로 인해 서비스 장애로 이어질 수 있습니다.CPU는 크게 높지 않기 때문에 네트워크나 OS, host 머신 등 다른 부분들은 점검하느라 시간을 허비 할 확률이 큽니다. 이런 경우를 방지하기 위해서 Redis의 프로세스만 따로 모니터링 해 주는게 중요 합니다. zabbix 의 경우 Item Key를 다음과 같이 설정하면 모니터링 가능 1proc.cpu.util[,계정,,redis-server] shell을 이용하는 경우 (bash shell 전문가님들은 분명 더 좋은 방법이 있겠지만 저는 아래와 같이 테스트 해 봤습니다) 1top -n 1 -p $(pidof redis-server) | sed -n &#x27;8,9p&#x27; | awk &#x27;&#123;print $9&#125;&#x27;","categories":[{"name":"Operations","slug":"Operations","permalink":"https://www.nakjunizm.com/categories/Operations/"},{"name":"Redis","slug":"Operations/Redis","permalink":"https://www.nakjunizm.com/categories/Operations/Redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://www.nakjunizm.com/tags/redis/"},{"name":"monitoring","slug":"monitoring","permalink":"https://www.nakjunizm.com/tags/monitoring/"},{"name":"zabbix","slug":"zabbix","permalink":"https://www.nakjunizm.com/tags/zabbix/"}]},{"title":"haproxy & keepalived 로 프록시 구축하기","slug":"haproxy","date":"2020-02-20T12:41:00.000Z","updated":"2021-10-06T15:33:17.456Z","comments":true,"path":"2020/02/20/haproxy/","link":"","permalink":"https://www.nakjunizm.com/2020/02/20/haproxy/","excerpt":"","text":"overviewVM 두대(이상)에 haproxy를 설치하여 L4(또는 L7) switch 장비를 대체 할 수 있도록 하는게 목표 입니다. haproxy간의 HA(High availability)는 keepalived를 사용하여 VIP를 넘기는 식으로 구성 합니다.사실 지금 L7을 사용하고 있는데 이렇게 하려는 이유는 다음과 같습니다. LoadBalancer를 사용할 수는 있는 환경 이지만 내가 컨트롤 할 수 없는 상황 (네트워크 부서에서 담담). 검증계에서 이것저것 구성하려고 해도 L7 관련 설정은 SR(Service Request) 티켓을 만들어야 하고, 최소 일주일 전에는 SR을 올려야 내가 원하는 기간에 맞춰서 설정을 바꿀 수 있음. 구성할 모습(TO-BE)평상시에는 위 그림과 같이 stg1에 VIP 12.34.56.129 이 붙어 있고 리퀘스트가 들어오면 stg1의 haproxy를 통해 stg1과 stg2로 밸런싱 됩니다.그러다가 stg1이 다운되면 아래 그림과 같이 VIP가 stg2로 옮겨 가게 되고, stg2 -&gt; stg2로만 리퀘스트를 보내다가 stg1이 다시 살아 나면 stg1로도 리퀘스트를 나눠 줍니다.테스트 목적의 검증계의 구성이라서 이렇게 열악하게 구성 되었지만, haproxy 두대를 별도로 구성하고 밑에 로드밸런싱 되는 서버들을 여러대 붙이는게 일반적인 구성입니다. 준비사항haproxy와 keepalived를 설치할 VM 2대 (yum repository 사용 가능한)floating ip로 사용할 VIP 1개 haproxy 설치123install haproxysudo yum install haproxy haproxy.cfg 수정 12sudo cp /etc/haproxy/haproxy.cfg /etc/haproxy/haproxy.cfg.templatesudo vi /etc/haproxy/haproxy.cfg 123456789101112131415161718192021222324252627282930313233defaults mode http log global option httplog option dontlognull option http-server-close option forwardfor except 127.0.0.0/8 option redispatch retries 3 timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout http-keep-alive 10s timeout check 10s maxconn 3000frontend main bind 12.34.56.119:80 mode http default_backend test-internal-proxybackend test-internal-proxy # health check option httpchk GET / http-check expect status 200 default-server inter 1s fall 3 rise 2 # load balancing balance source mode http server stg1 12.34.56.205 check server stg2 12.34.56.206 check balance option(algorithm) 에 대해 간략하게 정리 했습니다. (자세한 내용은 https://cbonte.github.io/haproxy-dconv/1.7/configuration.html#4-balance 참조) roundrobin: 우리가 잘 알고있는 ‘그’ roundrobin 방식과 동일. 순서대로 돌려주는 방식 입니다. static-rr: weight 에 따라 분배해 주는 방식 입니다. weight가 높은 서버로 더 많은 리퀘스트를 돌려줍니다. leastconn: connection이 제일 적은 서버에 돌려주는 방식 입니다. first: 서버 id 순서대로 돌려주는데, 앞에 서버가 차면 그 다음 서버로 돌려주는 방식 입니다. soucre: IP hash 값을 서버 댓수로 나눈 값에 따라 돌려주는 방식 입니다. uri: uri hash값을 총 서버 댓수로 나눈 값에 따라 돌려주는 방식 입니다. url_param: url의 쿼리스트링의 hash 값을 총 서버 댓수로 나눈 값에 따라 돌려주는 방식 입니다. hdr(): http header의 name 값을 보고 돌려주는데 name이 header에 없으면 rr로 돌려 줍니다.. rdp-cookie(): TCP 리퀘스트의 hash 값을 보고 돌려줌. equivalent ACL ‘reqrdpcookie()’ function. cookie가 없으면 rr로 돌려 줍니다. haproxy logging 설정기본적으로 haproxy 설정을 보면 아래와 같이 log를 127.0.0.1 로 보내고 있는것을 확인 할 수 있습니다.이렇게 보내면 rsyslog로 보내는 것 이지만, rsyslog에는 관련해서 아무런 설정을 하지 않았기 때문에 로깅이 당연히 안됩니다. 12global log 127.0.0.1 local2 /etc/rsyslog.conf 수정haproxy는 로그를 UDP로 보내주기 때문에 rsyslog에서 udp를 처리 할 수 있도록 아래 두 가지 옵션의 주석을 해제 합니다 1sudo vi /etc/rsyslog.conf 12$ModLoad imudp$UDPServerRun 514 /etc/rsyslog.d/haproxy.conf 파일 생성rsyslog에 udp 를 받을 수 있게 처리를 해 줬으니 실제로 haproxy 로그에 대한 설정 파일을 만들어 줍니다. 1sudo vi /etc/rsyslog.d/haproxy.conf 1local2.* /nakjunizm/data/logs/util/haproxy/haproxy.log 추가로 /nakjunizm/data/logs/util/haproxy 디렉토리 없으면 미리 생성. (mkdir -p /nakjunizm/data/logs/util/haproxy) rsyslog 재시작1sudo systemctl restart rsyslog sysctl 설정keepalived를 이용해서 floating ip를 옮겨다니게 하기 위해 아래 두가지 설정이 필요 합니다.net.ipv4.ip_forward 는 NIC 간의 forwarding 을 허용 해 주는 옵션으로, 예를들어 eth0으로 들어온 리퀘스트를 eth1로 포워딩 시킬때 필요 합니다.eth0에 VIP를 추가로 bind 시키는 경우에는 위 옵션을 1로 수정할 필요가 없고, 다른 NIC에 VIP를 붙이는 경우엔 필요한 것으로 생각 됩니다.net.ipv4.ip_nonlocal_bind 는 network interface에 할당되지 않은 IP를 bind 할수 있게 allow 하는 옵션으로, 우리는 VIP를 bind 할것이기 때문에 1로 설정하여 enable 시킬 것 입니다. 1sudo vi /etc/sysctl.conf 12net.ipv4.ip_forward = 1net.ipv4.ip_nonlocal_bind = 1 변경 사항 저장1sudo sysctl -p keepalived 설치install keepalived1sudo yum install keepalived keepalived 설정 변경MASTER 설정 변경 (stg1 서버)12sudo cp /etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf.templatevi /etc/keepalived/keepalived.conf 1234567891011121314151617181920! Configuration File for keepalivedglobal_defs &#123; router_id LVS_DEVEL&#125;vrrp_instance VI_1 &#123; state MASTER interface eth0 virtual_router_id 51 priority 200 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 12.34.56.119 &#125;&#125; BACKUP 설정 변경 (stg2 서버)BACKUP은 priority가 MASTER 보다 낮게 설정되어야 합니다. 12sudo cp /etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf.templatevi /etc/keepalived/keepalived.conf 1234567891011121314151617181920! Configuration File for keepalivedglobal_defs &#123; router_id LVS_DEVEL&#125;vrrp_instance VI_1 &#123; state BACKUP interface eth0 virtual_router_id 51 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 12.34.56.119 &#125;&#125; 실행keepalived 실행1sudo systemctl start keepalived keepalived를 양쪽에서 실행 하고 나서 ip a 이나 ifconfig 로 확인해보면 MASTER로 설정한 서버의 eth0에 vip가 추가로 붙어있는것을 확인 할 수 있습니다. MASTER 에서 ip a 한 결과12342: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP qlen 1000 link/ether 00:11:22:33:cc:dd brd ff:ff:ff:ff:ff:ff inet 12.34.56.205/24 brd 12.30.97.255 scope global eth0 inet 12.34.56.119/32 scope global eth0 BACKUP 에서 ip a 한 결과1232: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP qlen 1000 link/ether 00:11:22:33:ee:ff brd ff:ff:ff:ff:ff:ff inet 12.34.56.206/24 brd 12.30.97.255 scope global eth0 haproxy 실행1sudo systemctl start haproxy Referencespacemaker가 아닌 keepalived로 ha를 구성한 이유 https://www.quora.com/Which-is-a-better-Linux-ip-failover-tool-keepalived-or-heartbeat-pacemaker http://www.formilux.org/archives/haproxy/1003/3259.html haproxy 전체적인 개념 및 설치 https://d2.naver.com/helloworld/284659 https://www.serverlab.ca/tutorials/linux/network-services/deploying-an-haproxy-load-balancer-on-centos-6/ haproxy logging https://www.percona.com/blog/2014/10/03/haproxy-give-me-some-logs-on-centos-6-5/ keepalived 개념 설명 https://docs.oracle.com/cd/E3767001/E41138/html/sectionuxglzhnr.html ipforward &amp; nonlocalbind https://unix.stackexchange.com/questions/14056/what-is-kernel-ip-forwarding https://itsthe.network/post/tcp-nonlocal-bind-linux-kernel-settings/ 기타 참조 사이트 https://www.gslee.info/44 https://5log.tistory.com/226 https://cbonte.github.io/haproxy-dconv/configuration-1.5.html#balance http://www.keepalived.org/","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://www.nakjunizm.com/categories/DevOps/"},{"name":"LoadBalancing","slug":"DevOps/LoadBalancing","permalink":"https://www.nakjunizm.com/categories/DevOps/LoadBalancing/"}],"tags":[{"name":"haproxy","slug":"haproxy","permalink":"https://www.nakjunizm.com/tags/haproxy/"},{"name":"keepalived","slug":"keepalived","permalink":"https://www.nakjunizm.com/tags/keepalived/"}]},{"title":"사이더(CIDR) 란 무엇인가?","slug":"Cidr","date":"2020-01-29T13:15:00.000Z","updated":"2021-10-06T15:33:17.415Z","comments":true,"path":"2020/01/29/Cidr/","link":"","permalink":"https://www.nakjunizm.com/2020/01/29/Cidr/","excerpt":"","text":"CIDR?AWS, GCP, Azure 등 퍼블릭 클라우드 등을 사용할 때 네트워크 설정에서 VPC 및 Subnet 을 생성하여 네트워크를 구성하게 됩니다. 이 때 CIDR(Classless Inter-Domain Routing) 블록을 이용하여 10.10.1.0/24 등과 같이 표시하게 되는데 주니어 개발자 꼬꼬마 시절에는 AWS 콘솔에서 네트워크, 시큐리티그룹 등에서 많이 봐 왔지만 선배들이 알려준 대로 그냥 C클래스일때는 /24, 특정IP만 지정할때는 /32 로 알고 살아왔었고, 아직도 그렇게 알고 있는 사람들이 분명히 있을 것 같아서 간단하지만 정확하게! 포스트를 작성 해 보려 합니다. 참고로 CIDR는 사이더 라고 읽으면 되고, 유툽에서 미국인 개발자가 발음하는걸 들어보니 싸이더 정도로 발음 합니다. 사이더(Classless Inter-Domain Routing, CIDR)는 클래스 없는 도메인 간 라우팅 기법으로 1993년 도입되기 시작한, 최신의 IP 주소 할당 방법이다. 사이더는 기존의 IP 주소 할당 방식이었던 네트워크 클래스를 대체하였다. 사이더는 IP 주소의 영역을 여러 네트워크 영역으로 나눌 때 기존방식에 비해 유연성을 더해준다. 특히 다음과 같은 장점이 있다. 급격히 부족해지는 IPv4 주소를 보다 효율적으로 사용하게 해준다. 접두어를 이용한 주소 지정 방식을 가지는 계층적 구조를 사용함으로써 인터넷 광역 라우팅의 부담을 줄여준다. - 위키백과 사이더 정의 재밌는 사실은 위의 위키백과 정의와 같이 CIDR는 네트워크 클래스를 대체 하였습니다. 선배들이 이야기 해 줬던 C클래스일때는 /24 는 엄밀히 말하면 틀린것 인데 계산해 보면 사실 C클래스와 일치 하긴 합니다. 아마도 CIDR를 자세히 설명하기 어려웠거나 귀찮았던 것이겠죠. 잡설은 그만하고 바로 CIDR를 계산하는 방법으로 넘어가겠습니다. CIDR block10.10.1.32 라는 IPv4 의 IP를 8비트의 2진수 4그룹 (= 32비트)으로 표현 해 보겠습니다. 100001010.00001010.00000001.00100000 10.10.1.44 라는 IPv4 의 IP를 8비트의 2진수 4그룹 (= 32비트)으로 표현 해 보겠습니다. 100001010.00001010.00000001.00101100 위에서 예로 들은 각각의 IP는 10.10.1.0/24 사이더 블록에 포함 된다는건 기존에도 알고 있었습니다. 그렇지만 왜? /24 블록에 포함 되는것인지 몰랐을 뿐 이죠. 사실은 정말 간단 합니다. ** 사이더의 접두어의 길이라고 불리우는 /16 /24 /32 는 위의 32비트 IP의 각 자릿수를 나타내는 것입니다. ** 앞에서부터 24번째까지 쭉 따라 오면 100001010.00001010.00000001 까지가 /24 입니다. 즉 그 뒤의 8비트 (구 D클래스)는 00000000 ~ 11111111 까지 256개 즉 2^8개의 IP 를 가질 수 있는 것 입니다. 그래서 /24가 C클래스와 동일하다는 얘기가 틀리지만 맞는? 말인것 입니다. 위키백과 정의에서 ** 기존 방식에 비해 유연성을 더해준다 ** 고 했으니 (구)B 클래스, C클래스 처럼 딱딱 떨어지는 /16, /24 말고 10.10.1.40/29 등과같은 사이더 블록의 경우 어떨까요?산수와 눈치가 빠른 사람은 10.10.1.32이 사이더의 접두어인 10.10.1.40 보다 더 작은 숫자이므로 10.10.1.32는 10.10.1.40/29 사이더블록에 속하지 않을것이라고 생각 했을 겁니다. 하지만 저는 산수에 약하고 눈치도 느리므로 직접 그려 보겠습니다. 맨 위의 빨간색이 10.10.1.40 을 8비트의 2진수 4그룹으로 표시한 것이고 밑에 두개는 각각 위에서 예로 들었던 10.10.1.32, 10.10.1.44 입니다. ** 사이더의 접두어 ** 인 10.10.1.40 의 ** 접두어의 길이 ** 인 /29 까지, 즉 처음부터 29번째 비트까지 동일하면 사이더그룹에 포함되는 IP 입니다. 10.10.1.32는 접두어와 28번째까지는 동일하지만 29번째가 0이기 때문에 포함되지 않습니다. 10.10.1.44는 29번째 까지 동일하므로 사이더 그룹에 포함 되는것 입니다.정리하면, 10.10.1.40/29의 사이더 그룹에 포함되는 IP는 123400001010.00001010.00000001.0010100010.10.1.40 부터00001010.00001010.00000001.0010111110.10.1.47 까지 2^3 = 8개 입니다. Subnet의 IP Range위의 내용을 바탕으로 하면 서브넷을 생성 할 때 해당 서브넷에 몇개의 IP를 가질 수 있는지 쉽게 계산할 수 있습니다.2^(32-CIDR접두어의길이) 가 IP의 갯수가 됩니다.서브넷을 생성할 때는 사설 IP 주소 범위와 같은 주의할 점들이 몇가지 있는데 이건 다음에 따로 포스트를 작성 해 보도록 하겠습니다. 복잡한 부분은 저도 잘 모르기 때문에 다 빼고 실질적으로 사이더 그룹에 포함되는지 계산하는 방법 위주로 정리 해 봤는데 도움이 되었으면 좋겠네요!","categories":[{"name":"Operations","slug":"Operations","permalink":"https://www.nakjunizm.com/categories/Operations/"},{"name":"Cloud","slug":"Operations/Cloud","permalink":"https://www.nakjunizm.com/categories/Operations/Cloud/"}],"tags":[{"name":"CIDR","slug":"CIDR","permalink":"https://www.nakjunizm.com/tags/CIDR/"},{"name":"Subnet","slug":"Subnet","permalink":"https://www.nakjunizm.com/tags/Subnet/"}]},{"title":"도커 스웜의 미래 (The Future of Docker Swarm)","slug":"The_Future_Of_Docker_Swarm","date":"2020-01-08T12:45:00.000Z","updated":"2021-10-06T15:33:17.483Z","comments":true,"path":"2020/01/08/The_Future_Of_Docker_Swarm/","link":"","permalink":"https://www.nakjunizm.com/2020/01/08/The_Future_Of_Docker_Swarm/","excerpt":"","text":"원작자인 Bret Fisher에게 허락을 받고 번역/포스팅 함을 밝힙니다. 의역을 많이 해서 오역이 있을수 있습니다. 제 의견은 역주: 로 표시 하였습니다. 원문 링크 : https://www.bretfisher.com/the-future-of-docker-swarm/ 도커 스웜의 미래 (The Future of Docker Swarm)지금은 2018년 10월입니다. 저는 도커 스웜의 팬 입니다. 저는 스웜을 사용하고, 저의 고객들도 스웜을 사용 합니다. 저는 심지어 스웜에 대한 ** 세계 최고의 온라강좌 ** 그리고 ** 리얼월드 코스 ** 도 만들었습니다.이 글에서는 스웜의 과거와 현재 그리고 미래에 대해 포괄적으로 리뷰 하였습니다. 다섯달 전 쯤에 제가 쓴 ** “2018년도, 스웜은 죽었을까?”(It’s 2018, Is Swarm Dead?)** 를 봤을지는 모르겠지만,그 글에서 저는 “도커가 쿠버네티스를 스웜으로 대체할 것이다” 라는 [틀린] 추측을 했습니다. 실제로는 도커에서 쿠버네티스를 도커의 growing list에 오케스트레이터로 ** 추가 ** 했습니다. ** 2019 업데이트 **: 도커는 도커콘2018 유럽과 도커콘 2019에서 스웜의 미래에 대해 다시한번 확인시켜 줬습니다. 1. 새로운 스웜의 기능들, 2. 도커의 700+ 스웜을 사용하는 고객들의 규모, 3. 스웜팀은 현재 구인중, 4. 작년동안 본 모든 리포트에서 스웜의 사용이 늘어나고 있다고 함 이제 ** 도커 엔터프라이즈 2.0 with 쿠버네티스 서포트 ** 가 릴리즈 되었고, 제 생각에는 스웜킷(SwarmKit) 과 libnetwork(https://github.com/docker/libnetwork) 프로젝트들을 다시 방문해보고 지난 열두달간 어떤 일이 있었는지 확인 해 볼 시간인것 같습니다. 이 글은 제가 도커 스웜 엔지니어와 Anshul Pundir(https://twitter.com/anshulpundir) 와 인터뷰 하면서 만들었던 도커 스웜의 과거,현재 그리고 미래 유툽 비디오를 바탕으로 작성 하였습니다. Reminder: “Docker Swarm Mode” 는 우리 모두가 사용하는 Docker CLI 혹은 다양한 GUI’s의 도커 엔진의 기능집합 입니다. 이 기능들은 SwarmKit 과 libnetwork 두 오픈소스 라이브러리에서 만들어 졌다고 볼 수 있습니다. 그렇기 때문에 우리가 “Docker Engine Release 18.XX,” 에서 확인 할 수 있는 새로운 기능들은 때때로 개발자들이 먼저 그 새로운 기능들을 SwarmKit과 libnetwork 에 먼저 올렸다는 뜻이죠. ** 물론 SwarmKit/libnetwork 에 추가된 기능들이 Docker engine 릴리즈에 합쳐지는데는 몇달 이상씩 걸릴수도 있습니다. ** 2017년 하반기와 2018년에 완료된 일들지난 열두달 동안 어떤일들이 끝났는지에 대해 이야기 해 봅시다. 주요 영향들은 버그 픽스들, 확장성(scalability)의 향상, 기술 부채 (Technical debt) 그리고 더 쉬운 트러블슈팅과 모니터링 위주로 이뤄 졌습니다. 아래는 주요 테마 와 관련된 merged 된 pull requests 입니다. ** 스웜 서비스들 (Swarm services) 의 진짜 중단시간 없는 순차 업데이트를 가능성을 열어줄 ** 일련의 픽스들 (헬스체크와 적절한 앱간의 연결 관리를 한다는 가정 하에). 대부분 moby#30321 에서 찾을 수 있고 마지막으로 알려진 이슈(내가 알고있는)는 PR moby#36638 로 18.05에 merged 되었습니다. 위에 언급한 변경 사항들은 하드웨어의 fault-tolerance 는 필요 하지 않지만 여전히 중단 없는 순차 업데이트를 원하는 사람들이 하나의 노드로 동작하는 스웜을 운영할 수 있게 해 줍니다. ** 저는 항상 docker-compose cli 보다는 하나의 노드로 이루어진 스웜(Swarm for single-node Docker setups) 을 추천 ** 합니다. 진단(diagnostic) API 엔드포인트와 cli 클라이언트를 포함한 ** 클라이언트/서버에 네트워크 트러블슈팅을 추가하는 툴 ** 이 추가 되었습니다. 스웜킷에 ** 다양한 스웜 객체에 대한 매트릭스가 ** 추가 되었습니다 swarmkit#2673 moby#37372 를 통한 VIP 로드 밸런싱의 확장성의 향상/발전 이 있었습니다. 이로 인해 유명한 이슈인 50k 이상 서비스를 가진 스웜의 빠른 확장 시도 가 close 되었습니다. 많은 task 배포시의 ** CPU 성능 향상 **을 포함해서 말이죠 swarmkit#2675. ** Windows server 1709 와 1803에서 이제 full Swarm networking을 지원 합니다 **. (overlay networks, routing mesh 그리고 VIP 를 포함하여). 여기 관련된 마이크로소프트의 발표를 확인하세요. Server Core 1709 혹은 더 최신버전의 VM이 필요 하고 Docker 18.03 혹은 최신 버전이 필요함을 알 수 있습니다. 또 윈도우 컨테이너의 버전별 제약사항을 꼭 확인하세요. 스웜 또한 docker run, swarm create 그리고 stack deploy를 통해 Hyper-V isolation 혹은 Process isolation을 이용하여 task를 생성할 수 있습니다. moby#34424 대규모 스웜의 확장성과 성능을 위해 raft replication에서 streaming snapshot model로의 변경이 있었습니다 swarmkit#2458 미국 정부 NIST FIPS 140-2 컴퓨터 보안 표준 은 진행중 이지만 현재의 최선책은 ** FIPS 표준을 지원하는 도커와 스웜, 즉 최신버전의 Docker Enterprise release 18.03.1 을 사용 할 수 있습니다. 관련된 PR은 2018년 SwarmKit 진행상황에서 확인 가능 합니다. 그리고 도커 블로그 포스트에 따르면 Docker Enterprise 에 포함(Management Plane)되는 쿠버네티스도 결국에는 FIPS 140-2이 유효하게 될 것 입니다. 스웜킷을 위한 TLA+ 지원 이 됩니다. TLA+는 으로써 기본적으로 코드의 품질을 validate 하기 위해 툴들과 함께 테스트 될 수 있는, 동시(concurrent) 시스템을 위한 디자인 스펙 입니다. 이건 저에게는 너무 똑똑한 것 같지만, 확장성과 품질을 향상시키는 작업의 중요한 역할을 한다고 들었습니다. Docker CLI를 스웜/쿠버네티스 스택에서 동일하게 사용 할 수 있도록 (Feature parity) 합니다. Docker CLI를 이용해서 오케스트레이터에서 동일하게 앱 관리를 할 수 있습니다. cli#1031 스웜 raft heartbeat와 election waits를 위한 도커 엔진 설정들이 추가 되었습니다; 네트워크 레이턴시가 높은 상황에서의 복원력을 향상 시키고 “매니저가 바뀌어 버리는 현상 (manager flip/flops)” 을 방지 하기 위한것으로 예상 됩니다. moby#36726 스웜 오버레이 네트워크를 지원 하기 위해 SCTP 프로토콜 이 추가 되었습니다. 이건 현재도 지원되고 있는 TCP/UDP/ICMP 프로토콜 보다 어려운 프로토콜 입니다. moby#33922 스웜 디버그 로그의 디테일이 향상 되었습니다. swarmkit#2486 서비스 태스크 (컨테이너)를 만들때 노드의 호스트네임을 기반으로 한 커스텀 호스트네임과 다른 스웜 환경변수들 을 가지고 만들수 있습니다 (템플릿을 사용하여) moby#34686 지금 까지 나열한 것들이 물론 전부 다는 아닙니다. 좀 더 자세한 정보를 원한다면 종료된 전체 관련 PR 리스트를 확인 하세요. 다른 진행중인 일들 Other Works In Progress (WIP)다음으로, 공개적으로 시작했거나 시작하려고 마음 먹은 일들에 대해서 살펴 보겠습니다. 스웜 서비스 안의 sysctl (Linux Kernel parameters) 설정. sysctl 의 파라미터는 네트워크 최적화 등을 이유로 주로 변경 해서 사용 합니다. 현재는 docker run 에서 설정 할 수 있지만 보안/커널 관련된 옵션들을 모두 “run”에서 “services” 로 옮기려는 노력이 진행중에 있습니다. docker run 에서 docker service create 로 옮기려는 모든 기능들의 리스트 는 여기에서 확인 하세요. moby#37701 swarmkit#2729 (역주: 확인해 보니 merged 됐네요) 디바이스 지원: 가장 흔한 유즈 케이스는 GPU 의 지원 일 것 입니다. 이를 통해 여러분은 하나 혹은 이상의 GPU들을 사용하는 서비스를 스케쥴 할 수 있을 것 입니다. 그리고 스웜은 어디에 그 태스크를 스케쥴 해야 하고, 어떻게 그 리소스들을 사용해야 할 지 알게 될 것 입니다. swarmkit#2682 (역주: 이건 오픈 상태인데 커멘트들을 보면 보류 된 상태로 보입니다) 스웜 클러스터를 위한 Kubemark와 비슷한 성능 테스트와 검증 툴. 우리는 스웜킷에 약간의 새로운 메트릭 들이 추가된 것을 swarmkit#2673에서 봤었지만 사용자 관점의 테스팅 툴에 관한 움직임을 한동안 보지 못 했습니다. 스웜 클러스터를 위한 벤치마킹과 테스팅 툴이 있으면 좋겠다는 의견이 몇몇의 엔지니어들에 의해 언급 되었지만, 아직 코드는 작성 된게 없어 보입니다. 새로운 네트워크와 IP 할당자. 모든 서버들이 각각의 버추얼 네트워크를 만들고 서브넷을 생성하고 출동하지 않는 IP들을 생성하는것은 쉬운 일이 아닙니다. 그리고 여러분의 서버에서 매초마다 새로 생겼다가 없어지는 컨테이너들을 가지고 있다면 앞에서 말한 네트워크관련 된 작업의 정확한 상태를 유지 하는것은 굉장히 어렵 습니다. 지난 몇년간 관련된 다양한 이슈들- 제가본 PR들을 보면- 은 지금 해결 되었습니다. 이건 나중의 기능들과 약간의 엣지 케이스들을 위해서 길을 포장하는것 처럼 들립니다. swarmkit#2686 더욱 향상된 로드 밸런싱. 제 생각에는 이게 스웜의 오버레이 네트워크 드라이버 의 라우팅 메시(routing mesh)와 VIP 기능들의 사용할 수 있는 다이얼(knobs)를 뜻하는것 같네요. 관련된 스펙은 없습니다.(역주: 다른것들은 github pr이나 issue 넘버가 있는데 이건 없다는 뜻 입니다.) 클러스터 볼륨(Cluster volumes). 도커에는 이제까지 스웜에서 인식할 수 있는 내장된 볼름 드라이버가 없었습니다. 이에 대해서는 2017년 초부터 되어 왔습니다. ** 지금은 REX-Ray ** 를 사용 하거나 다른 써드파티 도커 플러그인 들을 사용할 수 있습니다. 또한 도커의 CloudStor 드라이버도 있지만 이들은 모두 아직 오픈소스가 아니거나 빌트인으로 제공 되지 않습니다. ** 스웜킷 팀에서는 클러스터 볼륨에 다시 관심을 갖게 되었고, 아마도 CSI 를 지원** 할것 같습니다. CSI는 Container Storage Interface 의 약자로 다른 오케스트레이터들도 지원을 합니다. 현재는 Custom default IP subnets 이 bridge networks 에 한하지만 overlay 까지 확장되길 기대 합니다. moby#36396 도커 스웜 팀은 지금 구인중 입니다위에 있는 제 Anshul 과의 인터뷰 비디오를 보면, 그의 팀은 스웜 엔지니어를 구한다고 언급 했습니다. 보다 자세한 정보는 그들의 구인 페이지에서 “Orchestration Engineers” 를 참조하세요. (역주: 현재 2020년 1월에 확인했을 때는 해당 링크는 존재하지 않습니다.) Thanks To Docker도커 팀에게 감사의 말씀을 드립니다. 도커 본사에서 저와 함께 시간을 보내면서 도커 캡틴들이 정보를 공유하고 커뮤니티에 도움을 줄 수 있게 도와준 Anshul Pundir 그리고 Mano Marks 특히 더 고맙습니다. Get More Swarm Education제 스웜 마스터리 코스는 인터넷상에서 스웜을 배우는 가장 좋은 방법 입니다! 그리고 도커의 기초 훈련도 제 도커 마스터리 코스에서 받을 수 있습니다.","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://www.nakjunizm.com/categories/DevOps/"},{"name":"Docker","slug":"DevOps/Docker","permalink":"https://www.nakjunizm.com/categories/DevOps/Docker/"},{"name":"Swarm","slug":"DevOps/Docker/Swarm","permalink":"https://www.nakjunizm.com/categories/DevOps/Docker/Swarm/"}],"tags":[{"name":"Swarm","slug":"Swarm","permalink":"https://www.nakjunizm.com/tags/Swarm/"},{"name":"Docker","slug":"Docker","permalink":"https://www.nakjunizm.com/tags/Docker/"}]},{"title":"RabbitMQ 고가용성(HA) 를 위해 Cluster 하는 방법 (RabbitMQ HA)","slug":"RabbitMQ_Cluster","date":"2019-10-30T07:31:00.000Z","updated":"2021-10-06T15:33:17.484Z","comments":true,"path":"2019/10/30/RabbitMQ_Cluster/","link":"","permalink":"https://www.nakjunizm.com/2019/10/30/RabbitMQ_Cluster/","excerpt":"","text":"RabbitMQ를 두대 이상의 PC/Server/VM 에 설치 하는 경우 HA(High Availability)를 확보 하기 위해 클러스터 Cluster로 만들어서 사용 할 수 있습니다. 이번 포스트에서는 커맨드 위주로 간단하게 클러스터를 만들어 보겠습니다. 참고: https://www.rabbitmq.com/clustering.html rabbitmq 클러스터링 하기 PC2를 PC1의 클러스터에 join 시키는 예로 진행 해 보겠습니다. @ 커맨드는 centos6 기준으로 작성 되었습니다. rabbitmq-env.conf 파일 확인 1sudo vi /etc/rabbitmq/rabbitmq-env.conf port나 directory등이 클러스터링 할 노드들 간에 서로 동일하게 설정 되어 있는지 확인 합니다. service stop (PC2에서) 1sudo service rabbitmq-server stop erlang cookie 맞추기 (한개서버의 erlang cookie값으로 통일) 1sudo cat /var/lib/rabbitmq/.erlang.cookie startup (PC2에서) 1sudo service rabbitmq-server start 각 서버 cluster_status 확인 (PC1 클러스터 이름확인) 1sudo rabbitmqctl cluster_status 클러스터 이름은 rabbit@nakjunizm 으로 확인 됐습니다. application stop (PC2에서) 1sudo rabbitmqctl stop_app join (PC2에서) 1sudo rabbitmqctl join_cluster rabbit@nakjunizm application start (PC2에서) 1sudo rabbitmqctl start_app 작업내용을 기록해 놓기 위한 포스트로 각 단계의 자세한 설명은 생략하였습니다.주의사항은 Queue는 mirror 되어 있어야 합니다. (제 경우 ha-all) queue mirror 관련 docs: https://www.rabbitmq.com/ha.html 위 단계들을 모두 마치고 cluster를 만들었으면 Active/Active 상태의 클러스터 이기 때문에, 어느 쪽에 데이터가 들어가던지 ha 전략에 따라 각 노드에 분산 됩니다. 그러므로 클러스터의 앞단에 Load balancer를 놓고 클라이언트에서는 Load balancer에 request를 요청한다. 클라이언트에서 각 클러스터의 주소값을 다 알고 있고, 코드에서 어느쪽으로 request를 요청할지 결정한다. 두가지 옵션 중 편한쪽으로 선택하여 사용하기시 바랍니다.","categories":[{"name":"Operations","slug":"Operations","permalink":"https://www.nakjunizm.com/categories/Operations/"},{"name":"RabbitMQ","slug":"Operations/RabbitMQ","permalink":"https://www.nakjunizm.com/categories/Operations/RabbitMQ/"}],"tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://www.nakjunizm.com/tags/rabbitmq/"},{"name":"ha","slug":"ha","permalink":"https://www.nakjunizm.com/tags/ha/"},{"name":"cluster","slug":"cluster","permalink":"https://www.nakjunizm.com/tags/cluster/"},{"name":"mirror","slug":"mirror","permalink":"https://www.nakjunizm.com/tags/mirror/"}]},{"title":"GraphQL의 스키마(Schema)","slug":"GraphQL_Schema","date":"2019-10-16T06:52:00.000Z","updated":"2021-10-06T15:33:17.418Z","comments":true,"path":"2019/10/16/GraphQL_Schema/","link":"","permalink":"https://www.nakjunizm.com/2019/10/16/GraphQL_Schema/","excerpt":"","text":"이번 포스트는 apollo docs 의 schema 부분의 일부를 번역 한 포스트 입니다. 원글: https://www.apollographql.com/docs/apollo-server/schema/schema/ Schema Scalar types Object types The Query type The Mutation type Input types Scalar types스칼라 타입은 다른 프로그래밍 언어에서 이야기 하는 기본형 (primitive type)과 유사 합니다. GraphQL의 default scalar types Int: A signed 32-bit integer Float: A signed double-precision floating-point value String: A UTF-8 character sequence Boolean: true or false ID (serialized as a String): A unique identifier that’s often used to refetch an object or as the key for a cache. Although it’s serialized as a String, an ID is not intended to be human-readable. Default 스칼라 타입으로 대부분의 경우 커버 가능 하지만, 그렇지 않은 경우에는 Custom scalar types 을 만들어서 사용하는것도 가능 합니다. Object typesGraphQL 스카마에 정의된 대부분의 타입은 object 타입 입니다.object는 필드의 컬렉션을 포함 하고 있고, 각 필드는 scalar 타입 이거나, 다른 object 타입 입니다.예를 들면 123456789type Book &#123; title: String author: Author&#125;type Author &#123; name: String books: [Book]&#125; The Query typeQuery 타입은 client에서 호출 할 GraphQL의 정확한 query를 정의 합니다. (read query)Query 의 필드는 쿼리 이름과 리턴타입으로 구성 되어 있습니다. 예를 들면 1234type Query &#123; getBooks: [Book] getAuthors: [Author]&#125; 위의 query 타입은 getBooks 와 getAuthors 라는 이름의 두 쿼리를 정의 하고, 각 쿼리는 Book과 Author 의 리스트를 각각 리턴 하는걸 알 수 있습니다. 이게 REST-based API 였다면 아마도 두개의 다른 endpoints로 만들었겠지요 (예를 들면 /api/books and /api/authors). 하지만 GraphQL은 하나의 endpoint에서 두개의 리소스에 접근 할 수 있는 유연성을 제공 합니다. Structuring a queryclient에서 서버의 data graph에 실행할 쿼리를 만들때, 그 쿼리는 서버의 schema에 정의 된 object types과 일치 해야 합니다. 지금까지 예로 들은 몇개의 스키마를 예를 들면, client는 다음과 같이 모든 book 과 모든 author 의 이름을 가져오는 쿼리를 할 수 있습니다. 12345678query &#123; getBooks &#123; title &#125; getAuthors &#123; name &#125;&#125; 우리 서버에서는 아래와 비슷하게 응답 해 줄 것 입니다. 12345678910111213141516&#123; &quot;data&quot;: &#123; &quot;getBooks&quot;: [ &#123; &quot;title&quot;: &quot;Jurassic Park&quot; &#125;, ... ], &quot;getAuthors&quot;: [ &#123; &quot;name&quot;: &quot;Michael Crichton&quot; &#125;, ... ] &#125;&#125; 이렇게 두개의 전혀 다른 리스트를 가져오는게 쓸모있는 경우가 있긴 하겠지만, client에서는 아마도 author의 이름이 포함 되어있는 하나의 books 리스트를 받기를 선호할것 같습니다. Book 타입이 Author 타입의 author 필드를 가지고 있으므로, client는 아마 아래와 같이 쿼리 하는것이 더 낫겠네요. 12345678query &#123; getBooks &#123; title author &#123; name &#125; &#125;&#125; 그러면 서버에서는 아래와 같이 더 깔끔한 결과를 보내 줄 것 입니다. 12345678910111213&#123; &quot;data&quot;: &#123; &quot;getBooks&quot;: [ &#123; &quot;title&quot;: &quot;Jurassic Park&quot;, &quot;author&quot;: &#123; &quot;name&quot;: &quot;Michael Crichton&quot; &#125; &#125;, ... ] &#125;&#125; The Mutation typeMutation 타입은 Query 타입과 구조적으로 비슷하게 생겼습니다. Query 타입이 데이터를 읽어오는(read) operation 을 정의 한다면,Mutation 타입은 데이터를 쓰는 (write) operation을 정의 합니다. 각 필드는 시그니처와 리턴 타입을 정의 하고, 예를 들면 아래와 같습니다. 123type Mutation &#123; addBook(title: String, author: String): Book&#125; 위 예의 Mutaion타입은 addBook 이라는 하나의 mutation을 정의 했습니다. addBook은 title과 author 두개의 인자값을 가지고 있으며 Book 타입의 object를 리턴해 준다고 정의 되어 있습니다. Book 타입은 물론 위의 obejct types의 스키마에 정의된 그 Book 입니다. Structuring a mutation쿼리와 마찬가지로, 뮤테이션도 스키마에 정의된 타입과 일치하는 구조를 갖고 있습니다. 아래 예는 새로운 Book 오브젝트의 생성을 요청하고, 리턴값으로는 방금 생성한 오브젝트의 특정 필드를 반환해 달라고 합니다. 12345678mutation &#123; addBook(title: &quot;Fox in Socks&quot;, author: &quot;Dr. Seuss&quot;) &#123; title author &#123; name &#125; &#125;&#125; 쿼리의 결과와 마찬가지로 서버에서는 아래와 같이 뮤테이션에서 요청한 필드들을 반환해 줍니다. 12345678910&#123; &quot;data&quot;: &#123; &quot;addBook&quot;: &#123; &quot;title&quot;: &quot;Fox in Socks&quot;, &quot;author&quot;: &#123; &quot;name&quot;: &quot;Dr. Seuss&quot; &#125; &#125; &#125;&#125; 한개의 client 요청에 여러개의 뮤테이션이 들어 있는 경우, 경합을 방지하기 위해 뮤테이션은 순차적으로 처리 됩니다. Input types인풋 타입은 특별한 오브젝트 타입 입니다. 쿼리와 뮤테이션에 정의된 operation은 인자로 스칼라 타입만 가질 수 있는데, 인풋 타입은 스칼라가 아니지만 인자로 사용할 수 있습니다. 그래서 인풋 타입은 operation의 시그니처를 깔끔한 상태로 유지할 수 있게 도와 줍니다. 이건 java에서 paramMap을 넘기거나, javascript에서 options object를 인자로 넘기는게 각 인자를 쭉~ 나열하는것 보다 보기에 깔끔하고, 추후에 인자로 추가 하고 싶은것이 생겼을때 함수의 시그니처를 변경하지 않아도 되는 장점이 있는것과 동일 합니다. 아래 뮤테이션이 블로그 포스트를 생성하는 뮤테이션이라고 가정 합시다. 12345type Mutation &#123; createPost(title: String, body: String, mediaUrls: [String]): Post&#125; 위와 같이 세개의 인자를 받는게 아니라 하나의 인풋 타입의 인자를 받게 바꿔 보겠습니다. 이렇게 하면 추후에 인자를 더 추가하기로 결정 한 경우, 예를 들면 author같은, 훨씬 간편 합니다. 12345678910type Mutation &#123; createPost(post: PostAndMediaInput): Post&#125;input PostAndMediaInput &#123; title: String body: String mediaUrls: [String]&#125; 이렇게 전달 하면 client에서 PostAndMediaInput은 도대체 뭐 하는 놈인데? 라고 생각 할 수 있는데, 이런걸 대비해서 GraphQL은 각 필드를 설명하는 annotating fields를 사용 할 수 있게 했습니다. GraphQL-enabled 된 툴에서는 해당 설명이 바로 보일 수 있게 말이죠. 12345678input PostAndMediaInput &#123; &quot;A main title for the post&quot; title: String &quot;The text body of the post.&quot; body: String &quot;A list of URLs to render in the post.&quot; mediaUrls: [String]&#125; 인풋타입은 가끔 완벽히 동일한 인자를 요구하는 쿼리나 뮤테이션에서 재 사용 하기 위해 사용 되기도 합니다. 그런데 이런 재사용은 최소한으로 해야 합니다. 왜냐하면 지금은 완벽히 동일한 인자가 필요 하지만 나중에는 아닐수도 있으니까요. ** 쿼리와 뮤테이션에서 동일한 인풋타입을 사용하지 마세요 ** 뮤테이션에는 required 인 필드가 쿼리에서는 optional인 경우가 굉장히 많기 때문 입니다.","categories":[{"name":"Development","slug":"Development","permalink":"https://www.nakjunizm.com/categories/Development/"},{"name":"GraphQL","slug":"Development/GraphQL","permalink":"https://www.nakjunizm.com/categories/Development/GraphQL/"}],"tags":[{"name":"GraphQL","slug":"GraphQL","permalink":"https://www.nakjunizm.com/tags/GraphQL/"},{"name":"Schema","slug":"Schema","permalink":"https://www.nakjunizm.com/tags/Schema/"},{"name":"Apollo","slug":"Apollo","permalink":"https://www.nakjunizm.com/tags/Apollo/"}]},{"title":"passport.js how to","slug":"Passportjs_guide","date":"2019-09-18T12:12:00.000Z","updated":"2021-10-06T15:33:17.427Z","comments":true,"path":"2019/09/18/Passportjs_guide/","link":"","permalink":"https://www.nakjunizm.com/2019/09/18/Passportjs_guide/","excerpt":"","text":"# Passport.jsPassport는 Node.js진영에서 가장 널리 사용되고 있는 authentication middelware 입니다. Passport is authentication middleware for Node.js. Extremely flexible and modular, Passport can be unobtrusively dropped in to any Express-based web application. A comprehensive set of strategies support authentication using a username and password, Facebook, Twitter, and more. -passportjs.org 개인적으로 진행하고 있는 Toy project가 있는데, Node.js를 이용해서 Server-side를 개발하고 있습니다. ID/Password 로그인 불가 - DB에 해당 정보를 가지고 있기 싫음 Google, Naver, Kakao 아이디를 연동한 로그인만 가능 별도의 회원가입 절차 없이 소셜 로그인을 성공 하면 1 해당 소셜의 아이디를 가진 User가 있을 시 로긴 2 해당 소셜의 아이디를 가진 User가 없을 시 User생성 후 로긴 위와같은 기능을 구현하기 위해 소셜 로그인 기능을 검색 하다가 Passport.js 를 알게 되었고,초보자의 입장에서 1부터 이해하기 쉽게 설명 되어있는 글을 찾기가 쉽지 않아서 기록의 목적으로 포스팅 합니다. # Flow일단 이게 어떤 흐름으로 동작 하는지를 이해 할 필요가 있습니다. 편의상 구글 로그인을 하는것으로 설명하면 화면에서 구글 로그인 버튼을 누름 구글 로그인 페이지가 뜸 (구글의 로그인 페이지. 나한테는 이 페이지의 주도권이 없음) 로그인 성공/실패 결과와 함께 구글 로그인 페이지가 Callback 함수를 찔러줌 (이때부터 다시 주도권이 나한테 돌아옴) 쉽게 위 세가지의 단계로 이뤄지고 구글로 설명 했지만구글, 페이스북, 카카오, 네이버, 깃헙 등등 소셜 로그인 서비스를 제공 해 주는 업체들 모두 동일 합니다.더 자세히 설명하진 않겠지만 각 서비스에 사용 신청을 하는 페이지에 필수적으로 넣어야 하는 값으로 서비스URL (또는 사이트 도메인) Callback URL (또는 Redirect URL) 서비스URL은 내 홈페이지 URL을 적어 주면 되고, Callback URL은 로그인 결과를 받을 내 서버의 api 주소를 적어 주면 됩니다.제 서비스는 아래와 같이 적어서 서비스 사용 신청을 했습니다. 서비스URL: http://plp.nakjunizm.com Callback URL: http://plp.nakjunizm.com/auth/google/callback # 구현어떤 흐름인지는 대충 알겠으니, 구현을 해 봅시다. &lt; /br&gt;First things first. 필요한 모듈을 설치 합니다. 1npm install passport passport-google-oauth20 express-session Passport 에서는 로그인을 Strategy라는 이름으로 구분짓는데, passport-google-oauth20 은 구글로그인을 하기 위한 Strategy를 쉽게 사용하기 위해 설치 합니다. express-session은 나중에 로그인 세션을 유지하기 위해 passport.session()을 호출해 줘야 하는데 이때 필수적으로 사용 됩니다. 아래 코드는 Strategy를 등록할 passport.js 입니다.passport.serializeUser() 와 passport.deserializeUser()는 세션과 관련된 함수 입니다. 제가 찾아봤던 대부분의 글에서 그냥 무작성 써야 동작한다 라고만 적혀있어서 이해하기 쉽지 않았는데 역시 모든 답은 공식 다큐먼트에 있었습니다. 꼭 공식 다큐먼트를 읽어보는 습관을 들입시다 ㅎㅎ SessionsIn a typical web application, the credentials used to authenticate a user will only be transmitted during the login request. If authentication succeeds, a session will be established and maintained via a cookie set in the user’s browser.Each subsequent request will not contain credentials, but rather the unique cookie that identifies the session. In order to support login sessions, Passport will serialize and deserialize user instances to and from the session. 123456789101112131415161718192021222324252627282930313233343536373839404142const passport = require(&quot;passport&quot;);const GoogleStrategy = require(&quot;passport-google-oauth20&quot;).Strategy;const config = require(&quot;config&quot;);const User = require(&quot;../models/User&quot;);module.exports = () =&gt; &#123; passport.serializeUser((user, done) =&gt; &#123; done(null, user); &#125;); passport.deserializeUser((user, done) =&gt; &#123; done(null, user); &#125;); passport.use( new GoogleStrategy( &#123; clientID: config.get(&quot;google.clientID&quot;), clientSecret: config.get(&quot;google.clientSecret&quot;), callbackURL: config.get(&quot;google.callbackURL&quot;) &#125;, async (accessToken, refreshToken, profile, cb) =&gt; &#123; try &#123; const user = await User.findUserByGoogleId(profile.id); if (user) &#123; return cb(null, user); &#125; // 회원 정보가 있으면 로그인 const newUser = new User(&#123; // 없으면 회원 생성 type: &quot;google&quot;, google_id: profile.id &#125;); newUser.save(user =&gt; &#123; return cb(null, user); // 새로운 회원 생성 후 로그인 &#125;); &#125; catch (err) &#123; return cb(err, false); &#125; &#125; ) );&#125;; server.js는 서버를 띄우는 main 클래스 입니다. 123456789101112131415161718192021222324252627282930313233343536const express = require(&quot;express&quot;);const connectDB = require(&quot;./config/db&quot;);const router = express.Router();// passportconst session = require(&quot;express-session&quot;); // 세션 설정const passport = require(&quot;passport&quot;);const passportConfig = require(&quot;./middleware/passport&quot;);const app = express();// 세션 활성화app.use( session(&#123; secret: &quot;mysecret&quot;, resave: true, saveUninitialized: false &#125;));app.use(passport.initialize());app.use(passport.session());connectDB();passportConfig();app.get(&quot;/&quot;, async (req, res) =&gt; &#123; console.log(&quot;hi&quot;); return res.status(200).send(`It&#x27;s up and running!`);&#125;);app.get(&quot;/login&quot;, async (req, res) =&gt; &#123; return res.status(200).send(`Login Page!`);&#125;);app.use(&quot;/auth&quot;, require(&quot;./routes/auth&quot;));const PORT = process.env.PORT || 5000;app.listen(PORT, () =&gt; &#123; console.log(`Server started on port $&#123;PORT&#125;`);&#125;); 공식 다큐먼트를 보면 static과 bodyparser관련 코드들이 있지만, 일단 여기서는 사용하지 않고 쌩으로 URL을 치고 들어가서 로그인 성공 여부만 테스트 해 보겠습니다; 임시로 / 와 /login 의 get route를 server.js에 넣어 놨고 나중에도 사용할 auth router는 따로 파일로 뺐습니다. 1234567891011121314151617const express = require(&quot;express&quot;);const router = express.Router();const passport = require(&quot;passport&quot;);// @route GET auth/googlerouter.get(&quot;/google&quot;, passport.authenticate(&quot;google&quot;, &#123; scope: [&quot;profile&quot;] &#125;));// @route GET auth/google/callbackrouter.get( &quot;/google/callback&quot;, passport.authenticate(&quot;google&quot;, &#123; failureRedirect: &quot;/login&quot; &#125;), async (req, res) =&gt; &#123; res.redirect(&quot;/&quot;); &#125;);module.exports = router; 웹브라우저에서 http://localhost:5000/auth/google 을 치고 들어 가면, passport.authenticate(&quot;google&quot;, &#123; scope: [&quot;profile&quot;] &#125;) 이 부분이 호출 되는데 이게 맨~위에 설명 했던 Flow의 2번. 구글 로그인 페이지가 뜸 (구글의 로그인 페이지. 나한테는 이 페이지의 주도권이 없음) 입니다.이와같이 로그인 페이지가 보인다면 정상적으로 동작 하고 있다는 뜻 이겠죠. 로그인을 진행 하면 Flow의 3. 로그인 성공/실패 결과와 함께 구글 로그인 페이지가 Callback 함수를 찔러줌 (이때부터 다시 주도권이 나한테 돌아옴)이 진행 됩니다. /google/callback 라우트를 보면 passport.authenticate(&quot;google&quot;, &#123; failureRedirect:...&#125;)이라고 되어 있는데 “google” strategy를 실행 할 것이고, 실패 시에는 failureRedirect로 보내겠다는 뜻 입니다. google strategy는 위에서 작성한 passport.js에 적혀있는대로 회원정보가 있으면 로그인, 없으면 자동으로 회원가입 시키면서 로그인을 합니다. # 정리Node.js를 최근에 공부하기 시작하여 ES6, ES7 문법으로 시작했기 때문에 어떤때는 다큐먼드들이 보기가 힘이 듭니다.공부한걸 정리하는 차원에서 최대한 arrow function 과 async await try catch를 사용 하였습니다.저도 이제 막 공부하는 단계이기 때문에 내용에 틀린점이 있다면 커멘트 부탁드립니다!","categories":[{"name":"Development","slug":"Development","permalink":"https://www.nakjunizm.com/categories/Development/"},{"name":"node","slug":"Development/node","permalink":"https://www.nakjunizm.com/categories/Development/node/"}],"tags":[{"name":"node","slug":"node","permalink":"https://www.nakjunizm.com/tags/node/"},{"name":"passport","slug":"passport","permalink":"https://www.nakjunizm.com/tags/passport/"},{"name":"OAuth","slug":"OAuth","permalink":"https://www.nakjunizm.com/tags/OAuth/"}]},{"title":"Ansible_For_Windows","slug":"Ansible_For_Windows","date":"2019-02-08T13:53:00.000Z","updated":"2021-10-06T15:33:17.420Z","comments":true,"path":"2019/02/08/Ansible_For_Windows/","link":"","permalink":"https://www.nakjunizm.com/2019/02/08/Ansible_For_Windows/","excerpt":"","text":"Ansible을 활용한 windows 서버에 배포 혹은 작업 하기 Ansible을 업무에 사용하는데 아주 가~끔 Linux + Windows 로 서버가 통일되지 않은 사이트들을 구축해야 할 때가 있습니다. Linux의 경우 Ansible이 agentless 하게 ssh로 모든 작업이 이뤄지기 때문에 아무런 문제가 없지만 Windows 서버의 경우 어떻게 해야 할지 막막하기도 하고 googling 해서 어찌어찌 하긴 하는데 계속 까먹어서 기록용으로 남기는 포스트 입니다. # 준비사항 ansible 2.0 이상 연결시키려는 윈도우 서버에서 ConfigureRemotingForAnsible.ps1 스크립트 실행 (링크 타고 github 들어가서 ps1파일 다운로드) # windows에 접속하기 위해 계정정보, 포트, winrm 설정 group_var 설정 (windows.yml 등으로 생성) 12345678# windows 서버의 subset nameansible_hosts: windows# windows 서버 계정ansible_user: nakjunizmansible_port: 5986ansible_connection: winrm# The following is necessary for Python 2.7.9+ when using default WinRM self-signed certificates:ansible_winrm_server_cert_validation: ignore # playbook 작성 (예 windows file check하는 task)a. 실행명령어 1ansible-playbook /nakjunizm/ansible/playbooks/deploy_agent.yml -i /nakjunizm/ansible/playbooks/inventories/staging.yml -l windows -u nakjunizm-k -e action=stat b. deploy_agent.yml 123- hosts: all roles: - agent c. main.yml 1- include_vars: &quot;/nakjunizm/ansible/playbooks/group_vars/common.yml&quot; d. stat.yml 12345---- name : check if agent.zip exists win_stat: path=D:\\agent\\agent.zip register: file_info- debug: var=file_info # 참조 사이트 http://docs.ansible.com/ansible/intro_windows.html","categories":[{"name":"Operations","slug":"Operations","permalink":"https://www.nakjunizm.com/categories/Operations/"},{"name":"Ansible","slug":"Operations/Ansible","permalink":"https://www.nakjunizm.com/categories/Operations/Ansible/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://www.nakjunizm.com/tags/ansible/"},{"name":"devops","slug":"devops","permalink":"https://www.nakjunizm.com/tags/devops/"}]},{"title":"ElasticSearch_Version_Up","slug":"ElasticSearch_Versionup_From2x_To6x","date":"2019-01-11T13:28:00.000Z","updated":"2021-10-06T15:33:17.411Z","comments":true,"path":"2019/01/11/ElasticSearch_Versionup_From2x_To6x/","link":"","permalink":"https://www.nakjunizm.com/2019/01/11/ElasticSearch_Versionup_From2x_To6x/","excerpt":"","text":"# Overview2.3.X 버전으로 운영되고 있는 클러스터를 6.4.X 클러스터로 버전업 했던 경험을 포스팅 해 보겠습니다. 제약사항 기존 2.3.X 클러스터에 ES 뿐 아니라 다른 어플리케이션들도 동작하고 있음 운영중인 시스템 이므로 ES 클러스터의 다운타임은 존재하면 안됨 제약사항 1 때문에 임시 서버를 받고, 임시 서버에 6.4.X 클러스터를 구성 하였음 # 작업 계획 임시서버에 6.4.X 클러스터 구성 기존 2.3.X 클러스터의 데이터를 6.4.X 클러스터로 이관 (_reindex api 활용) 이관이 완료되고 나면 ES에 indexing을 하거나 searching을 하는 모든 어플리케이션들이 6.4.X 클러스터(임시서버)를 바라보도록 설정. 2.3.X 클러스터는 더이상 사용되지 않으므로 종료 시키고, 로그 디렉토리 및 데이터 디렉토리 삭제. 2.3.X 클러스터를 삭제한 노드에 6.4.X 설치. 이때, 임시서버에 만든 클러스터에 join 될 수 있도록 설정. 여기까지 완료 되면 6.4.X 클러스터는 기존 대비 두배 많은 노드 수를 가지게 됨 (기존 노드 + 임시 서버) 어플리케이션들이 6.4.X (기존서버)를 바라보도록 설정. (임시서버 제거 준비작업) 임시서버 노드들을 한대씩 내리면서 기존 서버로만 구성된 클러스터 생성. (사용량이 많다면 shards re-allocate가 완료된 후 한대씩 내리면서 작업) # 주요 작업 상세2.3.X의 데이터는 DB에서 직접 인덱싱 하는 인덱스와, ES to ES 로 인덱싱 하는 데이터가 있는데, DB to ES는 마이그레이션 용도로 만든 프로그램을 사용하였고 ES to ES는 _reindex api 를 이용하여 색인 하였습니다. DB to ES 색인, ES to ES 색인 할때 성능 향상을 위해서는 아래 설정을 조정해 가면서 가장 빠르고 안정적으로 마이그레이션 할 수 있는 값을 찾아야 합니다. (다수의 테스트 마이그레이션 필요) ※ 아래 설정들은 모두 6.4.X 클러스터에 적용되어야 하는 값들 임index.number_of_replicas: “0” 으로 설정 (동적 변경 가능)index.refresh_interval: “-1” 로 설정 (동적 변경 가능)indices.memory.index_buffer_size: 40% 로 설정 (동적 변경 불가능 하므로 elasticsearch.yml 에 추가 하고 클러스터 재시작 필요. default는 10%) ※ 실제 마이그레이션이 완료 된 이후에는 위 세 값들은 모두 원복 하는것이 좋습니다. 마이그레이션이 완료 되고 난 후 ES를 사용하는 모든 어플리케이션들이 임시 서버로 인덱싱/서칭 하도록 설정하고 (api가 변경되었으므로 프로그램 수정 &amp; 배포 필요) 아래 그림과 같이 기존 2.3.X 노드가 설치되어 있던 서버들에서 2.3.X를 제거하고 6.4.X를 설치 하여 임시서버에 구성되어 있는 클러스터에 join 시킵니다. 위 그림과 같이 기존노드3, 임시노드3 인 경우 기존서버에 새로 설치한 6.4.X의 elasticsearch.yml 중 Discovery 일부 1234567891011# --------------------------------- Discovery ----------------------------------## Pass an initial list of hosts to perform discovery when new node is started:# The default list of hosts is [&quot;127.0.0.1&quot;, &quot;[::1]&quot;]#discovery.zen.ping.unicast.hosts: [&quot;node1&quot;, &quot;node2&quot;, &quot;node3&quot;, &quot;temp1&quot;,&quot;temp2&quot;,&quot;temp3&quot;]## Prevent the &quot;split brain&quot; by configuring the majority of nodes (total number of master-eligible nodes / 2 + 1):#discovery.zen.minimum_master_nodes: 4 안정적인 운영을 위해 discovery.zen.minimum_master_nodes를 4로 설정하고 join 시켰습니다.여기 까지 완료 되면 기존 노드가 3대로 운영되고 있었다고 할때 6.4.X 클러스터는 6노드로 운영되고 있는 형상을 가지게 됩니다.이제 임시 서버에 설치되어 있는 6.4.X를 제거 하기 위해 ES를 바라보는 모든 어플리케이션이 기존 서버 (아래 그림의 node1~3)을 바라보도록 설정 하고임시 서버의 노드를 한대씩 순차적으로 제거 합니다. ※ 주의사항node 1~3 에 discovery.zen.minimum_master_nodes 가 현재 4로 셋팅되어 있는데 임시 서버의 노드들을 탈락 시키기 전에 이 값을 2(최종 노드 갯수인3을 2로 나눈값 +1) 로 변경하고 클러스터 재시작을 한 이후 노드들을 제거 해야 함. 혹은 discovery.zen.minimum_master_nodes 는 dynamically 변경할 수 있는 설정이므로 온라인으로 변경 가능. 123456PUT _cluster/settings&#123; &quot;transient&quot;: &#123; &quot;discovery.zen.minimum_master_nodes&quot;: 2 &#125;&#125; 그런데 어짜피 unicast hosts 에서 임시서버를 제거 해야 하므로 (이 셋팅은 dynamic 이 아님…..) elasticsearch.yml 수정 후 클러스터 재시작 추천. elasticsearch.yml 1234567891011# --------------------------------- Discovery ----------------------------------## Pass an initial list of hosts to perform discovery when new node is started:# The default list of hosts is [&quot;127.0.0.1&quot;, &quot;[::1]&quot;]#discovery.zen.ping.unicast.hosts: [&quot;node1&quot;, &quot;node2&quot;, &quot;node3&quot;]## Prevent the &quot;split brain&quot; by configuring the majority of nodes (total number of master-eligible nodes / 2 + 1):#discovery.zen.minimum_master_nodes: 2 minimum_master_nodes의 값을 4로 유지한채로 임시서버의 노드를 내리기 시작하면, 노드 갯수가 세개가 되는 순간 마스터 노드를 선출하지 못하게 되고 클러스터가 사용 불가능한 상태가 될 수 있습니다. (실제로 해당 작업중 직접 경험 ㄷㄷㄷ) # 정리ElasticSearch의 엄청난 EOL 스케쥴 - 2019년 3월이면 ES 5.6.X (5X의 최신버전)이 EOL 되는 무시무시함 - 과6.4.0 이후부터 공식적으로 사용 가능한 한국어 형태소 분석기인 nori 를 사용하기 위해서는 버전업은 꼭 하는 것을 추천 하고여유가 된다면 임시 서버를 받아서 클러스터의 중단 없이 버전업 하는 방법을 조심스레 추천 드려 봅니다.사실상 버전업에서 가장 중요한 작업은 데이터 마이그레이션 이고 시간도 가장 많이 소요 됐습니다. 충분한 테스트와 검증 기간을 거친 후 버전 업그레이드를 진행하시길 바랍니다.","categories":[{"name":"Operations","slug":"Operations","permalink":"https://www.nakjunizm.com/categories/Operations/"},{"name":"ElasticSearch","slug":"Operations/ElasticSearch","permalink":"https://www.nakjunizm.com/categories/Operations/ElasticSearch/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://www.nakjunizm.com/tags/elasticsearch/"},{"name":"versionup","slug":"versionup","permalink":"https://www.nakjunizm.com/tags/versionup/"},{"name":"ES Version up","slug":"ES-Version-up","permalink":"https://www.nakjunizm.com/tags/ES-Version-up/"},{"name":"6.4.0","slug":"6-4-0","permalink":"https://www.nakjunizm.com/tags/6-4-0/"}]},{"title":"eager global ordinals","slug":"Eager_Global_Ordinals","date":"2018-12-28T13:11:21.000Z","updated":"2021-10-06T15:33:17.445Z","comments":true,"path":"2018/12/28/Eager_Global_Ordinals/","link":"","permalink":"https://www.nakjunizm.com/2018/12/28/Eager_Global_Ordinals/","excerpt":"","text":"# eager_global_ordinals란 무엇인가Elastic공식 가이드에서 필요한 부분만 발췌하여 번역하였습니다. # Global ordinals Global ordinals 는 doc values 최상위에 존재하는 데이터 구조로 각 유니크한 term에 대해 증가하는 넘버를 부여하는 형태로 존재 합니다. keyword와 text 필드에 적용 가능 합니다. 실제 doc values 에는 ordinals를 가지고 있는데 이는 세그먼트와 필드에 유니크 넘버를 부여한 것이고 Global ordinals는 그 위에 존재함으로써 segment ordinals와 global ordinals사이의 맵핑을 제공해 줍니다. 이로 인해 segment ordinals를 사용하는 작업, 예를 들면 terms aggregation, join 등이 일어날때 실행 시간을 단축 시키는 역할을 합니다. 이게 가능한 이유는 global ordinals만을 사용해서 shard level에서 aggregation을 수행하고, global ordinals를 real term으로 변환하는 과정은 final reduce phase (각 shard result를 합치는 phase)에서만 일어나기 때문 입니다. # eager global ordinals global ordinals는 default로 search-time 에 로드 됩니다. (indexing speed에 더 관심이 있는 경우) eager_global_ordinals: true 를 field의 속성으로 주면 index의 refresh time 에 로드 시킵니다. (검색 시간이 더 중요한 경우) 즉 global_ordinals 를 로드시키는 시점이 search-time이나 refresh-time이냐에 따라서 eager_global_ordinals 옵션을 false 혹은 true로 설정하는 것 입니다.","categories":[{"name":"Operations","slug":"Operations","permalink":"https://www.nakjunizm.com/categories/Operations/"},{"name":"ElasticSearch","slug":"Operations/ElasticSearch","permalink":"https://www.nakjunizm.com/categories/Operations/ElasticSearch/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://www.nakjunizm.com/tags/elasticsearch/"},{"name":"ordinals","slug":"ordinals","permalink":"https://www.nakjunizm.com/tags/ordinals/"},{"name":"eager_global_ordinals","slug":"eager-global-ordinals","permalink":"https://www.nakjunizm.com/tags/eager-global-ordinals/"},{"name":"doc value","slug":"doc-value","permalink":"https://www.nakjunizm.com/tags/doc-value/"}]},{"title":"Kibana Authentication with nginx proxy","slug":"Kibana_Authentication_with_nginx","date":"2018-11-08T11:11:00.000Z","updated":"2021-10-06T15:33:17.427Z","comments":true,"path":"2018/11/08/Kibana_Authentication_with_nginx/","link":"","permalink":"https://www.nakjunizm.com/2018/11/08/Kibana_Authentication_with_nginx/","excerpt":"","text":"kibana에 id/password 기반의 auth 적용 현재 운영하고 있는 클러스터는 readonly-rest plugin을 사용해서 acl을 적용해 놓은 상태이기 때문에cluster에는 security(x-pack feature)를 적용하고 싶지 않고, kibana에만 id/password를 치고 로그인을 하고 싶었습니다. 이런 경우 내가 security를 사용할 수 있는 subscription을 구매해서 가지고 있다고 하더라도 elastic에서 제공하는 방법으로는 불가능 합니다.그래서 nginx의 reverse proxy를 사용해서 kibana 앞단에 두고 로그인을 해야만 kibana를 접속 할 수 있도록 하는 방법에 대해서 포스팅 하려고 합니다. yum/apt 를 사용하여 install 해도 전혀 무방하지만 저는 특정 위치에 설치하는것을 선호 하기 때문에 직접 소스코드를 컴파일 하는 방향으로 설명 하겠습니다. # nginx 다운로드먼저 nginx gzip 파일을 다운로드 받고 압축을 해제 합니다. 123wget http://nginx.org/download/nginx-1.14.1.tar.gztar xvfz nginx-1.14.1.tar.gzcd nginx-1.14.1 pcre &amp; openssl 설치pcre와 openssl 은 기본적으로 요구하는것 같으니 해당 파일들을 다운로드 받아서 압축을 해제 합니다. (기존에 설치되어 있고, 경로를 알고 있다면 이 작업은 필요 없습니다.) 압축은 nginx 압출 푼 디렉토리에서 진행하는게 나중에 정리할때 편합니다. 1234wget ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-8.42.tar.gzwget https://www.openssl.org/source/openssl-1.1.1a.tar.gztar xvfz pcre-8.42.tar.gztar xvfz openssl-1.1.1a.tar.gz ** + 2018-11-19 추가: ** 다른 고객사의 서버 에서는 zlib도 설치하는걸 요구해서 zlib 도 추가로 설치했습니다. 12wget https://zlib.net/zlib-1.2.11.tar.gztar xvfz zlib-1.2.11.tar.gz # configure, make&amp;&amp;make install–prefix –with-pcre와 –with-openssl 옵션을 붙여서 configure 합니다. (필요하면 zlib 추가) 123./configure --prefix=/nakjunizm/util/nginx --user=nakjunizm--group=nakjunizm --with-pcre=/nakjunizm/util/nginx-1.14.1/pcre-8.42 --with-openssl=/nakjunizm/util/nginx-1.14.1/openssl-1.1.1 --with-zlib=/nakjunizm/util/nginx-1.14.1/zlib-1.2.11make&amp;&amp;make install # temp directory 및 설치 파일 삭제나중에 까먹을수도 있으니 작업한 파일들은 삭제 합시다. 12cd ..rm -rf nginx-1.14.1.tar.gz nginx-1.14.1 # id/password 기반의 authentication 설정지금 까지는 nginx 설치과정이었고 이제부터 실제로 htpd-tools를 사용하여 패스워드 파일을 만들고, nginx에 reverse proxy 설정을 하여 id/password 를 적용해 보겠습니다. # httpd-toolsnginx는 httpd-tools를 설치하고 htpasswd 명령어를 사용해서 만든 htpasswd 파일을 사용해서 로그인을 구현할 수 있습니다. 혹시 httpd-tools가 설치되어 있지 않다면 설치 후 아래와 같이 패스워드 파일을 만들어 줍시다. 12345nakjunizm@myserver:/nakjunizm/util/nginx$ sudo htpasswd -c /nakjunizm/util/nginx/userdata/htpasswd.users kibanaNew password:Re-type new password:Adding password for user kibana # nginx.conf 파일 수정server 디렉티브를 찾아서 proxy와 auth 관련 설정을 추가해 줍니다. 1234567891011121314151617vi nginx.conf-------------- server &#123; listen 5602; server_name localhost; location / &#123; proxy_pass http://127.0.0.1:5600; auth_basic &quot;Restricted&quot;; auth_basic_user_file /nakjunizm/util/nginx/userdata/htpasswd.users; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125; 위와 같이 간단히 설정을 하고 나면 http://nginx서버ip:5602 로 접속하면 127.0.0.1:5600 으로 넘겨주고, user/password 를 물어보는 팝업창이 나타납니다. # kibana.yml 파일 수정이제 kibana 5602 포트는 nginx에서 사용할 것이니 이제부터 kibana는 nginx에 설정한대로 5600번 포트로 띄울것 입니다.** 그리고 직접 5600 포트를 치고 다이렉트로 들어올 수 있으면 지금 하고 있는 모든 작업이 의미없는 작업이 될 수 있으므로 ** server.host 를 127.0.0.1 로 바꿔 줍니다 1234vi kibana.yml--------------server.port: 5600server.host: &quot;127.0.0.1&quot; # kibana &amp; nginx 재시작모든 설정이 완료되었으므로 kibana를 재시작 하고, nginx를 시작 합니다. ngingx의 경우 sbin 경로를 따로 빼서 설치하지 않았음으로 설치위치/sbin/nginx 로 실행 합니다. 1cd /nakjunizm/util/nginx/sbin ./nginx #참고 중지: ./nginx -s stop 설정새로고침: ./nginx -s reload # 접속 확인이제 http://nginx-ip:5602로 접속 해서 정상적으로 로긴 화면이 나오는지 확인 합니다. # 참고한 사이트http://nginx.org/en/docs/configure.htmlhttps://www.hugeserver.com/kb/how-secure-kibana-nginx-centos/","categories":[{"name":"Operations","slug":"Operations","permalink":"https://www.nakjunizm.com/categories/Operations/"},{"name":"ElasticSearch","slug":"Operations/ElasticSearch","permalink":"https://www.nakjunizm.com/categories/Operations/ElasticSearch/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://www.nakjunizm.com/tags/elasticsearch/"},{"name":"kibana","slug":"kibana","permalink":"https://www.nakjunizm.com/tags/kibana/"},{"name":"authentication","slug":"authentication","permalink":"https://www.nakjunizm.com/tags/authentication/"},{"name":"nginx","slug":"nginx","permalink":"https://www.nakjunizm.com/tags/nginx/"}]},{"title":"ElasticSearch cluster_block_exception","slug":"ElasticSearch_Cluster_block_exception","date":"2018-10-26T12:13:20.000Z","updated":"2021-10-06T15:33:17.438Z","comments":true,"path":"2018/10/26/ElasticSearch_Cluster_block_exception/","link":"","permalink":"https://www.nakjunizm.com/2018/10/26/ElasticSearch_Cluster_block_exception/","excerpt":"","text":"# 1. 문제 발생 운영하고 있는 서비스의 검증계 서버에서 인덱싱이 안된다는 제보가 들어와서 클라이언트 로그를 살펴보니 아래와 같습니다.1index [nakjunizm-index-20181019], type [_doc], id [153974268305904171], message [ElasticsearchException[Elasticsearch exception [type=cluster_block_exception, reason=blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];]]] # 2. 원인 ElasticSearch 도 RDB 처럼 특정 상황에서 read-only상태로 전환될 수 있습니다. 노드의 disk가 95% 이상 (default) 사용중이면 master node의 클러스터 로그에 아래와 같이 flood stage disk watermark exceeded 라고 로그를 뱉어 냅니다. 그리고 나서는 ** 모든 인덱스를 read-only ** 로 만들어 버린것을 확인할 수 있습니다.1nakjunizm-cluster-2018-10-22-1.log:[2018-10-22T06:08:27,226][WARN ][o.e.c.r.a.DiskThresholdMonitor] [node1] flood stage disk watermark [95%] exceeded on [OxyEnIXvRRuoxy7VqTf3KQ][node2][/data/elasticsearch6/nakjunizm/nodes/0] free: 11gb[4.8%], all indices on this node will be marked read-only 제 경우 node2의 디스크가 4.8% 밖에 안남았고 all indices on this node will be marked read-only 되었네요. # 3. 문제 해결 1차 시도 (Failed) 오래지난 로그파일등 쓸데없는 파일들을 정리합니다. 다시 인덱싱을 요청해 봤으나 여전히 FORBIDDEN/12/index read-only / allow delete (api) 라며 인덱싱이 불가합니다! 그 이유는 한번 read-only 상태로 들어간 인덱스는 명시적으로 read-only를 풀어주기 전까지는 디스크가 여유 있다 하더라도 다시 자동으로 돌아오지 않기 때문입니다. # 4. 문제 해결 방법 아래와 같이 명시적으로 read_only_allow_delete 를 false 로 변경 해 주면 해결 됩니다. (물론 디스크는 정리해서 80% 이하로 떨어뜨려 놓고 시도 해야 겠습니다.) 12345678PUT _settings&#123; &quot;index&quot;: &#123; &quot;blocks&quot;: &#123; &quot;read_only_allow_delete&quot;: &quot;false&quot; &#125; &#125;&#125; 만약 디스크 용량이 너~~~무 모자라서 가장 중요한 인덱스 만이라도 먼저 살려야 겠다 싶으면 아래와 같이 특정 인덱스의 셋팅을 변경 하면 됩니다. 12345678PUT your_index_name/_settings&#123; &quot;index&quot;: &#123; &quot;blocks&quot;: &#123; &quot;read_only_allow_delete&quot;: &quot;false&quot; &#125; &#125;&#125; # 참조사이트https://discuss.elastic.co/t/forbidden-12-index-read-only-allow-delete-api/110282/7https://www.elastic.co/guide/en/elasticsearch/reference/current/disk-allocator.html","categories":[{"name":"Operations","slug":"Operations","permalink":"https://www.nakjunizm.com/categories/Operations/"},{"name":"ElasticSearch","slug":"Operations/ElasticSearch","permalink":"https://www.nakjunizm.com/categories/Operations/ElasticSearch/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://www.nakjunizm.com/tags/elasticsearch/"},{"name":"read-only","slug":"read-only","permalink":"https://www.nakjunizm.com/tags/read-only/"},{"name":"FORBIDDEN/12/index","slug":"FORBIDDEN-12-index","permalink":"https://www.nakjunizm.com/tags/FORBIDDEN-12-index/"},{"name":"allow_delete","slug":"allow-delete","permalink":"https://www.nakjunizm.com/tags/allow-delete/"},{"name":"watermark","slug":"watermark","permalink":"https://www.nakjunizm.com/tags/watermark/"},{"name":"disk_flood","slug":"disk-flood","permalink":"https://www.nakjunizm.com/tags/disk-flood/"}]},{"title":"Kafka Offset 재설정 하는 방법","slug":"Kafka_Offset_Reset","date":"2018-04-23T03:17:00.000Z","updated":"2021-10-06T15:33:17.485Z","comments":true,"path":"2018/04/23/Kafka_Offset_Reset/","link":"","permalink":"https://www.nakjunizm.com/2018/04/23/Kafka_Offset_Reset/","excerpt":"","text":"# 1. Topic 확인먼저 내가 가진 토픽이 뭔지 정확히 알아야 하므로 아래 커맨드로 확인 합니다. 1234567nakjunizm@localhost[/kafka/bin]./kafka-topics.sh --list --zookeeper localhost:3181...MyTopic1MyTopic2MyTopic3__consumer_offsets... # 2. consumer all stopoffset을 수정하고자 하는 kafka topic 에 연결되어 있는 모든 consumer들을 shutdown 시킵니다. # 3. Offset 확인특정 토픽의 현재 Offset을 확인하는 방법 입니다. 123456nakjunizm@localhost[/kafka/bin]./kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list localhost:9192 -topic MyTopic1 --time -1...MyTopic1:0:216968MyTopic1:1:217575MyTopic1:2:220127MyTopic1:3:221329 각 옵션이 뜻하는것은 아래와 같습니다.–broker-list &lt;hostname:port,…, REQUIRED: The list of hostname and hostname:port&gt; port of the server to connect to.–max-wait-ms &lt;Integer: ms&gt; The max amount of time each fetch request waits. (default: 1000)–offsets &lt;Integer: count&gt; number of offsets returned (default: 1) –partitions comma separated list of partition ids. If not specified, it will find offsets for all partitions (default:)–time &lt;Long: **timestamp/-1(latest)/-2 timestamp of the offsets before that (earliest)** &gt;–topic REQUIRED: The topic to get offset from. # 4. Offset 재설정이제 offset을 재설정 할텐데, 각 consumer group의 partition별로 설정해 줘야 합니다. kafka의 offset정보는 zookeeper에서 받아오기 때문에 zookeeper cli로 설정 합니다.myconsumer 컨슈머그룹의 MyTopic1 topic 0번 partition의 offset만 100개 줄여 보겠습니다. 1234567891011nakjunizm@localhost[/zookeeper/bin]./zkCli.sh -server localhost:3181[zk: localhost:3181(CONNECTED) 0] ls /consumers/myconsumer/offsets/MyTopic1/0 1 2 3[zk: localhost:3181(CONNECTED) 0] ls /consumers/myconsumer/offsets/MyTopic1/0[][zk: localhost:3181(CONNECTED) 1] get /consumers/myconsumer/offsets/MyTopic1/0216968...[zk: localhost:3181(CONNECTED) 2] set /consumers/myconsumer/offsets/MyTopic1/0 216868 여기까지 하고 나서 kafka tool 등으로 offset을 조정한 컨슈머그룹의 해당 토픽을 보면offset이 100 줄어있고 lag이 100 늘어있는것을 확인 할 수 있습니다. # 5. consumer startup이제 consumer를 띄워서 바뀐 offset부터 마지막 처리해야 하는 logSize 까지 모두 처리하고 lag이 다시 0이 되는지 확인 합니다.","categories":[{"name":"Operations","slug":"Operations","permalink":"https://www.nakjunizm.com/categories/Operations/"},{"name":"Kafka","slug":"Operations/Kafka","permalink":"https://www.nakjunizm.com/categories/Operations/Kafka/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://www.nakjunizm.com/tags/kafka/"},{"name":"offset","slug":"offset","permalink":"https://www.nakjunizm.com/tags/offset/"},{"name":"zookeeper","slug":"zookeeper","permalink":"https://www.nakjunizm.com/tags/zookeeper/"}]},{"title":"ElasticSearch Ingest Node","slug":"Ingest_Node","date":"2018-03-09T00:17:00.000Z","updated":"2021-10-06T15:33:17.453Z","comments":true,"path":"2018/03/09/Ingest_Node/","link":"","permalink":"https://www.nakjunizm.com/2018/03/09/Ingest_Node/","excerpt":"","text":"** 이 포스트는 ELK(+beats)를 이용한 apache log visualization 의 후속 포스트로써 logstash 대신 elasticsearch 의 ingest node 를 사용하는 방법을 소개 합니다. ** filebeat-logstash-elasticsearch stack을 이용하여 kibana에서 대시보드를 구성하는 방법을 알아봤었습니다.5.X 버전에서 소개된 ** ingest node ** 를 이용하면 filebeat 에서 elasticsearch 로만 데이터를 보낼때는 grok 등의 전처리 작업이 들어가더라도 logstash 없이 elasticsearch로 바로 데이터를 보낼 수 있습니다. # ingest nodeingest node를 이용하면 filebeat의 모듈이나 logstash를 이용하지 않고도 indexing 되기 전에 전처리 과정을 넣을 수 있습니다.ingest node는 default로 모든 node는 별도의 설정을 하지 않는 이상 ingest node로 사용 될 수 있으며 전처리의 각 단계라고 볼 수 있는 processor들을 나열한 pipeline을 정의 함으로써 logstash에서 해주던 것과 비슷하게 전처리를 할 수 있습니다. # pipeline 정의기존에 logstash의 filter 부분에 넣었던 grok을 processor로 정의하여 아래와 같이 pipeline을 정의 할 수 있습니다. (Dev Tools의 Console에서 작업하는 기준 입니다.) 12345PUT _ingest/pipeline/$&#123;파이프라인이름&#125;&#123; &quot;description&quot;: &quot;&quot;, &quot;processors&quot;[]&#125; 아래는 실제 제가 적용한 pipeline의 예 입니다. grok과 remove의 두가지 processor를 등록 했고 grok의 patterns는 커스텀으로 작성 했습니다.로그 포멧을 custom으로 찍고 있는 경우 (이 포스트에서 다루는 경우와 같은)일일히 체크하면서 pattern을 만들어야 하지만 기본적으로 setting 되어 있는 default 로그 형식을 사용하는 경우에는 pre-defined 되어 있는 값을 사용하면 훨씬 편하게 적용할 수 있습니다. (pre-defined 되어있는 값들은 여기서 확인 가능 합니다.) 1234567891011121314151617181920PUT _ingest/pipeline/ssl_access_log&#123; &quot;description&quot;: &quot;Ingest pipeline for ssl log&quot;, &quot;processors&quot;: [ &#123; &quot;grok&quot;: &#123; &quot;field&quot;: &quot;message&quot;, &quot;ignore_failure&quot;: true, &quot;patterns&quot;: [ &quot;&quot;&quot;(?:%&#123;IP:xff&#125;|-) %&#123;IP:client_ip&#125; %&#123;USER:ident&#125; %&#123;USER:auth&#125; \\[%&#123;HTTPDATE:apache_timestamp&#125;\\] &quot;%&#123;WORD:method&#125; /%&#123;DATA:request_uri&#125; HTTP/%&#123;NUMBER:http_version&#125;&quot; %&#123;NUMBER:status&#125; %&#123;NUMBER:byte_response&#125; %&#123;NUMBER:byte_received&#125; %&#123;NUMBER:byte_sent&#125; %&#123;NUMBER:response_time_sec&#125;/%&#123;NUMBER:response_time_milisec&#125;&quot;&quot;&quot; ] &#125; &#125;, &#123; &quot;remove&quot;: &#123; &quot;field&quot;: &quot;message&quot; &#125; &#125; ]&#125; ** 2018-05-29 추가 **patterns 에 %{패턴:이름} 으로만 정의한 경우 해당 “패턴”에 걸린 값들을 “이름”으로 인덱싱 합니다. 하지만 인덱스 템플릿과, 맵핑에 integer나 long type으로 정의된 값들도 어떤 이유에서인지 전부 text값으로 들어가는 문제점이 발생하여 다음과 같이%{패턴:이름:인덱싱타입} 으로 정의하게 수정하자 원하는 타입으로 인덱싱 되었습니다. 123&quot;patterns&quot;: [ &quot;&quot;&quot;(?:%&#123;IP:xff&#125;|-) %&#123;IP:client_ip&#125; %&#123;USER:ident&#125; %&#123;USER:auth&#125; \\[%&#123;HTTPDATE:apache_timestamp&#125;\\] &quot;%&#123;WORD:method&#125; /%&#123;DATA:request_uri&#125; HTTP/%&#123;NUMBER:http_version&#125;&quot; %&#123;NUMBER:status:int&#125; %&#123;NUMBER:byte_response:long&#125; %&#123;NUMBER:byte_received:long&#125; %&#123;NUMBER:byte_sent:long&#125; %&#123;NUMBER:response_time_sec:long&#125;/%&#123;NUMBER:response_time_milisec:int&#125;&quot;&quot;&quot; ] # filebeat 설정pipeline을 만들었으니 이제 filebeat-&gt;logstash로 보내지 않고 바로 filebeat-&gt;elasticsearch 로 보내도록 설정 해 보겠습니다.** 일반적으로 elasticsearch 로 보낼때와의 차이점은 pipeline 을 적어 준다는 점 입니다. ** filebeat에서 자동으로 생성해 주는 index가 아닌 우리가 elasticserach에 만들어 놓은 index로 데이터를 보낼때는 setup.template.name과 setup.template.pattern도 정의해 줘야 합니다. ** elasticsearch template 생성에 관한 부분은 이 포스트를 참조하세요 ** 123456789101112131415161718192021filebeat.yml 내용중 일부filebeat.prospectors:- type: log enabled: true paths: - /data/logs/apache/*access.log* exclude_files: [&#x27;.gz$&#x27;]...setup.template.name: &quot;ssl_access&quot;setup.template.pattern: &quot;ssl_access-*&quot;setup.template.overwrite: false...output.elasticsearch: # Array of hosts to connect to. hosts: [&quot;$&#123;es_host&#125;:$&#123;es_port&#125;&quot;] index: &quot;ssl_access-%&#123;+YYYY.MM.dd&#125;&quot; pipeline: &quot;ssl_access_log&quot; # filebeat 실행1&gt; nakjunizm@filebeat호스트:/nakjunizm/util/filebeat$ ./filebeat -e -c filebeat.yml -d &quot;publish&quot; # elasticsearch 에서 확인오늘 날짜로 생성된 ssl_access_log 인덱스에 데이터가 정상적으로 인덱싱 됐는지 확인 해 봤습니다. 1GET ssl_access-2018.03.08/_search 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&#123; &quot;took&quot;: 0, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;skipped&quot;: 0, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 485, &quot;max_score&quot;: 1, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;ssl_access-2018.03.08&quot;, &quot;_type&quot;: &quot;doc&quot;, &quot;_id&quot;: &quot;KYbsBWIBGR2P1wb4_g4m&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;response_time_sec&quot;: &quot;0&quot;, &quot;offset&quot;: 28199, &quot;method&quot;: &quot;GET&quot;, &quot;auth&quot;: &quot;-&quot;, &quot;ident&quot;: &quot;-&quot;, &quot;prospector&quot;: &#123; &quot;type&quot;: &quot;log&quot; &#125;, &quot;http_version&quot;: &quot;1.1&quot;, &quot;source&quot;: &quot;/data/logs/apache/ssl_access.log.20180308&quot;, &quot;apache_timestamp&quot;: &quot;08/Mar/2018:14:03:54 +0000&quot;, &quot;request_uri&quot;: &quot;/lib/mysite.js&quot;, &quot;byte_response&quot;: &quot;3431&quot;, &quot;byte_sent&quot;: &quot;4212&quot;, &quot;@timestamp&quot;: &quot;2018-03-08T14:03:59.418Z&quot;, &quot;byte_received&quot;: &quot;3061&quot;, &quot;response_time_milisec&quot;: &quot;1316&quot;, &quot;beat&quot;: &#123; &quot;hostname&quot;: &quot;host&quot;, &quot;name&quot;: &quot;hostname&quot;, &quot;version&quot;: &quot;6.2.2&quot; &#125;, &quot;client_ip&quot;: &quot;myip&quot;, &quot;status&quot;: &quot;200&quot; &#125; &#125;,...... 정상적으로 들어와 있는것을 확인 할 수 있습니다.","categories":[{"name":"Operations","slug":"Operations","permalink":"https://www.nakjunizm.com/categories/Operations/"},{"name":"ElasticSearch","slug":"Operations/ElasticSearch","permalink":"https://www.nakjunizm.com/categories/Operations/ElasticSearch/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://www.nakjunizm.com/tags/elasticsearch/"},{"name":"kibana","slug":"kibana","permalink":"https://www.nakjunizm.com/tags/kibana/"},{"name":"logstash","slug":"logstash","permalink":"https://www.nakjunizm.com/tags/logstash/"},{"name":"elk","slug":"elk","permalink":"https://www.nakjunizm.com/tags/elk/"},{"name":"visualization","slug":"visualization","permalink":"https://www.nakjunizm.com/tags/visualization/"},{"name":"ingest_node","slug":"ingest-node","permalink":"https://www.nakjunizm.com/tags/ingest-node/"}]},{"title":"ElasticSearch license update","slug":"ElasticSearch_License_Update","date":"2018-03-08T00:56:00.000Z","updated":"2021-10-06T15:33:17.484Z","comments":true,"path":"2018/03/08/ElasticSearch_License_Update/","link":"","permalink":"https://www.nakjunizm.com/2018/03/08/ElasticSearch_License_Update/","excerpt":"","text":"2020 업데이트!** 현재는 kibana 에서 손쉽게 라이선스를 업데이트 할 수도 있으니 참고하세요 **https://www.elastic.co/guide/en/kibana/current/managing-licenses.html Elasticsearch를 운영 하면서 X-pack 에 포함되어 있는 Monitoring 이나 Devtool 등을 사용하면 얻을 수 있는 이점이 많습니다.반가운 점은 기본적인 ** Basic license를 발급받아서 무료로 사용이 가능 ** 하다는 것 입니다. # 1. Basic license 발급 받기Elasticsearch 라이센스 발급 페이지 에서 회사 email 주소를 포함한 기본적인 정보를 입력하면 email로 다음 정보를 받을수 있습니다. 라이센스 다운로드 링크 라이센스 등록 가이드 링크 basic 라이센스는 max 100개의 노드에 사용 가능 하며 무료입니다.기본적으로 Monotoring, Devtool 정도는 사용할 수 있고자세한 사항은 subscription page 참고 하세요. # 2. 발급받은 license를 cluster에 등록하기12345678910To download your license, please go to:--&gt; http://license.elastic.co/registration/download/라이센스hash값For license installation instructions:Elasticsearch 6.x -- https://www.elastic.co/guide/en/x-pack/current/installing-license.htmlElasticsearch 5.x -- https://www.elastic.co/guide/en/x-pack/5.6/installing-license.htmlElasticsearch 2.x -- https://www.elastic.co/guide/en/marvel/current/license-management.htmlElasticsearch 1.x -- Use license code &#x27;1010&#x27; to register 메일 본문에 보면 위와 같은 내용이 들어 있습니다.다운로드 링크를 누르면 2.X, 5.X이상의 라이센스를 선택해서 받을 수 있는 페이지로 연결 되고 json 파일로 된 라이센스 파일을 다운로드 받을 수 있습니다. 발급 받은 라이센스는 _license api 호출을 통해등록 가능 합니다. 1234# 1.x&gt; curl -XPUT &#x27;http://&lt;host&gt;:&lt;port&gt;/_licenses&#x27; -d @license.json# 2.x&gt; curl -XPUT &#x27;http://&lt;host&gt;:&lt;port&gt;/_license&#x27; -d @license.json ES 1.x 와 2.x 는 _licenses와 _license의 단수/복수 차이만 있고 위에서 다운로드 받은 json 파일을 등록할 수 있습니다.5.0 부터 xpack 에 포함되어 졌으므로 api 호출 주소도 _xpack/license 로 변경 되었고, Content-Type에 application/json 을 명시해 줘야 되는 점을 제외하면 기본적으로 등록 하는 방식은 이전 버전과 동일 합니다. 123# 5.x 6.x&gt; curl -XPUT -u elastic &#x27;http://&lt;host&gt;:&lt;port&gt;/_xpack/license&#x27; -H &quot;Content-Type: application/json&quot; -d @license.json # License 연장 시 주의할 점라이센스 연장 시 기존과 동일한 등급 (Basic to Basic, Platinum to Platinum 등 ) 이 아닌 다른 등급으로 새 라이센스를 받아서 등록하는 경우 아래와 같이 ** ?acknowledge=true ** 를 뒤에 붙여줘야 합니다. 1234# 2.x&gt; curl -XPUT &#x27;http://&lt;host&gt;:&lt;port&gt;/_license?acknowledge=true&#x27; -d @license.json# 5.x 6.x&gt; curl -XPUT -u elastic &#x27;http://&lt;host&gt;:&lt;port&gt;/_xpack/license?acknowledge=true&#x27; -H &quot;Content-Type: application/json&quot; -d @license.json # Tip: json 파일을 서버에 남기지 않고 License 등록 하기Devtool (구 Sense)를 이용하여 바로 License를 등록 하고 싶거나 서버에 파일을 넣기 번거로운 경우 (운영계 VM에 접속하려면 절차가 복잡한 경우 등)다운 받은 license 파일을 직접 열어서 등록 할 수 있습니다.간단히 License파일을 열어서 전체 내용을 복사하고 request를 날리면 됩니다. 1234567891011121314# devtool 5.x 기준POST _xpack/license&#123; &quot;license&quot;: &#123; &quot;uid&quot;:&quot;893361dc-9749-4997-93cb-802e3d7fa4xx&quot;, &quot;type&quot;:&quot;basic&quot;, &quot;issue_date_in_millis&quot;:1411948800000, &quot;expiry_date_in_millis&quot;:1914278399999, &quot;max_nodes&quot;:1, &quot;issued_to&quot;:&quot;issuedTo&quot;, &quot;issuer&quot;:&quot;issuer&quot;, &quot;signature&quot;:&quot;xx&quot; &#125;&#125;","categories":[{"name":"Operations","slug":"Operations","permalink":"https://www.nakjunizm.com/categories/Operations/"},{"name":"ElasticSearch","slug":"Operations/ElasticSearch","permalink":"https://www.nakjunizm.com/categories/Operations/ElasticSearch/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://www.nakjunizm.com/tags/elasticsearch/"},{"name":"license","slug":"license","permalink":"https://www.nakjunizm.com/tags/license/"}]},{"title":"System Event Notification Service 준비 중 해결 방법","slug":"SystemEventNotificationService","date":"2018-01-30T01:43:00.000Z","updated":"2021-10-06T15:33:17.465Z","comments":true,"path":"2018/01/30/SystemEventNotificationService/","link":"","permalink":"https://www.nakjunizm.com/2018/01/30/SystemEventNotificationService/","excerpt":"","text":"Windows 2012/R2 # 증상사용자가 로그아웃을 시도했는데 “System Event Notification Service 준비 중….” 메세지가 화면에서 뱅글뱅글 돌고 로그아웃은 되지 않는 경우 # 해결운영중인 시스템에서 ** 재부팅을 하지 않고 ** 해결 가능한 방법 입니다. 1sc queryex sens 를 치면 System Event Notification Service 의 PID를 확인 할 수 있습니다.해당 PID를 강제로 종료시켜야 합니다. 1taskkill /PID 646 /F","categories":[{"name":"Operations","slug":"Operations","permalink":"https://www.nakjunizm.com/categories/Operations/"},{"name":"Windows","slug":"Operations/Windows","permalink":"https://www.nakjunizm.com/categories/Operations/Windows/"}],"tags":[{"name":"windows2012","slug":"windows2012","permalink":"https://www.nakjunizm.com/tags/windows2012/"},{"name":"SENS","slug":"SENS","permalink":"https://www.nakjunizm.com/tags/SENS/"},{"name":"System Event Notification Service","slug":"System-Event-Notification-Service","permalink":"https://www.nakjunizm.com/tags/System-Event-Notification-Service/"}]},{"title":"Singleton Pattern","slug":"Singleton_Pattern","date":"2018-01-05T11:48:00.000Z","updated":"2021-10-06T15:33:17.437Z","comments":true,"path":"2018/01/05/Singleton_Pattern/","link":"","permalink":"https://www.nakjunizm.com/2018/01/05/Singleton_Pattern/","excerpt":"","text":"# Singleton Pattern싱글톤 패턴(Singleton pattern)은 클래스의 객체화를 한번으로 제한함으로써 프로그램 전반에 걸쳐서 같은 객체에 접근하도록 하는 패턴 입니다.자주 접하는 대표적인 예로는 logger 가 있겠네요.아래는 log4j와 slf4j(logback) 사용 예 입니다. new()를 이용해서 객체를 생성하지 않고 정적 팩토리 메소드를 이용해서 객체를 생성하는것을 확인 할 수 있습니다. 12345//log4jprivate final Logger logger = Logger.getLogger(Example.class);//slf4j(logback)private final Logger logger= LoggerFactory.getLogger(Example.class); 싱글톤 패턴을 구현하는 방법은 여러가지가 있는데 그중에서도 효과적인 방법 네가지만 알아보도록 하겠습니다. 1. Eager initialization가장 기본적인 싱글톤 패턴의 구현방법으로 싱글스레드 프로그래밍에서 간단하게 사용할때 사용가능합니다.**핵심은 **- 생성자를 private으로 만들어서 외부에서 new()로 생성불가능하게 하고- 클래스 내에 private static final로 자기 자신을 instance화 해서 미리 만들어 놓습니다.- 외부에서는 public static으로 공개된 getInstance() 메소드를 통해서 미리 만들어 놓은 instance를 받아서 쓰게 됩니다. 1234567891011public class EagerInitializedSingleton &#123; private static final EagerInitializedSingleton instance = new EagerInitializedSingleton(); //private constructor to avoid client applications to use constructor private EagerInitializedSingleton()&#123;&#125; public static EagerInitializedSingleton getInstance()&#123; return instance; &#125;&#125; 2. Lazy Initialization &amp; thread safe way of Lazy Initialization앞에서 살펴본 Eager initialization 방식의 단점중에 한가지는 static 변수로 객체를 미리 다 할당해 놓기 때문에 아무도 해당 객체를 호출하지 않더라도 불필요하게 메모리에 올라가게 됩니다. 어짜피 요즘환경에서 실무에서는 못쓰는 방식이라 신경쓰일 만큼의 대용량 객체가 생성되진 않겠지만 예전 싱글쓰레드에서 메모리에 민감한 사람들이 아래 Lazy Initialization idiom을 생각해 내지 않았나 하고 개인적으로 생각 됩니다 ㅎㅎ핵심은- 여전히 private으로 생성자를 만들어놔서 외부에서 new()로 객체를 생성 하는것은 제한합니다.- 이번에는 private static으로 선언한 클래스자신의 변수인 instance 를 바로 new() 로 생성해 놓지 않습니다.- public static으로 외부에서 호출하는 getInstance()메서드 내부에서 현재 instance 객체가 null이면 new()를 하고 그게 아니면 만들어진 instance를 돌려줍니다.즉, 미리 싱글톤 객체를 생성해 놓는것이 아니라 누군가 최초에 한번 호출을 하면 그제서야 객체를 생성 하는것 입니다.하지만 null 체크하는부분에서 ** 여러 쓰레드가 동시에 접근해 버리면 여러개의 객체가 생성되는 문제 ** 가 있고 이를 해결하려면 간단히 getInstance() 메서드에 synchronized를 붙여서 동기화시키면 쓰레드 쎄잎 한 싱글톤 클래스를 생성할 수 있습니다. 12345678910111213public class LazyInitializedSingleton &#123; private static LazyInitializedSingleton instance; private LazyInitializedSingleton()&#123;&#125; public static LazyInitializedSingleton getInstance()&#123; if(instance == null)&#123; //이부분이 Thread safe 하지 않게되는 원인 입니다. instance = new LazyInitializedSingleton(); &#125; return instance; &#125;&#125; 12345678910111213public class ThreadSafeSingleton &#123; private static ThreadSafeSingleton instance; private ThreadSafeSingleton()&#123;&#125; public static synchronized ThreadSafeSingleton getInstance()&#123; if(instance == null)&#123; instance = new ThreadSafeSingleton(); &#125; return instance; &#125;&#125; 참고로 getInstance() 메소드 전체를 동기화 시킴으로써 성능적으로 손해보는걸 조금이라도 줄여보겠다!라고 한다면 아래와같이 null일때만 동기화 시키는 방법도 있습니다. (double-checked locking idiom) 3. Enum Singleton이 방법은 이펙티브자바의 저자인 조슈아 블로크 형님께서 java1.5 이상에서 싱글톤을 구현하는 가장 좋은 방법이라고 소개한 방식입니다. 간결하면서도 직렬화가 자동으로 처리되고 리플렉션공격에도 안전 합니다. 12345678public enum EnumSingleton &#123; INSTANCE; public static void doSomething()&#123; //do something &#125;&#125; 음… 이걸 어떻게 쓰라는거지………..??!! 사실 이번 포스트를 쓰게 된 계기이기도 합니다 ㅎㅎ 저도 매번 헷갈려서..어렵게 생각할것 없이 그냥 아래와 같이 일반 클래스 생성하듯이 생성하고 호출하면 됩니다. 12EnumSingleton enumSingleton = EnumSingleton.INSTANCE;enumSingleton.doSomthing(); 4. Bill Pugh Singleton마지막으로 Bill Pugh 라는 분이 만들어낸 싱글턴 패턴의 구현 입니다.JVM이 클래스를 로드하는 방식&amp;순서를 이용해서 싱글톤을 구현한 idiom 이며 아래 JLS(Java Language Spec)에 따라https://docs.oracle.com/javase/specs/jls/se8/html/jls-12.html#jls-12.4.1https://docs.oracle.com/javase/specs/jls/se8/html/jls-12.html#jls-12.4.2https://docs.oracle.com/javase/specs/jls/se8/html/jls-8.html#jls-8.1.3inner클래스는 outter클래스가 로드될때 같이 로드되지 않고,클래스가 객체화 될때는 fully initialized 되기 전까지는 사용할 수 없다는 점을 이용했다고 합니다. 즉, inner클래스(holder)가 outter클래스(실제 싱글톤으로 사용하고 싶은 클래스)의 객체를 완전히 생성하기 전까지는 다른 쓰레드에서는 해당 클래스를 접근할 수 없고 final로 선언되어있으므로 이후 접근시에는 같은 객체를 계속 반납해 주는 방식 입니다.다른 lazy initialization 방식들과 눈에 띄게 다른점은 static 변수를 가지고 있지 않다는 점 (다른패턴에서는 static변수를 미리 만들어 놓고 나중에 사용할 때 객체생성 했었죠) inner class에 private static final 변수를 가지고 있음. 가장 널리 이용되는 싱글톤패턴의 구현방법이며 가장 빠르게 동작하는 싱글톤 패턴의 구현 방식으로도 알려져 있습니다.하지만 직렬화를 위해 추가로 작성해 줘야 할 부분이 있고, 리플렉션공격에 취약한 단점이 있습니다. 12345678910111213141516public class SingletonBillPugh &#123; /* private constructor */ private SingletonBillPugh() &#123; &#125; /* static inner class */ private static class LazyHolder&#123; private static final SingletonBillPugh INSTANCE = new SingletonBillPugh(); &#125; /* get instance of SingletonBillPugh */ public static SingletonBillPugh getInstance()&#123; return LazyHolder.INSTANCE; &#125;&#125; 지금까지 유명한 싱글톤 패턴의 이디엄들을 살펴 봤는데요누군가에게는 도움이 되셨으면 좋겠습니다. 참조 자료https://www.journaldev.com/1377/java-singleton-design-pattern-best-practices-exampleshttps://dzone.com/articles/java-singletons-using-enumhttps://en.wikipedia.org/wiki/Initialization-on-demand_holder_idiomhttp://www.javaquery.com/2016/07/bill-pugh-initialization-on-demand.html","categories":[{"name":"Development","slug":"Development","permalink":"https://www.nakjunizm.com/categories/Development/"},{"name":"java","slug":"Development/java","permalink":"https://www.nakjunizm.com/categories/Development/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://www.nakjunizm.com/tags/java/"},{"name":"pattern","slug":"pattern","permalink":"https://www.nakjunizm.com/tags/pattern/"},{"name":"singleton","slug":"singleton","permalink":"https://www.nakjunizm.com/tags/singleton/"}]},{"title":"ELK(+beats)를 이용한 apache log visualization","slug":"ELK_Apache_Log_Visualization","date":"2018-01-01T02:23:00.000Z","updated":"2021-10-06T15:33:17.493Z","comments":true,"path":"2018/01/01/ELK_Apache_Log_Visualization/","link":"","permalink":"https://www.nakjunizm.com/2018/01/01/ELK_Apache_Log_Visualization/","excerpt":"","text":"file beats+logstash+elasticsearch+kibana를 이용하여apache 로그에서 의미있는 데이터를 시각화 하는 방법을 알아보겠습니다. # 설치Elastic stack 설치는 대부분 압축 해제하고 yml 로 된 설정파일을 수정하는것으로 끝납니다.Elastic Search의 경우 OS 셋팅변경이 필요할 수도 있으니 여기를 참조하세요. # File Beat 설정12345678910filebeat.prospectors:- type: log enabled: true paths: - /nakjunizm/logs/platform/apache/*access.log* exclude_files: [&#x27;.gz$&#x27;]#----------------------------- Logstash output --------------------------------output.logstash: # The Logstash hosts hosts: [&quot;logstash호스트:5043&quot;] filebeat의 prospector는 수집기 각각을 나타냅니다. 설정 이름은 상당히 직관적 입니다.위 설정대로 저는 /nakjunizm/logs/platform/apache/access.log 를 수집하는데 .gz 파일은 수집하지 않을것 입니다. # Logstash 설정 part1일단 beats input을 받아서 stdout으로 출력되는 간단한 설정파일 작성해 보겠습니다.logstash home 에 filebeat-pipeline 이라는 설정파일을 하나 만들어서 아래 값을 넣습니다. 1nakjunizm@logstash호스트:/nakjunizm/util/logstash$ vi filebeat-pipeline.conf 12345678910input &#123; beats &#123; port =&gt; &quot;5043&quot; &#125;&#125;#filter &#123;#&#125;output &#123; stdout &#123; codec =&gt; rubydebug &#125;&#125; 기본적으로 logstash의 설정파일은 위의 구조를 가지고 있습니다input : input source로 db, file, beats 등등 많은 형식을 source로 가질 수 있습니다. 여기로 가보시면 엄청나게 많은 input plugin이 있는것을 확인하실수 있습니다. filter : logstash의 강력한 기능중의 하나 입니다. input으로 들어온 데이터를 aggregate, mutate, grok 등 각각의 이벤트에 수정을 가할 수 있습니다. output : filter까지 마친 데이터를 output plugin을 통해 보낼 수 있습니다. 제 목표는 Elastic Search 로 보내는 것 입니다. 지금은 확인을 위해 console에 결과를 출력하도록 stdout 플러그인을 사용하겠습니다. # beats-logstash 정상동작 확인위와같이 간단히 설정을 마치고 난 뒤 정상적으로 beat에서 데이터를 보내주는지 확인해 봅시다.저는 logstash와 filebeat를 각각 다른 호스트에 설치하였고 아래와깉이 logstash를 구동시켜서 정상적으로 떴는지 확인 한 후 filebeat호스트에서 filebeat를 실행 시켰습니다. 12nakjunizm@logstash호스트:/nakjunizm/util/logstash$ bin/logstash -f filebeat-pipeline.confnakjunizm@filebeat호스트:/nakjunizm/util/filebeat$ ./filebeat -e -c filebeat.yml -d &quot;publish&quot; 1234567891011121314151617&quot;beat&quot; =&gt; &#123; &quot;hostname&quot; =&gt; &quot;filebeat호스트&quot;, &quot;version&quot; =&gt; &quot;6.1.0&quot;, &quot;name&quot; =&gt; &quot;filebeat호스트&quot;&#125;,&quot;host&quot; =&gt; &quot;filebeat호스트&quot;,&quot;message&quot; =&gt; &quot;- some.remote.ip.19 - - [22/Dec/2017:10:57:14 +0000] \\&quot;POST /api1/v1/auth/token HTTP/1.1\\&quot; 200 104 4742 5189 0/14987&quot;,&quot;@version&quot; =&gt; &quot;1&quot;,&quot;offset&quot; =&gt; 520032,&quot;tags&quot; =&gt; [ [0] &quot;beats_input_codec_plain_applied&quot;],&quot;@timestamp&quot; =&gt; 2017-12-26T02:17:56.028Z,&quot;prospector&quot; =&gt; &#123; &quot;type&quot; =&gt; &quot;log&quot;&#125;,&quot;source&quot; =&gt; &quot;/nakjunizm/logs/platform/apache/ssl_access.log.20171222&quot; 정상적으로 출력되는것을 확인할 수 있습니다 # Logstash 설정 part2** filebeat ** 와 ** logstash ** 가 정상적으로 연결되었고 동작하는것을 확인 했으니 이제 filter를 추가해서 로그파일과 ES index mapping 간의 관계를 설정 해 주겠습니다.위의 결과에서 보면 message에 로그 한줄이 그대로 들어가 있는걸 확인할 수 있는데 그 message를 각각의 필드로 쪼개서 맵핑하는 작업입니다. %{패턴:맵핑} 구조로 되어 있고 대부분의 로그는 패턴으로 이미 정의되어 있으니 링크를 확인 해 보시고 혹시라도 내가 직접 만든 어플리케이션 로그라서 패턴이 전혀 정의되어 있지 않는 경우에는 regex로 직접 정의할 수도 있습니다. 1nakjunizm@logstash호스트:/nakjunizm/util/logstash$ vi filebeat-pipeline.conf 12345678910111213input &#123; beats &#123; port =&gt; &quot;5043&quot; &#125;&#125;filter &#123; grok &#123; match =&gt; [ &quot;message&quot;, &#x27;(?:%&#123;IP:xff&#125;|-) %&#123;IP:client_ip&#125; %&#123;USER:ident&#125; %&#123;USER:auth&#125; \\[%&#123;HTTPDATE:apache_timestamp&#125;\\] \\&quot;%&#123;WORD:method&#125; /%&#123;DATA:request_uri&#125; HTTP/%&#123;NUMBER:http_version&#125;\\&quot; %&#123;NUMBER:status&#125; %&#123;NUMBER:byte_response&#125; %&#123;NUMBER:byte_received&#125; %&#123;NUMBER:byte_sent&#125; %&#123;NUMBER:response_time_sec&#125;/%&#123;NUMBER:response_time_milisec&#125;&#x27; ] &#125;&#125;output &#123; stdout &#123; codec =&gt; rubydebug &#125;&#125; https://grokdebug.herokuapp.com 에서 한단어씩 끊어가면서 제대로 체크 되는지 확인하는데, grokdebug 홈페이지에서 더블쿼테이션은 이스케이프 해줘야(&quot;) 정상적으로 동작하니 주의하세요!** 확인을 마치고 실제로 filter에 적용할 때는 내용안에 더블쿼테이션이 있으므로 싱글쿼테이션으로 감싸줘 합니다.**저는 apache로그에 x-forwarded-for라던지 응답시간 초/밀리초 등을 추가해서 위와같은 삽질을 좀 했는데,** default apache로그 설정을 사용하는 시스템 ** 에서는 간단히 아래와 같이 코어 패턴으로 처리하거나(%{COMBINEDAPACHELOG}등과 같이 미리 정의된 코어 패턴들은 여기에서 확인 가능합니다.)1match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;COMBINEDAPACHELOG&#125;&quot; &#125; filebeat에서 logstash로 보내는 과정을 생략하고!! ** filebeat의 apache2모듈 ** 을 사용해서 바로 elasticsearch로 로그데이터를 보낼수도 있으니 아래 링크들을 참조해 보시면 좋을것 같습니다. 심지어 filebeat의 apache2모듈은 kibana에 기본적인 시각화 차트들과 대쉬보드까지 제공해주는 강력한 모듈 입니다. apache2이외에도 많은 filebeat 모듈들이 존재하니 확인해보세요!!https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-module-apache2.html # filter 가 잘 적용 됐는지 확인1nakjunizm@logstash호스트:/nakjunizm/util/logstash-6.1.1$ bin/logstash -f filebeat-pipeline.conf 1234567891011121314151617181920212223242526272829303132&#123; &quot;ident&quot; =&gt; &quot;-&quot;, &quot;request_uri&quot; =&gt; &quot;api2/v1/notification?type=UNREAD&quot;, &quot;byte_received&quot; =&gt; &quot;2100&quot;, &quot;byte_response&quot; =&gt; &quot;55&quot;, &quot;offset&quot; =&gt; 222231, &quot;method&quot; =&gt; &quot;GET&quot;, &quot;http_version&quot; =&gt; &quot;1.1&quot;, &quot;source&quot; =&gt; &quot;/nakjunizm/logs/platform/apache/ssl_access.log.20171218&quot;, &quot;@timestamp&quot; =&gt; 2017-12-26T08:21:15.686Z, &quot;auth&quot; =&gt; &quot;-&quot;, &quot;prospector&quot; =&gt; &#123; &quot;type&quot; =&gt; &quot;log&quot; &#125;, &quot;response_time_milisec&quot; =&gt; &quot;13303&quot;, &quot;response_time_sec&quot; =&gt; &quot;0&quot;, &quot;beat&quot; =&gt; &#123; &quot;name&quot; =&gt; &quot;filebeat호스트&quot;, &quot;version&quot; =&gt; &quot;6.1.0&quot;, &quot;hostname&quot; =&gt; &quot;filebeat호스트&quot; &#125;, &quot;tags&quot; =&gt; [ [0] &quot;beats_input_codec_plain_applied&quot; ], &quot;apache_timestamp&quot; =&gt; &quot;18/Dec/2017:06:40:18 +0000&quot;, &quot;host&quot; =&gt; &quot;filebeat호스트&quot;, &quot;byte_sent&quot; =&gt; &quot;885&quot;, &quot;message&quot; =&gt; &quot;- some.remote.ip.171 - - [18/Dec/2017:06:40:18 +0000] \\&quot;GET /api2/v1/notification?type=UNREAD HTTP/1.1\\&quot; 200 55 2100 885 0/13303&quot;, &quot;status&quot; =&gt; &quot;200&quot;, &quot;@version&quot; =&gt; &quot;1&quot;, &quot;client_ip&quot; =&gt; &quot;some.remote.ip.171&quot;&#125; filter를 설정하기 전에 message에 모든 내용이 다 들어오던것과는 달리, message 의 내용을 각각 정의한대로 잘 쪼개서 출력해 주는것을 확인 할 수 있습니다. # ElasticSearch 로 보내도록 output plugin 설정1nakjunizm@logstash호스트:/nakjunizm/util/logstash$ vi filebeat-pipeline.conf 12345678910111213141516input &#123; beats &#123; port =&gt; &quot;5043&quot; &#125;&#125;filter &#123; grok &#123; match =&gt; [ &quot;message&quot;, &#x27;(?:%&#123;IP:xff&#125;|-) %&#123;IP:client_ip&#125; %&#123;USER:ident&#125; %&#123;USER:auth&#125; \\[%&#123;HTTPDATE:apache_timestamp&#125;\\] \\&quot;%&#123;WORD:method&#125; /%&#123;DATA:request_uri&#125; HTTP/%&#123;NUMBER:http_version&#125;\\&quot; %&#123;NUMBER:status&#125; %&#123;NUMBER:byte_response&#125; %&#123;NUMBER:byte_received&#125; %&#123;NUMBER:byte_sent&#125; %&#123;NUMBER:response_time_sec&#125;/%&#123;NUMBER:response_time_milisec&#125;&#x27; ] remove_field =&gt; [ message ] &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; &quot;elasticsearch호스트:9200 &#125;&#125; message 필드는 더이상 필요없으니 remove_field 했고, output은 elasticsearch로 보내도록 설정했습니다.이 설정 그대로 실행시켜보면 elasticsearch 에 logstash-* 로 자동으로 인덱스가 생성 되고 데이터가 잘 들어가는것을 확인 할 수 있습니다. # ElasticSearch Template 생성자동으로 생성된 logstash-* 인덱스를 살펴보면 불필요하게 대부분의 필드를 인덱싱 하는것을 확인할 수 있습니다. 키워드 검색의 용도로 저장하는것이 아니기 때문에 각각의 필드를 형태소 분석기에 돌릴 필요는 없으니 template을 생성해 보겠습니다. # kibana의 devtool에서 현재 mapping 상태 확인1GET logstash-2017.12.26/_mappings 123456789101112....&quot;apache_timestamp&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;norms&quot;: false, &quot;fields&quot;: &#123; &quot;keyword&quot;: &#123; &quot;type&quot;: &quot;keyword&quot;, &quot;ignore_above&quot;: 256 &#125; &#125;&#125;.... logstash-yyyy.MM.dd index에 doc type과 _default type 두가지의 type이 생성되어 있는것을 확인할 수 있고,대부분의 필드는 위와같은 형식으로 되어있음을 확인할 수 있습니다.doc type에 있는값 들 중에서 제가 분석하고 싶은 field들을 먼저 뽑아보면 request_uri client_ip response_time_sec/response_time_milisec status host 정도가 있을것 같은데. 위 필드를 제외한 나머지 필드는 인덱싱 하지 않거나keyword 검색정도만 가능하게 설정 하겠습니다. ES2.X 에서는 아래와같이 “type” : “string”, “index” : “not_analyzed” 를 이용하였지만5.X 이상부터는 “type” : “keyword”, “index” : true 를 통해 설정 가능합니다. 123456789101112131415ES2.x&#123; &quot;foo&quot;: &#123; &quot;type&quot; : &quot;string&quot;, &quot;index&quot;: &quot;not_analyzed&quot; &#125;&#125;ES5.x 이상&#123; &quot;foo&quot;: &#123; &quot;type&quot;: &quot;keyword&quot;, &quot;index&quot;: true &#125;&#125; 위 조건을 모두 충족시키는 템플릿을 아래와 같이 만들어 봤습니다. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137&#123; &quot;order&quot;: 0, &quot;index_patterns&quot;: &quot;ssl_access-*&quot;, &quot;settings&quot;: &#123; &quot;index&quot;: &#123; &quot;analysis&quot;: &#123; &quot;filter&quot;: &#123;&#125;, &quot;analyzer&quot;: &#123;&#125; &#125; &#125; &#125;, &quot;mappings&quot;: &#123; &quot;doc&quot;: &#123; &quot;properties&quot;: &#123; &quot;@timestamp&quot;: &#123; &quot;type&quot;: &quot;date&quot; &#125;, &quot;@version&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;apache_timestamp&quot;: &#123; &quot;type&quot;: &quot;date&quot;, &quot;format&quot;: &quot;dd/MMM/yyyy:HH:mm:ss Z&quot; &#125;, &quot;auth&quot;: &#123; &quot;type&quot;: &quot;keyword&quot;, &quot;index&quot;: true &#125;, &quot;beat&quot;: &#123; &quot;properties&quot;: &#123; &quot;hostname&quot;: &#123; &quot;type&quot;: &quot;keyword&quot;, &quot;index&quot;: true &#125;, &quot;name&quot;: &#123; &quot;type&quot;: &quot;keyword&quot;, &quot;index&quot;: true &#125;, &quot;version&quot;: &#123; &quot;type&quot;: &quot;keyword&quot;, &quot;index&quot;: true &#125; &#125; &#125;, &quot;byte_received&quot;: &#123; &quot;type&quot;: &quot;integer&quot; &#125;, &quot;byte_response&quot;: &#123; &quot;type&quot;: &quot;integer&quot; &#125;, &quot;byte_sent&quot;: &#123; &quot;type&quot;: &quot;integer&quot; &#125;, &quot;client_ip&quot;: &#123; &quot;type&quot;: &quot;ip&quot; &#125;, &quot;geoip&quot;: &#123; &quot;dynamic&quot;: &quot;true&quot;, &quot;properties&quot;: &#123; &quot;ip&quot;: &#123; &quot;type&quot;: &quot;ip&quot; &#125;, &quot;latitude&quot;: &#123; &quot;type&quot;: &quot;half_float&quot; &#125;, &quot;location&quot;: &#123; &quot;type&quot;: &quot;geo_point&quot; &#125;, &quot;longitude&quot;: &#123; &quot;type&quot;: &quot;half_float&quot; &#125; &#125; &#125;, &quot;host&quot;: &#123; &quot;type&quot;: &quot;keyword&quot;, &quot;index&quot;: true &#125;, &quot;http_version&quot;: &#123; &quot;type&quot;: &quot;half_float&quot; &#125;, &quot;ident&quot;: &#123; &quot;type&quot;: &quot;keyword&quot;, &quot;index&quot;: true &#125;, &quot;message&quot;: &#123; &quot;type&quot;: &quot;keyword&quot;, &quot;index&quot;: false &#125;, &quot;method&quot;: &#123; &quot;type&quot;: &quot;keyword&quot;, &quot;index&quot;: true &#125;, &quot;offset&quot;: &#123; &quot;type&quot;: &quot;long&quot; &#125;, &quot;prospector&quot;: &#123; &quot;properties&quot;: &#123; &quot;type&quot;: &#123; &quot;type&quot;: &quot;keyword&quot;, &quot;index&quot;: true &#125; &#125; &#125;, &quot;request_uri&quot;: &#123; &quot;type&quot;: &quot;keyword&quot;, &quot;index&quot;: true &#125;, &quot;response_time_milisec&quot;: &#123; &quot;type&quot;: &quot;integer&quot; &#125;, &quot;response_time_sec&quot;: &#123; &quot;type&quot;: &quot;integer&quot; &#125;, &quot;source&quot;: &#123; &quot;type&quot;: &quot;keyword&quot;, &quot;index&quot;: true &#125;, &quot;status&quot;: &#123; &quot;type&quot;: &quot;integer&quot; &#125;, &quot;tags&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;norms&quot;: false, &quot;fields&quot;: &#123; &quot;keyword&quot;: &#123; &quot;type&quot;: &quot;keyword&quot;, &quot;ignore_above&quot;: 256 &#125; &#125; &#125;, &quot;xff&quot;: &#123; &quot;type&quot;: &quot;ip&quot; &#125; &#125; &#125; &#125;&#125; # 작성한 템플릿 ES에 등록위에서 작성한 json을 file로 만들어서 아래와 같이 실행해도 되지만 (ssl_access 라는 이름으로 템플릿 생성) 1curl -XPUT elastic호스트:포트/_template/ssl_access -d@ssl_access.json 저는 일단 kibana의 DevTools에서 직접 돌렸습니다. 12345&#123; &quot;order&quot;: 0, &quot;index_patterns&quot;: &quot;ssl_access-*&quot;, .... 위에 작성한 내용과 동일 ...&#125; # logstash 설정 part3이제 모든 준비를 완료 했으니 logstash의 설정을 마지막으로 바꿔보겠습니다. 1nakjunizm@logstash호스트:/nakjunizm/util/logstash$ vi filebeat-pipeline.conf 1234567891011121314151617input &#123; beats &#123; port =&gt; &quot;5043&quot; &#125;&#125;filter &#123; grok &#123; match =&gt; [ &quot;message&quot;, &#x27;(?:%&#123;IP:xff&#125;|-) %&#123;IP:client_ip&#125; %&#123;USER:ident&#125; %&#123;USER:auth&#125; \\[%&#123;HTTPDATE:apache_timestamp&#125;\\] \\&quot;%&#123;WORD:method&#125; /%&#123;DATA:request_uri&#125; HTTP/%&#123;NUMBER:http_version&#125;\\&quot; %&#123;NUMBER:status&#125; %&#123;NUMBER:byte_response&#125; %&#123;NUMBER:byte_received&#125; %&#123;NUMBER:byte_sent&#125; %&#123;NUMBER:response_time_sec&#125;/%&#123;NUMBER:response_time_milisec&#125;&#x27; ] remove_field =&gt; [ message ] &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; &quot;elasticsearch호스트:9200&quot; index =&gt; &quot;ssl_access-%&#123;+YYYY.MM.dd&#125;&quot; &#125;&#125; # 잘 동작하는지 확인앞의 모든 설정을 마친 상태로 logstash를 구동하고, filebeat의 data폴더아래있는 데이터를 삭제한 후 (offset정보등이 들어있는)filebeat재구동해서 ElasticSeach에 데이터를 넣고 잘 동작하는지 확인 합니다. 1GET ssl_access-2017.12.26/_search 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&#123; &quot;took&quot;: 2, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;skipped&quot;: 0, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 25259, &quot;max_score&quot;: 1, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;ssl_access-2017.12.27&quot;, &quot;_type&quot;: &quot;doc&quot;, &quot;_id&quot;: &quot;6AorlmAB1NCOl3BsnBUx&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;method&quot;: &quot;POST&quot;, &quot;ident&quot;: &quot;-&quot;, &quot;apache_timestamp&quot;: &quot;04/Dec/2017:03:18:45 +0000&quot;, &quot;byte_received&quot;: &quot;4710&quot;, &quot;response_time_sec&quot;: &quot;0&quot;, &quot;client_ip&quot;: &quot;some.remote.ip.19&quot;, &quot;beat&quot;: &#123; &quot;version&quot;: &quot;6.1.0&quot;, &quot;name&quot;: &quot;filebeat호스트&quot;, &quot;hostname&quot;: &quot;filebeat호스트&quot; &#125;, &quot;response_time_milisec&quot;: &quot;3457&quot;, &quot;byte_response&quot;: &quot;66&quot;, &quot;status&quot;: &quot;200&quot;, &quot;source&quot;: &quot;/nakjunizm/logs/platform/apache/ssl_access.log.20171204&quot;, &quot;byte_sent&quot;: &quot;4996&quot;, &quot;prospector&quot;: &#123; &quot;type&quot;: &quot;log&quot; &#125;, &quot;@version&quot;: &quot;1&quot;, &quot;http_version&quot;: &quot;1.1&quot;, &quot;offset&quot;: 61270, &quot;tags&quot;: [ &quot;beats_input_codec_plain_applied&quot; ], &quot;request_uri&quot;: &quot;api1/v1/auth/token&quot;, &quot;@timestamp&quot;: &quot;2017-12-27T04:12:07.575Z&quot;, &quot;auth&quot;: &quot;-&quot;, &quot;host&quot;: &quot;filebeat호스트&quot; &#125; &#125;, ..... # Kibana 에서 시각화 하기ElasticSearch에 내가 원하는 형태로 데이터가 들어오고 있다면 kibana를 이용해서 데이터를 시각화 하는 부분은 상대적으로 쉽습니다. 저는 Y-Axis에 response_time_sec의 평균과 최대값을 넣고, X-Axis에 request_uri를 넣어서 그래프를 그려보니request_uri별로 응답속도의 평균값과 최대값이 나와서 평균대비 max가 높은 uri들은 어떤게 있는지 한눈에 알아볼 수 있는 그래프를 만들어 봤습니다.이 부분은 각자의 데이터와 분석하려는 목적에 따라 판이하게 달라질 수 있으니 kibana 홈페이지에서 참조하세요https://www.elastic.co/guide/en/kibana/current/index.html","categories":[{"name":"Operations","slug":"Operations","permalink":"https://www.nakjunizm.com/categories/Operations/"},{"name":"ElasticSearch","slug":"Operations/ElasticSearch","permalink":"https://www.nakjunizm.com/categories/Operations/ElasticSearch/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://www.nakjunizm.com/tags/elasticsearch/"},{"name":"kibana","slug":"kibana","permalink":"https://www.nakjunizm.com/tags/kibana/"},{"name":"logstash","slug":"logstash","permalink":"https://www.nakjunizm.com/tags/logstash/"},{"name":"elk","slug":"elk","permalink":"https://www.nakjunizm.com/tags/elk/"},{"name":"visualization","slug":"visualization","permalink":"https://www.nakjunizm.com/tags/visualization/"},{"name":"apache","slug":"apache","permalink":"https://www.nakjunizm.com/tags/apache/"},{"name":"log","slug":"log","permalink":"https://www.nakjunizm.com/tags/log/"}]},{"title":"Builder Pattern","slug":"Builder_Pattern","date":"2017-12-31T06:45:00.000Z","updated":"2021-10-06T15:33:17.480Z","comments":true,"path":"2017/12/31/Builder_Pattern/","link":"","permalink":"https://www.nakjunizm.com/2017/12/31/Builder_Pattern/","excerpt":"","text":"# 빌더패턴 (Builder pattern)빌더패턴은 immutable 클래스를 만드는 방법중의 하나로 작성하기 쉽고 읽기도 쉬운 좋은 코드를 만들 수 있습니다. 그런 이유로 많은 프레임웍이나 라이브러리들이 빌더 패턴으로 객체를 생성하는 방법을 제공합니다. 필요한 객체를 직접 생성하는 대신 빌더 객체를 먼저 만들고, 필요한 설정 메서드들을 호출하여 선택적 인자를 추가해 나가고 마지막으로 .build() 메서드를 호출하여 객체를 생성합니다. 아래는 이펙티브자바에서 예로 들고 있는 NutritionFacts 클래스 입니다. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class NutritionFacts &#123; private final int servingSize; private final int servings; private final int calories; private final int fat; private final int sodium; private final int carbohydrate; public static class Builder &#123; //필수 인자 private final int servingSize; private final int servings; //선택 인자 private int calories = 0; private int fat = 0; private int carbohydrate = 0; private int sodium = 0; public Builder(int servingSize, int servings) &#123; this.servingSize = servingSize; this.servings = servings; &#125; public Builder calories(int calories) &#123; this.calories = calories; return this; &#125; public Builder fat(int fat) &#123; this.fat = fat; return this; &#125; public Builder carbohydrate(int carbohydrate) &#123; this.carbohydrate = carbohydrate; return this; &#125; public Builder sodium(int sodium) &#123; this.sodium = sodium; return this; &#125; public NutritionFacts build() &#123; return new NutritionFacts(this); &#125; &#125; private NutritionFacts(Builder builder) &#123; this.servingSize = builder.servingSize; this.servings = builder.servings; this.calories = builder.calories; this.fat = builder.fat; this.sodium = builder.sodium; this.carbohydrate = builder.carbohydrate; &#125;&#125; NutritionFacts 객체를 생성하기 위해서는 아래와 같이 직관적으로 코드를 작성하면 됩니다. 1NutritionFacts cocaCola = new NutritionFacts.Builder(240, 8).calories(100).sodium(35).build(); 선택 인자 중에서도 fat과 carbohydrate은 기본값을 사용하고 싶으면 단순히 .fat().carbohydrate() 를 호출하지 않으면 됩니다. 만약 일반적인 생성자 패턴으로 위 객체를 만드려면 아래와 같이 생성해야 하는데인자가 많은 경우, 특히 동일한 타입으로 된 인자가 많은 경우 순서가 헷갈려 버리면 ** 컴파일 에러나 런타임에러가 발생하지 않고 정상적으로 프로그램이 도는것 처럼 보이지만 사실은 잘못된 데이터가 쌓이고 있는 ** 엄청난 버그가 발생할 수 도 있습니다. 1NutritionFacts cocaCola = new NutritionFacts(240, 8, 100, 0, 35, 0); 빌더패턴의 단점은 객체를 생성자로 바로 생성하는것이 아니고 빌더객체를 먼저 생성하고 그 빌더객체로 다시한번 새 객체를 반환하기 때문에 이 과정에서의 오버헤드가 문제가 될 수 있습니다. (대부분의 상황에서는 이정도의 오버헤드가 문제가 되지는 않겠지만) 속도에 매우 민감한 프로그램에서는 빌더패턴으로 객체를 생성하는것을 재고해봐야 할 수도 있습니다.","categories":[{"name":"Development","slug":"Development","permalink":"https://www.nakjunizm.com/categories/Development/"},{"name":"java","slug":"Development/java","permalink":"https://www.nakjunizm.com/categories/Development/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://www.nakjunizm.com/tags/java/"},{"name":"builder","slug":"builder","permalink":"https://www.nakjunizm.com/tags/builder/"},{"name":"pattern","slug":"pattern","permalink":"https://www.nakjunizm.com/tags/pattern/"}]},{"title":"쓰레드와 동기화","slug":"Thread_And_Synchronized","date":"2017-12-23T03:55:00.000Z","updated":"2021-10-06T15:33:17.419Z","comments":true,"path":"2017/12/23/Thread_And_Synchronized/","link":"","permalink":"https://www.nakjunizm.com/2017/12/23/Thread_And_Synchronized/","excerpt":"","text":"이펙티브자바 규칙66: 변경 가능 공유 데이터에 대한 접근은 동기화하라 아래 코드는 실행한지 1초가 지나면 stopRequested 변수를 true로 바꿔주고 프로그램이 종료되도록 기대하면서 작성된 코드입니다. 하지만 실제로 아래 코드를 돌려보면 절대 종료 되지 않습니다. 12345678910111213141516171819202122import java.util.concurrent.TimeUnit;public class StopThread &#123; private static boolean stopRequested; public static void main(String[] args) throws InterruptedException &#123; Thread backgroundThread = new Thread(new Runnable() &#123; @Override public void run() &#123; int i = 0; while (!stopRequested) &#123; i++; &#125; &#125; &#125;); backgroundThread.start(); TimeUnit.SECONDS.sleep(1); stopRequested = true; &#125;&#125; 그 이유는 위 코드는 동기화 메커니즘을 적용하지 않고 멀티 쓰레드로 개발을 했기 때문에 **main 쓰레드**에서 변경한 stopRequest의 새로운 값을 backgroundThread 에서 언제 확인하게 될지 알 수가 없기 때문입니다. 책에서는 이 문제를 해결하기 위한 솔루션으로 두가지를 제시 합니다. synchronized 키워드를 사용하여 stopRequested 변수를 동기화 하는 방법. volatile 키워드를 사용하여 lock없이 모든 쓰레드가 최근에 기록된 값을 읽어가도록 보장하는 방법 synchronized 키워드를 이용한 방법의 코드 12345678910111213141516171819202122232425262728import java.util.concurrent.TimeUnit;public class StopThread &#123; private static boolean stopRequested; private static synchronized void requestStop() &#123; stopRequested = true; &#125; private static synchronized boolean stopRequested() &#123; return stopRequested; &#125; public static void main(String[] args) throws InterruptedException &#123; Thread backgroundThread = new Thread(new Runnable() &#123; @Override public void run() &#123; int i = 0; while (!stopRequested()) &#123; i++; &#125; &#125; &#125;); backgroundThread.start(); TimeUnit.SECONDS.sleep(1); requestStop(); &#125;&#125; 쓰기 메서드 (requestStop)와 읽기 메서드(stopRequested) 모두에 동기화 메커니즘이 적용되어 있습니다. ** 읽기와 쓰기 모두에 적용하지 않으면 동기화는 아무런 효과도 없다** 고 책에서 강조하고 있습니다. 위 코드에서 동기화 메서드가 하는 일은 실제 그 메서드 들의 상호 배제성을 위해서라기보다는 (Mutual Exclusion) stopRequested변수의 가시성(Visibility)을 보장하기 위해서였습니다.이 부분은 이 블로그를 한번 읽어보시면 도움이 됩니다. 사실 단순히 그 목적이라면 성능 향상을 위해 해당 객체를 lock 잡지 않고 volatile로 선언하기만 해도 해결할 수 있습니다. volatile 키워드를 이용한 코드 12345678910111213141516171819202122import java.util.concurrent.TimeUnit;public class StopThread &#123; private static volatile boolean stopRequested; public static void main(String[] args) throws InterruptedException &#123; Thread backgroundThread = new Thread(new Runnable() &#123; @Override public void run() &#123; int i = 0; while (!stopRequested) &#123; i++; &#125; &#125; &#125;); backgroundThread.start(); TimeUnit.SECONDS.sleep(1); stopRequested = true; &#125;&#125; 맨 처음의 잘못된 코드와 다른점은 stopRequested 변수를 volatile로 선언한 것 밖에 없지만 1초후에 정상적으로 종료 되는것을 확인 할 수 있습니다. 그럼 long과 double을 제외하고서는 기본적으로 원자성을 보장 해 주고….위와같이 volatile 키워드를 사용하면 동기화 블럭이나 동기화 함수를 만들지 않고도 Thread safe 하게 변수를 공유하는 프로그램을 짤 수 있겠다!!! 하지만 아래와 같은 코드는 ++연산자가 원자적이지 않기 때문에 쓰레드 쎄이프 하지 않습니다. 1234private static volatile int nextSerialNumber = 0;public static int generateSerialNumber() &#123; return nextSerialNumber++;&#125; 위 코드는 synchronized block을 사용해서 해결 할 수 도 있지만 java.util.concurrent.atomic에 속해있는 AtomicLong을 사용하여 해결하는것이 성능적으로 더 좋습니다. 1234private static final AtomicLong nextSerialNumber = new AtomicLong();public static long generateSerialNumber() &#123; return nextSerialNum.getAndIncrement();&#125; # 결론간단하게 쓰레드 간에 변수만 공유하는 경우에 대해서 알아봤는데요 아래 나열한 내용을 숙지하고 프로그램 한다면 좋을것 같습니다. 변경가능 데이터는 한 스레드에서만 이용하는 것이 가장 좋다. 하지만 그게 불가능 하다면 변경 가능한 데이터를 읽거나 쓰는 모든 쓰레드는 동기화를 수행해야 함. 원자성이 보장되는 경우는 volatile키워드만으로 안전하게 데이터를 교환할 수 있음. java.util.concurrent.atomic에 속해있는 클래스를 사용하는것은 좋은 해법임.","categories":[{"name":"Development","slug":"Development","permalink":"https://www.nakjunizm.com/categories/Development/"},{"name":"java","slug":"Development/java","permalink":"https://www.nakjunizm.com/categories/Development/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://www.nakjunizm.com/tags/java/"},{"name":"thread","slug":"thread","permalink":"https://www.nakjunizm.com/tags/thread/"},{"name":"synchronized","slug":"synchronized","permalink":"https://www.nakjunizm.com/tags/synchronized/"},{"name":"volatile","slug":"volatile","permalink":"https://www.nakjunizm.com/tags/volatile/"}]},{"title":"직렬화(Serialization) 와 transient 키워드","slug":"Serialization_And_Transient","date":"2017-12-10T03:38:00.000Z","updated":"2021-10-06T15:33:17.440Z","comments":true,"path":"2017/12/10/Serialization_And_Transient/","link":"","permalink":"https://www.nakjunizm.com/2017/12/10/Serialization_And_Transient/","excerpt":"","text":"# Serialization직렬화 (Serialization)으로 검색해서 나온 정보들은 종합해 보면 대부분 같습니다. 직렬화란 오브젝트를 데이터스트림에 쓰기 위해 연속적인(serial) 바이트로 변환 하는것을 말한다. Java에서 직렬화가 가능한 것은 원시타입 객체 Serializable 인터페이스를 implements 한 오브젝트 Serializable 인터페이스를 implements 한 클래스나 인터페이스를 상속/구현 한 오브젝트 개념이 좀 안잡히니 예를 들어보겠습니다.내가 생성한 User 객체를 Disk에 저장하려고 합니다.User.java에는 String type의 _username_과 password 를 정의했습니다. username 과 password 를 파일로 저장하고 싶으면 간단히 파일을 열고 해당값을 저장하는 프로그램을 작성하면 됩니다. 하지만 username 과 password 의 값이 포함된 상태의 User ** 객체 자체 ** 를 저장하고 싶다면 어떻게 해야 할까요? 상식적으로 생각해봐도 파일에 User 객체를 쓰기는 쉽지 않을것 같은데 이렇게 객체를 데이터 스트림에 쓰기 위한 작업을 ** 직렬화 ** 라는 과정을 통해 가능하게 만들어 주는것 입니다. Q : 그렇다면 transient 키워드는 무엇인가요?A : transient 키워드를 붙인 변수는 직렬화 대상에서 제외 됩니다. 어렵게 생각할 필요가 없습니다. 데이터를 디스크에 저장하거나 디비에 저장하거나 http request를 통해 보내거나 할때 민감한 데이터(개인정보등)은 제외하고 싶으면 transient를 붙이면 되는것 입니다.(참고로 JPA (or hibernate)의 도메인(모델) 에는 @transient 라는 어노테이션을 붙이게 되면 DB의 값과 맵핑시키지 않습니다.) 아래 예제는 User 클래스를 객체로 만들고 직렬화/역직렬화 해보는 예제 입니다. 123456789101112131415161718192021public class User implements Serializable &#123; private static final long serialVersionUID = 1000000000000001L; private String username; private transient String password; public User(String username, String password)&#123; this.username = username; this.password = password; &#125; public String getUsername() &#123; return username; &#125; public String getPassword() &#123; return password; &#125;&#125; 123456789101112131415161718192021222324public class UserTest &#123; @Test public void transientField() throws IOException, ClassNotFoundException &#123; final User user = new User(&quot;Rafael&quot;, &quot;secret321&quot;); final FileOutputStream fos = new FileOutputStream(&quot;/tmp/user&quot;); final ObjectOutputStream oos = new ObjectOutputStream(fos); oos.writeObject(user); oos.flush(); oos.close(); fos.close(); final FileInputStream fis = new FileInputStream(&quot;/tmp/user&quot;); final ObjectInputStream ois = new ObjectInputStream(fis); final User deserialized = (User) ois.readObject(); assertEquals(&quot;Rafael&quot;, deserialized.getUsername()); assertNull(deserialized.getPassword()); //password는 transient 키워드가 붙어있으므로 넘어오지 않았음. &#125;&#125;","categories":[{"name":"Development","slug":"Development","permalink":"https://www.nakjunizm.com/categories/Development/"},{"name":"java","slug":"Development/java","permalink":"https://www.nakjunizm.com/categories/Development/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://www.nakjunizm.com/tags/java/"},{"name":"serialization","slug":"serialization","permalink":"https://www.nakjunizm.com/tags/serialization/"},{"name":"transient","slug":"transient","permalink":"https://www.nakjunizm.com/tags/transient/"}]},{"title":"Redis backup and restore","slug":"Redis_Backup_And_Restore","date":"2017-10-10T03:50:00.000Z","updated":"2021-10-06T15:33:17.426Z","comments":true,"path":"2017/10/10/Redis_Backup_And_Restore/","link":"","permalink":"https://www.nakjunizm.com/2017/10/10/Redis_Backup_And_Restore/","excerpt":"","text":"# Redis Persistence modeRedis는 데이터를 메모리에 올려놓고 쓰기 때문에 Redis가 down되면서 데이터가 날아가는 것을 방지 하기 위해 두가지의 persistence 모드를 제공 합니다. RDB AOF 1. RDBRDB persistence는 point-in-time snapshot을 사용자가 지정한 inverval 마다 찍어서 디스크에 .rdb file로 내립니다. 장점 특정 시점의 데이터를 file로 저장하고 저장된 파일을 안전한 backup 저장소로 옮길수 있기 때문에 backup 용도로 좋음. AOF에 비해 상대적으로 빠른 복구가 가능 단점 snapshot을 찍는 interval 사이에 들어온 데이터는 보존할 수 없음. RDB는 disk 에 파일을 내릴때 fork()를 수행하는데 이 때 dataset 의 크기가 크면 Redis가 some millisecond 동안 응답을 못 줄 확률이 있음. 2. AOFAOF는 모든 write operation에 대한 로그를 파일로 남깁니다.그래서 redis가 startup 될때 그 로그에 남아있는 command를 다시 play함으로써 원본 dataset을 복원하는 방식 입니다. 장점 모든 write operation이 로깅 되므로 놓치는 data가 없이 완벽하게 복원 가능 AOF 로그는 append only log이므로 파일이 corrupt될 확률이 거의 없고 만약 disk full 등의 이유로 파일이 깨지더라도 redis-check-aof tool로 쉽게 고칠 수 있음. AOF 로그가 너무 커지면 Reis가 알아서 로그를 rewrite 할수 있다. 단점 파일 크기가 일반적으로 RDB 파일보다 큼. fsync policy에 따라 다르긴 하지만 일반적으로 RDB에 비해 느림. # RDB를 써야하나 AOF를 써야하나?Redis 홈페이지의 article에 따르면 데이터의 양이 많고 몇분간의 데이터 유실정도는 감수 할 수 있으면 간단히 RDB 만 사용해도 무방. 데이터의 유실이 절대 있으면 안된다면 AOF를 단독으로 사용하지는 말고, AOF+RDB 사용을 권장함. # RDB Backup 디폴트로 Redis는 snapshot을 save하게 설정되어 있고 해당 파일은 dump.rdb라는 이름으로 디스크에 저장됩니다. dataset의 변경이 최소 M번 이상 있었는지 매 N 초 마다 확인해서 save 하도록 설정할 수 있습니다. 수동으로 SAVE 혹은 BGSAVE 명령어를 사용하여 .rdb 파일을 생성할수 있습니다. redis.conf 파일 설정 예) save 60 1000 &lt;- 60초마다 최소 1000개의 key의 변화가 있을 시 save. 여러개의 save 조건을 다른 라인으로 설정 하는 것도 가능 합니다. # RDB Restoring dump.rdb 파일을 restore하기 위해서는 단순히 dump.rdb 파일을 Redis의 data dir 에 넣고 redis를 재시작 하기만 하면 됩니다. data dir이 어딘지 모르겠으면 redis.conf 파일에서 dir을 찾거나 redis-cli에서1127.0.0.1:6379&gt; CONFIG get dir 명령어를 쳐 보면 어느 경로에 설정되어 있는지 확인할 수 있습니다.","categories":[{"name":"Operations","slug":"Operations","permalink":"https://www.nakjunizm.com/categories/Operations/"},{"name":"Redis","slug":"Operations/Redis","permalink":"https://www.nakjunizm.com/categories/Operations/Redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://www.nakjunizm.com/tags/redis/"},{"name":"backup","slug":"backup","permalink":"https://www.nakjunizm.com/tags/backup/"},{"name":"restore","slug":"restore","permalink":"https://www.nakjunizm.com/tags/restore/"}]},{"title":"reroute: shard를 강제로 locate 시키는 방법","slug":"reroute","date":"2017-09-26T09:27:00.000Z","updated":"2021-10-06T15:33:17.462Z","comments":true,"path":"2017/09/26/reroute/","link":"","permalink":"https://www.nakjunizm.com/2017/09/26/reroute/","excerpt":"","text":"# ElasticSearch Shard Initialize fail 시 강제로 locate 시키는 방법어떤 이유에선지 shard의 initialize가 실패하고 unassigned shard상태로 남아있다면 강제로 특정 노드로 옮겨줘야 할 필요가 있습니다. 12345678910111213POST _cluster/reroute&#123; &quot;commands&quot;: [ &#123; &quot;allocate&quot;: &#123; &quot;index&quot;: &quot;인덱스명&quot;, &quot;shard&quot;: &quot;보낼샤드넘버, &quot;node&quot;: &quot;타겟노드명&quot;, &quot;allow_primary&quot;: &quot;true&quot; &#125; &#125; ]&#125; allow_primary 옵션을 true로 주면 primary 샤드를 옮기겠다고 선언 하는 것 입니다.혹시라도 cluster health가 red로 빠져있고 primary and replica shard 모두 unassigned 샤드 인경우…primary 샤드만 재배치 되고 replica는 여전히 unassigned 로 남아 있다면 “allow_primary”: “false” 로 바꾸고 “node” 도 primary shard가 있는 노드가 아닌 다른 노드로 설정하여 다시 한번 실행 시켜주면 됩니다.","categories":[{"name":"Operations","slug":"Operations","permalink":"https://www.nakjunizm.com/categories/Operations/"},{"name":"ElasticSearch","slug":"Operations/ElasticSearch","permalink":"https://www.nakjunizm.com/categories/Operations/ElasticSearch/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://www.nakjunizm.com/tags/elasticsearch/"},{"name":"unassigned","slug":"unassigned","permalink":"https://www.nakjunizm.com/tags/unassigned/"},{"name":"reroute","slug":"reroute","permalink":"https://www.nakjunizm.com/tags/reroute/"}]},{"title":"ElasticSearch Heap 메모리 설정","slug":"ElasticSearch_Heap_Memory","date":"2017-09-07T05:31:00.000Z","updated":"2021-10-06T15:33:17.486Z","comments":true,"path":"2017/09/07/ElasticSearch_Heap_Memory/","link":"","permalink":"https://www.nakjunizm.com/2017/09/07/ElasticSearch_Heap_Memory/","excerpt":"","text":"# 권장 메모리 할당량ES의 힙 사이즈는 전체 서버가 가진 메모리의 반을 설정하는 것을 권장하고, 64GB 이상의 메모리를 가지고 있는 서버라고 할지라도 30.5GB 이상을 ES에 할당하는것은 권장하지 않습니다. 예를들어 32GB의 메모리를 가진 서버라면 ES에 16GB 할당. 64GB의 메모리를 가진 서버라면 ES에 30.5GB 할당.128GB의 메모리를 가진 서버라고 할지라도 ES에 30.5 GB 할당.왜 30.5GB로 한정 짓는지에 대해서는 밑에서 좀 더 자세히 다루도록 하겠습니다. # Memory swapping 기능은 비활성화ES는 메모리에 많은양의 데이터를 올려놓고 searching, indexing 등의 작업을 하기 때문에 swap을 켜 놓으면 disk로 내려서 작업이 되어 버리는 순간 성능에 치명적인 악영향을 끼칠수 있습니다.엘라스틱 에서는 swap을 사용하지 않게 하기 위해서 세가지 옵션을 제시 합니다. swap off1sudo swapoff -a 위 설정은 reboot 하고 나면 원상복구 되는 설정 입니다.그러므로 fstab에서도 swap 을 comment out 하는것이 좋습니다.12345sudo vi /etc/fstab````swap 이란 단어를 포함하고 있는 라인 #으로 주석처리- sysctl 의 vm.swappiness=1 로 설정 sysctl -a |grep swappiness1을 하여 vm.swappiness 설정이 되어 있는지 확인하고, grep되는 결과가 없거나 1이 아닌 값으로 설정 되어 있다면 sysctl -w vm.swappiness=11or sudo vi /etc/sysctl.confvm.swappiness=11추가 후 sysctl -p12345678910참고로 vm.swapiness 설정은 swap 사용의 적극성 혹은 활용 수준을 정하는 커널 속성 입니다.0으로 설정하면 사용 안함 1은 최소로 사용 ~ 100은 적극적으로 스왑 활용 인데 ** 0으로 설정하지 않고 1로 설정하는 이유 ** 는 0으로 설정할 시 `OOM Killer`가 스왑을 사용하려고 시도하는 어플리케이션!!!! 을 외치며 ES를 바로 kill 시켜 버릴수도 있기 때문에 0으로는 설정하지 않습니다.&lt;br /&gt;인터넷에서 찾을 수 있는 포스트 내용 중 SSD일 경우 vm.swapiness를 10으로 줘도 문제가 없다고 하는 사람들도 있는데 저는 서버에 SSD를 사용해서 10으로 설정했다가 OS가 swap을 사용해 버리는 바람에 성능에 영향을 받았던 경험이 있습니다. 그래서 다시 1로 변경.- memory lock&lt;br /&gt;위 두 설정은 root나 sudoer 계정을 가지고 있을때만 가능한 설정 인데OS를 관리하는 쪽에서 절대로 위 설정들을 허용해 주지 않는다면 마지막으로 jvm자체에 설정을 주는 수 밖에 없습니다.** elasticsearch.yml ** 파일에 다음과 같이 을 true를 주면 (버전에 따라 프로퍼티 네임이 다르니 주의!)이 옵션은 elasticsearch가 기동될때 자기한테 할당된 메모리를 lock 한 채로 뜨게 되며swap으로 메모리가 빠져나가는것을 방지 해 주는 옵션입니다. #ES 2.Xbootstrap.mlockall: true#ES 5.Xbootstrap.memory_lock: true123456789101112131415161718192021222324252627282930313233하지만 memory lock 설정과 vm.swappiness: 1로 설정은 elasticsearch 가 스왑을 최대한 안 쓰게 설정한 것이지만스왑 자체가 OS에서 사용하는 자원이기 때문에 OS가 필요하다고 판단하면 쓸 수도 있습니다.개인적으로는 vm.swappiness :1 설정 및 mlockall :true 둘 다 설정 했는데 그 이후로 거의 1년간 운영해 오면서 OS가 swap을 쓴적은 없습니다.확인 할 수 있는 방법은 간단하게 free -m 등으로 확인해서 swap 영역에 할당된 영역을 확인해 보시면 됩니다.### # Zero-Based Compressed Oops (Ordinary Object Pointers)** \\# 권장 메모리 할당량 ** 에서 30.5GB 이상으로 설정하지 말라고 했던 것의 연장선 입니다.Oops 에 대해서 대략적으로 말씀드리면 오브젝트들이 어느 메모리에 locate 되어 있는지를 관리하는 ** JVM의 포인터 ** 라고 생각 하면 쉽습니다.이 Managed 포인터의 크기는 기본적으로 OS의 bit를 따라 가며 32bit OS에서는 2의 32승(=4GB)의 크기를 가지며 64bit OS에서는 2의 64승(=2EB 엑사바이트)의 크기를 가진다고 볼 수 있겠습니다.그런데 생각해보면 2의 64승의 주소를 찾아가는 연산을 하려면 오브젝트의 메모리 주소를 찾는데만해도 많은 시간이 소요될 것이고 거의 쓸모없는 프로그램이 될것이기 때문에** JAVA는 64bit의 OS라 할지라도 4GB 이하의 힙을 가지고 JVM을 띄우면 32bit의 oops를 그대로 따라가도록 설계 ** 되어 있습니다.그리고 4GB가 넘어가는 영역에 대해서는 compressed oops라는 기법을 사용할 수 있는데 포인터가 실제 오브젝트가 들어있는 메모리 주소값을 가르키는것이 아니고 8byte단위로 나눠놓은 offset을 가르키게 됩니다.이렇게 되면 2의 32승 bit (=4GB)을 표현할 수 있는 32bit oop를 이용하여 실제로는 8배 많은 32GB의 주소값까지 표현할 수 있게 되는것 입니다.Compressed oops를 설계 한 사람들이 아무 생각없이 8byte (= 2의 3승 byte) 단위로 끊어 놓지는 않았을 테고.. 어떤이유가 있을까요?아마도 적당히 큰 메모리 공간을 활용할 수 있으면서 성능도 놓치고 싶지 않는 범위내에서 끊어 놓았을텐데....굉장히 복잡한 여러가지 이유가 있겠지만 ** 기본적으로 java가 사용하는 메모리 스키마는 8byte의 구조를 가지고 있다고 합니다. ** 그렇기 때문에 8byte단위로 건너뛰면서 mapping을 해 놓으면 좌로 3번 시프트 ( &lt;&lt; 3 ) 해 주는 연산만으로 원래 가르키고자 했던 주소값을 정확히 가르킬수 있게 되는것 입니다.&lt;br /&gt;그런데 이렇게 되기 위해서는 한가지 필요충분조건이 필요 합니다.바로 메모리주소의 시작점이 0부터 시작해야 한다는 조건인데요, 이 조건이 충족되지 않으면 Non-Zero based Compressed oops로 동작을 하게 되고 좌로 3번 시프트 &lt;&lt; 3 해준 이후에 시작점만큼 + 해주는 연산이 추가로 들어가야 되서 메모리의 크기가 큰 경우 성능에 영향을 끼치게 됩니다.자세히 보려면 너무 어렵고 한번에 다루기도 힘든 내용이니 관심 있으신 분들은 이 두 포스트를 읽어보시길 추천 합니다.&lt;http://docs.oracle.com/javase/7/docs/technotes/guides/vm/performance-enhancements-7.html&gt;&lt;https://wiki.openjdk.java.net/display/HotSpot/CompressedOops&gt;### # 결론 : 그럼 나는 얼마까지 ES에 메모리를 할당하면 좋을까요?1. 서버의 메모리가 63GB 미만이라면 =&gt; 내가 가진 메모리의 반.2. 서버의 메모리가 63GB 이상이라면 =&gt; 내 서버에서 Zero based 모드로 Compressed oops를 사용할 수있는 임계치※ 임계치를 알아보는 방법&lt;br /&gt;서버에서 커맨드를 그냥 날려보시면 됩니다! &lt;br /&gt;내 메모리가 64GB라서 32GB부터 확인해보는 시나리오로 확인해 보는법을 보여드리겠습니다.- 32GB java -Xmx32G -XX:+PrintFlagsFinal -XX:+UnlockDiagnosticVMOptions -XX:+PrintCompressedOopsMode 2&gt;/dev/null |grep Compressed |grep Oopsbool PrintCompressedOopsMode := true {diagnostic}bool UseCompressedOops = false {lp64_product}123bool UseCompressedOops = false 임을 확인 할수 있습니다.- 31GB java -Xmx31G -XX:+PrintFlagsFinal -XX:+UnlockDiagnosticVMOptions -XX:+PrintCompressedOopsMode 2&gt;/dev/null |grep Compressed |grep Oopsheap address: 0x00007f9348800000, size: 31744 MB, Compressed Oops mode: Non-zero based:0x00007f93487ff000, Oop shift amount: 3bool PrintCompressedOopsMode := true {diagnostic}bool UseCompressedOops := true {lp64_product}12331GB는 UseCompressedOops = true 입니다. ** 하지만! Compressed Oops mode 가 Non-zero based 인 것을 확인 할 수 있습니다. ** 우리가 원하는 결과가 아닙니다.- 30GB java -Xmx30G -XX:+PrintFlagsFinal -XX:+UnlockDiagnosticVMOptions -XX:+PrintCompressedOopsMode 2&gt;/dev/null |grep Compressed |grep Oopsheap address: 0x0000000080000000, size: 30720 MB, Compressed Oops mode: Zero based, Oop shift amount: 3bool PrintCompressedOopsMode := true {diagnostic}bool UseCompressedOops := true {lp64_product}```이번에는 CompressedOops 도 사용하고 Zero based 모드로 잘 되어 있네요.30GB는 사용해도 좋습니다. ** 추가 Tip **30GB로 운영하는데 CPU도 별로 많이 안쓰는것 같고 메모리도 여유있는것으로 확인되면 FullGC 시간을 줄이기 위해 힙을 24GB정도로 내려서 사용하는것도 고려해 볼 만 합니다. 운영환경에서 최적의 힙 메모리를 적용하기 위해서는 일정기간 트렌딩을 살펴보고 결정하는게 좋겠습니다. # references :https://www.elastic.co/guide/en/elasticsearch/guide/current/heap-sizing.htmlhttps://www.elastic.co/guide/en/elasticsearch/reference/5.5/setup-configuration-memory.htmlhttps://www.elastic.co/blog/a-heap-of-troublehttp://docs.oracle.com/javase/7/docs/technotes/guides/vm/performance-enhancements-7.htmlhttps://wiki.openjdk.java.net/display/HotSpot/CompressedOops","categories":[{"name":"Operations","slug":"Operations","permalink":"https://www.nakjunizm.com/categories/Operations/"},{"name":"ElasticSearch","slug":"Operations/ElasticSearch","permalink":"https://www.nakjunizm.com/categories/Operations/ElasticSearch/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://www.nakjunizm.com/tags/elasticsearch/"},{"name":"heap","slug":"heap","permalink":"https://www.nakjunizm.com/tags/heap/"},{"name":"swapoff","slug":"swapoff","permalink":"https://www.nakjunizm.com/tags/swapoff/"},{"name":"compressedoops","slug":"compressedoops","permalink":"https://www.nakjunizm.com/tags/compressedoops/"}]},{"title":"Node가 예기치 않게 이탈될 경우 shard allocation 지연시키기","slug":"Shard_Allocation_And_FD","date":"2017-08-24T03:57:00.000Z","updated":"2021-10-06T15:33:17.439Z","comments":true,"path":"2017/08/24/Shard_Allocation_And_FD/","link":"","permalink":"https://www.nakjunizm.com/2017/08/24/Shard_Allocation_And_FD/","excerpt":"","text":"# 클러스터에서 노드가 제외되는 현상ElasticSearch 에서는 Fault Detection을 위해 master-&gt;nodes, nodes-&gt;master 양방향으로 주기적으로 ping을 날립니다.아무 설정을 하지 않았다면 1초마다 ping을 날리고, 30초 동안 응답이 없으면 3번 재시도 후 최종적으로 fault라고 단정짓고 해당 노드를 클러스터에서 제외 시킵니다. 운영중인 클러스터에서는 이런 상황이라면 문제가 심각해 질 수 있습니다. 이유는 클러스터에서 노드가 한개 빠짐 -&gt; 빠진 노드가 가지고 있던 shard 들이 unassigned shards 로 변경됨 -&gt; unassigned shards 를 기존 노드들이 나눠갖는 shard allocation 발생 -&gt; 데이터 량이 많은 인덱스의 경우 shard allocation 작업은 굉장히 비싼 작업이므로 CPU load 높아짐 -&gt; 서비스 지연이 발생 가능 위와같은 상황이 발생되지 않도록 예방하기 위해서는 두가지 솔루션이 있습니다. ** 노드가 클러스터에서 이탈되지 않도록 Fault Detection 을 느슨하게 변경 ** ** 노드가 클러스터에서 이탈 되더라도 unassigned shards 를 바로 allocation 이 일어 나지 않도록 설정 변경** # Fault Detection첫번째로 Fault Detection을 느슨하게 변경 하는 방법을 알아보겠습니다. 아래 표와 같이 ping_interval, ping_timeout, ping_retries 관련 값을 조정함으로서 느슨하게 변경 할 수 있습니다.** ※ 해당 값의 변경은 Elastic 에서 권장하는 방법은 아닙니다. ** Setting Description discovery.zen.fd.ping_interval How often a node gets pinged. Defaults to 1s. discovery.zen.fd.ping_timeout How long to wait for a ping response, defaults to 30s. discovery.zen.fd.ping_retries How many ping failures / timeouts cause a node to be considered failed. Defaults to 3. &lt; elasticsearch.yml 에 설정 할 수 있는 fault detection 관련 설정값&gt;출처 : https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-discovery-zen.html 위 설정은 dynamic setting 으로 바로 적용하기는 어렵고 (바로 반영 시키려면 인덱스를 close 한 상태로는 가능) elasticsearch.yml 파일에 설정 후 재기동 하는것이 좋겠습니다.인덱스 close가 가능한 상황이라면 아래 명령어를 바로 날려도 됩니다. fault detection ping retries 를 6번으로 변경하는 예 123456curl -XPUT &#x27;localhost:9200/_all/_settings?pretty&#x27; -H &#x27;Content-Type: application/json&#x27; -d&#x27;&#123; &quot;settings&quot;: &#123; &quot;discovery.zen.fd.ping_retries&quot;: 6 &#125;&#125;&#x27; # allocation 지연두번째로 unassigned shards의 allocation을 지연시키는 방법을 알아 보겠습니다. 이유를 정확히 알 수 없지만 GC가 오래 걸려서 Stop the world가 길게 된다던지 하면 첫번째 방법으로 fault detection을 느슨하게 했더라도 노드가 클러스터에서 빠질 수 있습니다. 노드가 빠졌더라도 shard allocation만 일어나지 않는다면 서버에 무리를 주지는 않으므로 (replica가 1 이상 설정 되어 있어서 노드 한개가 빠지더라도 서비스에 영향이 없다는 가정하에) 빠진 노드를 재시작 하고 다시 클러스터에 join 시킬때까지 시간을 좀 벌려는 목적으로 아래 설정을 적용 시킵니다. unassigned shards 를 5분이 지날때 까지 unassigned 상태로 유지하는 예 123456curl -XPUT &#x27;localhost:9200/_all/_settings?pretty&#x27; -H &#x27;Content-Type: application/json&#x27; -d&#x27;&#123; &quot;settings&quot;: &#123; &quot;index.unassigned.node_left.delayed_timeout&quot;: &quot;5m&quot; &#125;&#125;&#x27; 저렇게 되면 노드 하나가 빠져서 cluster health 가 yellow로 변경 된 이후 5분의 여유가 생기므로 shard allocation을 none 으로 바꾼 후 분석을 한다던지 복구를 한다던지 하는 선택지를 가질수 있게 됩니다.","categories":[{"name":"Operations","slug":"Operations","permalink":"https://www.nakjunizm.com/categories/Operations/"},{"name":"ElasticSearch","slug":"Operations/ElasticSearch","permalink":"https://www.nakjunizm.com/categories/Operations/ElasticSearch/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://www.nakjunizm.com/tags/elasticsearch/"},{"name":"unassigned","slug":"unassigned","permalink":"https://www.nakjunizm.com/tags/unassigned/"},{"name":"shards","slug":"shards","permalink":"https://www.nakjunizm.com/tags/shards/"},{"name":"allocation","slug":"allocation","permalink":"https://www.nakjunizm.com/tags/allocation/"}]},{"title":"try-with-resources","slug":"Try_With_Resources","date":"2017-08-10T12:45:00.000Z","updated":"2021-10-06T15:33:17.492Z","comments":true,"path":"2017/08/10/Try_With_Resources/","link":"","permalink":"https://www.nakjunizm.com/2017/08/10/Try_With_Resources/","excerpt":"","text":"java7부터 AutoCloseable 인터페이스를 구현한 클래스라면 try-catch-finally 구조에서 지저분하게 finally 블럭에 close()를 명시적으로 호출 하지 않아도 자동으로 close 시켜주는 쿨한 feature를 제공합니다. 하지만 옛날에 자바를 배워서 쭉 코딩은 해왔지만 새로운 코딩스타일을 선호 하지 않는 분들은 아래와 같이 코딩 합니다. 1234567891011121314151617@Testpublic void oldStyleTryCatch() &#123; BufferedReader bufferedReader = null; try &#123; bufferedReader = new BufferedReader(new FileReader(&quot;/myhome/test.txt&quot;)); String line = bufferedReader.readLine(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; if (bufferedReader != null) bufferedReader.close(); &#125; catch (IOException ex) &#123; ex.printStackTrace(); &#125; &#125;&#125; 분명 나쁜 코드는 아니지만 좋은 코드라고 할수도 없겠네요. Oracle에서 제공하는 공식 docs를 먼저 읽어봅니다. try 선언부에 세미콜론(;)으로 구분된 한개 이상의 리소스를 선언(declarations)을 할 수 있다고 하네요. 리소스는 java.lang.AutoCloseable를 implement 하고 있는 클래스 라면 리소스로 쓰일수 있다고 합니다. 위 코드를 try-with-resources statement 를 이용한 코드로 바꿔보겠습니다. 12345678@Testpublic void newStyleTryCatch() &#123; try (BufferedReader bufferedReader = new BufferedReader(new FileReader(&quot;C:\\\\mydev\\\\test.txt&quot;));) &#123; String line = bufferedReader.readLine(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125; 훨씬 보기에 깔끔한 코드로 바뀐것을 확인 할 수 있습니다. FileReader/Writer 등과 관련된 클래스들, DB Connection과 관련된 클래스들에 주로 많이 사용할 수 있으니 아직까지 try-with-resources statement 의 사용법을 잘 모르셨던 분들이라면 꼭 익히시길 추천합니다.","categories":[{"name":"Development","slug":"Development","permalink":"https://www.nakjunizm.com/categories/Development/"},{"name":"java","slug":"Development/java","permalink":"https://www.nakjunizm.com/categories/Development/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://www.nakjunizm.com/tags/java/"},{"name":"exception","slug":"exception","permalink":"https://www.nakjunizm.com/tags/exception/"},{"name":"try-with-resources","slug":"try-with-resources","permalink":"https://www.nakjunizm.com/tags/try-with-resources/"}]},{"title":"내 클러스터에 문제가 있는건 아닌지 의심된다면?","slug":"Cluster_Check","date":"2017-08-03T00:20:00.000Z","updated":"2021-10-06T15:33:17.494Z","comments":true,"path":"2017/08/03/Cluster_Check/","link":"","permalink":"https://www.nakjunizm.com/2017/08/03/Cluster_Check/","excerpt":"","text":"bulk indexing을 하고 있거나 검색을 heavy 하게 날리고 있을때 클러스터 헬스는 그린으로 멀쩡한거 하지만 뭔가 퍼포먼스가 너무 떨어지는 느낌이 들때가 있습니다.클러스터 로그를 살펴봐도 별다른점을 못찾겠고 어디서 부터 살펴봐야 할지 난감한데요 이럴 때 참고하면 좋은 몇가지 api들을 소개하겠습니다. # 1. pending task 확인1curl -XGET &#x27;host:port/_cluster/pending_tasks&#x27; 공식docs를 보면 일반적인 상황에서는 empty list를 반환 하지만 pending 되어 있는 작업이 있는 경우 그 리스트를 리턴 합니다. 12345678910111213141516171819202122232425&#123; &quot;tasks&quot;: [ &#123; &quot;insert_order&quot;: 101, &quot;priority&quot;: &quot;URGENT&quot;, &quot;source&quot;: &quot;create-index [foo_9], cause [api]&quot;, &quot;time_in_queue_millis&quot;: 86, &quot;time_in_queue&quot;: &quot;86ms&quot; &#125;, &#123; &quot;insert_order&quot;: 46, &quot;priority&quot;: &quot;HIGH&quot;, &quot;source&quot;: &quot;shard-started ([foo_2][1], node[tMTocMvQQgGCkj7QDHl3OA], [P], s[INITIALIZING]), reason [after recovery from shard_store]&quot;, &quot;time_in_queue_millis&quot;: 842, &quot;time_in_queue&quot;: &quot;842ms&quot; &#125;, &#123; &quot;insert_order&quot;: 45, &quot;priority&quot;: &quot;HIGH&quot;, &quot;source&quot;: &quot;shard-started ([foo_2][0], node[tMTocMvQQgGCkj7QDHl3OA], [P], s[INITIALIZING]), reason [after recovery from shard_store]&quot;, &quot;time_in_queue_millis&quot;: 858, &quot;time_in_queue&quot;: &quot;858ms&quot; &#125; ]&#125; ** pending tasks 가 있는 경우 단순히 작업량이 많아서 밀리고 있는 것 인지 비정상 적인 상황인지 판단해야 합니다 ** # 2. hot threads 확인hot threads 를 확인하는 일은 elasticsearch cluster 를 운영하다 보면 종종 있는 일 입니다.특히 GC가 비정상 적이거나, CPU가 높거나, 검색이 밀리거나 하는등 거의 대부분의 문제의 원인을 유추해 볼 수 있는 단서가 될 수 있습니다. 1curl -XGET &#x27;host:port/_nodes/&#123;nodesIds&#125;/hot_threads?pretty&#x27; 공식docs 에 따르면 아래와 같은 파라미터를 같이 던질 수 있습니다. type이 기본적으로 cpu로 되어 있고 threads가 3으로 설정 되어 있기 때문에 CPU 사용률이 높은 세개의 쓰레드가 표시됩니다. param description threads number of hot threads to provide, defaults to 3. interval the interval to do the second sampling of threads. Defaults to 500ms. type The type to sample, defaults to cpu, but supports wait and block to see hot threads that are in wait or block state. ignore_idle_threads If true, known idle threads (e.g. waiting in a socket select, or to get a task from an empty queue) are filtered out. Defaults to true. 12345678910111224.6% (122.8ms out of 500ms) cpu usage by thread &#x27;elasticsearch[cluster][search][T#13]&#x27; 10/10 snapshots sharing following 10 elements sun.misc.Unsafe.park(Native Method) java.util.concurrent.locks.LockSupport.park(LockSupport.java:186) org.elasticsearch.common.util.concurrent.jsr166y.LinkedTransferQueue.awaitMatch(LinkedTransferQueue.java:706) org.elasticsearch.common.util.concurrent.jsr166y.LinkedTransferQueue.xfer(LinkedTransferQueue.java:615) org.elasticsearch.common.util.concurrent.jsr166y.LinkedTransferQueue.take(LinkedTransferQueue.java:1109) org.elasticsearch.common.util.concurrent.SizeBlockingQueue.take(SizeBlockingQueue.java:162) java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068) java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) java.lang.Thread.run(Thread.java:724) 위 output에서는 서치쓰레드의 T#13이 24.6%의 cpu를 사용하는것을 알 수 있습니다.해당 쓰레드의 스택 트레이스도 같이 나오므로 써드파티 라이브러리나 플러그인을 사용한 경우 해당 쓰레드가 자주 등장한다면 버그가 있는것은 아닌지 찾아봐야 하고, java core 쪽. 특히 cache나 concurrent쪽 쓰레드가 자주 나타난다면 메모리 관련 OS설정들은 잘 적용 되었는지 (Post not found: ElasticSearch_Heap 참조) 등등 문제가 될 만한 부분들을 찾아내는 좋은 단서가 됩니다.","categories":[{"name":"Operations","slug":"Operations","permalink":"https://www.nakjunizm.com/categories/Operations/"},{"name":"ElasticSearch","slug":"Operations/ElasticSearch","permalink":"https://www.nakjunizm.com/categories/Operations/ElasticSearch/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://www.nakjunizm.com/tags/elasticsearch/"},{"name":"pending tasks","slug":"pending-tasks","permalink":"https://www.nakjunizm.com/tags/pending-tasks/"},{"name":"hot thread","slug":"hot-thread","permalink":"https://www.nakjunizm.com/tags/hot-thread/"}]},{"title":"자바의 String Pool","slug":"String_Pool","date":"2017-07-25T13:07:00.000Z","updated":"2021-10-06T15:33:17.481Z","comments":true,"path":"2017/07/25/String_Pool/","link":"","permalink":"https://www.nakjunizm.com/2017/07/25/String_Pool/","excerpt":"","text":"# String pool 의 개념String은 자바 개발자라면 굉장히 자주 쓰게 되는 자료형 일 것 입니다.오늘 책을 보다가 String pool 이라는 단어를 접했는데 여태까지 자바가 내부 적으로 String을 이렇게 처리하고 있는지 몰랐다는게 부끄러워 져서 정리 하는 포스트 입니다. 이미 모두가 잘 알고 있듯이 자바에서 String 객체의 값은 변경할 수 없습니다. 12String a = &quot;hello, world&quot;;a += &quot;bye&quot;; 위와같이 a를 수정하는 코드를 작성하면 실제로는 기존 “hello, world”를 가지고 있던 a는 버리고 새롭게 “hello, world bye”를 가지고 있는 a를 만든다는 것 이지요. 이 내용은 이미 알고 있거나 비슷한 이야기를 어디선가 들어 보셨을 겁니다. 여기서 재밌는 사실이 하나 등장합니다.String a = &quot;hello, world&quot; 라고 선언된 부분 중에 실제 내용 부분 (aka. literal)인 hello, world 는 컴파일 후에 String pool 에 들어 갑니다. 1234567@Testpublic void stringChanges()&#123;String a = &quot;Hello, world&quot;;String b = &quot;Hello, world&quot;;assertTrue( a == b );&#125; String 객체 간의 == 연산은 값을 비교하는게 아니고 같은 메모리를 참조하고 있느냐를 비교하는것 입니다. 처음에 String a = &quot;Hello, world&quot;; 라고 선언 했을 때 Hello, world 를 String pool에 넣고 두번째로 String b = &quot;Hello, world&quot;로 또 만들려고 보니 Hello, world 라는 literal은 이미 String pool에 존재하기 때문에 다시 Hello, world 만들어서 스트링풀에 넣지 않고, 기존에 만들어놓은 스트링풀에서 꺼내서 할당 해 줬다는 이야기 입니다. 이게 가능한것은 맨 처음에 말했듯이 스트링 객체의 값은 변경 할 수 없기 때문에 가능 합니다.만약 맨처음 설명했듯이 값의 변경이 있을때 새로운 객체에 할당하지 않고 실제로 값을 바꿔버리게 되면 a만 바꿨을 뿐인데 b도 영향을 받을수 있겠죠? String b = &quot;Hello, world&quot; 에서 새로 객체를 할당하지 않고 String pool 을 뒤져서 equal 연산 후 있으면 그대로 리턴해 주는 부분은 컴퓨터 공학에서 String interning 이라고 합니다. 지금 이 포스팅에서 이야기 하고 있는 String pool 은 JVM이 string interning을 구현한 것이라고 볼 수 있습니다.더 자세히 알고 싶으신 분은 String interning 위키피디아 를 참조하세요. # Java에서의 String pool컴파일이 완료된 클래스 파일들과 스태틱 변수들 등등은 JAVA에서(~java7) Permanent 영역에 저장된다는 사실은 모두 알고 있는 사실인데 string pool에 대해서 알아보다 보니 몇몇 책이나 블로그 등에서 잘못된 정보를 제공하는 경우가 있었습니다. “String pool이 PermGen 영역에 저장된다” 라고 알려주는 책과 블로그등이 있는데 이는 ** 일부만 맞고 일부는 잘못된 정보입니다.** 일부만 맞다고 하는 이유는 대부분의 잘못된 정보를 알려주는 자료들은 ** 작성된지 오래된 자료 ** 이거나 ** 오래된 자료를 참고한 글 ** 이고 그때 당시에 java6 혹은 그 이하 버전이 범용적으로 사용되던 시절이라면 맞는 정보입니다. 하지만 요즘은 대부분 java7 이상을 사용하기 때문에 사실 현재 시점에서는 저 정보는 틀렸다고 볼 수 있습니다. ** java7 이상에서는 String pool을 PermGen 영역에 저장하지 않고 heap 영역에 저장 ** 합니다.그 이유는 .. 너무 어려워서 제가 완벽히 이해를 못했기 때문에 파고들면 이번 포스트가 산으로 갈것 같아서 요약해서 설명해 드리면 다음과 같습니다. java 6 이하에서는 PermGen 영역에 String Pool을 저장해 놓았었는데 PermGen영역은 ** Runtime에 확장될 수 없는 고정된 capacity ** 를 가지고 있기 때문에 intern되는 String 값이 너무 많아 지면 OutOfMemoryException을 맞게 될 확률이 높았습니다. 때문에 java7부터 heap에 저장 하게 변경 되었다고 합니다. # Intern()String class는 public method인 intern()을 가지고 있습니다. intern() Returns a canonical representation for the string object. canonical representation은 대표값정도의 의미로 해석하시면 됩니다. 즉, intern()을 호출하면 string object의 대표값이 리턴 된다는 말 입니다. intern()을 호출 하면 해당 literal이 pool에 있는지 확인하고 있으면 pool에 있는 literal을 return 합니다. pool에 없으면 해당 literal을 pool에 집어 넣습니다. 위에서 주저리 주저리 설명은 했는데 도대체 이게 왜 필요한 것 입니까?intern() 이 가지고 있는 특성. 즉 값이 string pool에 있으면 그냥 가져오고, 없으면 string pool에 등록시키는 특성을 잘 활용하면 반복적으로 스트링이 같은지 비교연산 할 때 중복값이 많은 스트링을 처리할때 실제 값을 체크하는 equals() 연산보다 ** 1. 적은 메모리 2. 빠른 속도 ** 로 이를 처리 할 수 있습니다. ** ※ Java는 모든 String 을 default로 intern 합니다.** 그럼 실제로 intern() method를 언제 사용할 수 있을지 생각 해 봅시다.맨처음 예로 들었던 코드를 다시 보겠습니다. 1234567@Testpublic void stringCompares()&#123; String a = &quot;Hello, world&quot;; String b = &quot;Hello, world&quot;; assertTrue( a == b );&#125; b는 intern 되었기 때문에 a와 같은 메모리 주소값을 가지고 있습니다.그럼 아래와 같은 경우는 어떨까요? 1234567@Testpublic void stringCompares2()&#123; String a = &quot;Hello, world&quot;; String b = new String(&quot;Hello, world&quot;); assertTrue( a == b );&#125; 위 테스트는 ** 실패 ** 합니다. 왜냐하면 b를 기존의 String pool을 살펴보는 대신에 new 를 통해 새로운 객체를 명시적으로 생성하도록 했기 때문에 String pool이 아닌 객체를 참조하기 때문이죠. 위 테스트를 성공하는 테스트로 만들려면 assertTrue( a.equals(b) ) 로 바꾸면 됩니다. equals 는 값을 비교하는 연산이기 때문입니다. 이제 세번째 테스트를 보면 intern()을 언제 사용하면 좋을지 감이 좀 잡힙니다. 12345678910@Testpublic void stringInternTest()&#123; String a = &quot;Hello, world&quot;; String b = new String(&quot;Hello, world&quot;); String c = b.intern(); assertTrue(a.equals(b)); assertTrue(b.equals(c)); assertTrue(a == c);&#125; String 객체 c를 만드는데 이 때 b를 intern() 합니다. intern()을 호출하면 string pool을 뒤져보고 값이 있으면 리턴, 없으면 등록 한다고 했었는데 위의 테스트 케이스는 성공하는 테스트 케이스 일까요? 네 성공 하는 케이스 입니다. 그런데 사실 real world 에서는 intern()을 직접 호출하는 경우를 만나기는 쉽지 않을것 같습니다.실제 사용할 일이 생긴다면 아마도 엄청나게 많은 양의 데이터를 파싱한다던지, 스트링 값이 많은 데이터를 저장하고 비교한다던지 하는 일이 필요한 프로그램 에서 사용할 수 있을것 같고 실제 코드는 아래와 같이스트링 필드를 가지고 있는 데이터셋이 있을때 그 객체의 스트링필드를 intern 하고 비교하는 식으로 사용할 수 있겠네요. 123456789@Testpublic void stringInternTest()&#123; SomeObject someObject = someDataset.get(); String a = &quot;Hello, world&quot;; String b = someObject.getSomeStringField().intern(); assertTrue(a == b);&#125; 최대한 옳은 정보를 드리기 위해 공부하면서 정리했는데 혹시라도 틀린 부분이 있으면 부담없이 commnet 남겨 주세요. # 참조한 글 https://dzone.com/articles/string-interning-what-why-and http://javarevisited.blogspot.kr/2015/12/when-to-use-intern-method-of-string-in-java.html","categories":[{"name":"Development","slug":"Development","permalink":"https://www.nakjunizm.com/categories/Development/"},{"name":"java","slug":"Development/java","permalink":"https://www.nakjunizm.com/categories/Development/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://www.nakjunizm.com/tags/java/"},{"name":"stringpool","slug":"stringpool","permalink":"https://www.nakjunizm.com/tags/stringpool/"},{"name":"스트링풀","slug":"스트링풀","permalink":"https://www.nakjunizm.com/tags/%EC%8A%A4%ED%8A%B8%EB%A7%81%ED%92%80/"}]},{"title":"변수에서의 final 키워드","slug":"Final_Keyword","date":"2017-07-03T14:23:00.000Z","updated":"2021-10-06T15:33:17.513Z","comments":true,"path":"2017/07/03/Final_Keyword/","link":"","permalink":"https://www.nakjunizm.com/2017/07/03/Final_Keyword/","excerpt":"","text":"** 이 포스트 에서는 final 키워드가 변수 혹은 객체 앞에 붙었을 때 어떻게 동작 하는지 알아보겠습니다 ** # Final keyword원시타입에 선언하는 final 키워드와 객체에 선언하는 final 키워드는 동일한 역할을 합니다.변수를 만들면서 할당한 초기값을 누군가가 다른 값으로 변경하지 못하도록 하는 역할 12345678@Testpublic void testFinalKeyword() &#123; final int a = 990; a++; //컴파일 에러 final List&lt;String&gt; list = new ArrayList&lt;&gt;(); list = new ArrayList&lt;&gt;(); //컴파일 에러&#125; 위의 코드에서와 같이 원시타입인 int형 변수를 정의할때 990이라는 초기값을 주고 그 아랫줄에서 a++ 를 시도하면 컴파일 에러가 발생 합니다. 이클립스에서는 &quot;The final local variable a cannot be assigned. It must be blank and not using a compound assignment&quot; 라고 X표가 쳐져 있네요. 참조타입인 List형 변수도 마찬가지로 list를 정의할때 new ArrayList()로 새로운 객체에 한번 할당 하고 다른 객체에 다시 할당할 수 없습니다. 하지만 객체자체를 바꾸는 것은 불가능 하지만 한번 생성된 객체의 내부값들은 변경할 수 있다는 점이 원시타입의 final과는 구분되는 점 입니다. 123456789@Testpublic void testFinalKeyword() &#123; final List&lt;String&gt; list = new ArrayList&lt;&gt;(); list.add(&quot;a&quot;); list.add(&quot;b&quot;); assertEquals(2, list.size()); list.clear(); assertEquals(0, list.size());&#125; 위의 코드를 보면 final로 생성한 list에 add()하고 clear() 하는등의 조작을 가해도 문제없이 동작 하는것을 알 수 있습니다. 일반적으로 final 변수는 프로그램 전체에 걸쳐 사용되는 경우가 많아서 앞에서 예로 들었던 경우처럼 사용되는 경우는 거의 없고 클래스에 static과 함께 선언하여 사용합니다. 원시타입 (Primitive Type) 포스트에 예로 많이 들었던 Integer.MAX_VALUE나 Integer.MIN_VALUE 등과 같이 클래스이름으로 직접 접근하는 객체들이 이에 해당하는 경우라고 할 수 있습니다. ** list로 예를 든 것 같이 immutable class가 아닌 객체 앞에 final을 붙이면 객체 자체를 다시 new() 로 새로 할당 할 순 없지만 내부값들은 변경 가능하다는 점은 잘 기억해서 실수 하는 일이 없어야 겠습니다. ** # Code Conventionstatic final 변수 에 대해서는 곁다리로 추가 설명해 드리고 넘어가야 할 점이 있는데요 꼭 지키지는 않아도 되지만 되도록 지키는게 더 좋은 코드 컨벤션에 대한 이야기 입니다. 클래스 안에 static final로 변수를 선언할 때에는 변수명을 모두 대문자로 합니다. static final 변수에서 두단어가 합쳐질때는 언더스코어(단어_단어)로 명명 합니다. 로컬변수는 첫글자가 소문자로 시작하는 camelCase 로 정의 합니다. static final 변수도 그대로 로컬변수처럼 선언하는 경우가 많이 있습니다.그렇게 선언 하는 것이 프로그램적으로 잘못된 것이 아니고 혼자 개발 하는것 이라면 상관 없겠지만 그래도 더불어 사는세상 법으로 제정되진 않았지만 지켜야할 덕목이 있는것처럼 코드 컨벤션은 지키려고 노력하는게 좋겠습니다. 특히 요즘은 깃헙 에 오픈소스로 공개하는 경우가 많은데 코드 컨벤션을 지켜서 올리면 같이 프로젝트에 참여하는 사람들이 보다 쉽게 코드를 이해하는데 도움이 될 것입니다. 123456789101112public class PrimitiveType &#123; public static final int LIMIT=10; public static final String MY_NAME=&quot;haha&quot;; public int absIntegerValue(int intValue) &#123; if (intValue == Integer.MIN_VALUE) &#123; throw new NumberFormatException(); &#125; return Math.abs(intValue); &#125;&#125; 위와같이 PrimitiveType 클래스내부에 static final로 변수를 설정하고 나면혹시라도 다른 클래스에서 저 클래스의 객체를 new PrimitiveType() 등으로 생성하게 되었을 경우 그 객체의 참조변수에서도 바로 접근이 가능 합니다. 하지만 코딩 규약에서는 그렇게 하는것을 권장하지 않습니다. 123456789101112@Testpublic void testJavaCodingConvention()&#123; int myLimit = 5; //좋지않은 방법 PrimitiveType pt = new PrimitiveType(); assertTrue(myLimit &lt; pt.LIMIT); //권장하는 방법 assertTrue(myLimit &lt; PrimitiveType.LIMIT);&#125; 코드 컨벤션에 관심 있으신 분들은 내용이 방대하긴 하지만 아래 링크들을 참조해 보시기 바랍니다. Google Java Style GuideCode Conventions for the Java Programming Language","categories":[{"name":"Development","slug":"Development","permalink":"https://www.nakjunizm.com/categories/Development/"},{"name":"java","slug":"Development/java","permalink":"https://www.nakjunizm.com/categories/Development/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://www.nakjunizm.com/tags/java/"},{"name":"final","slug":"final","permalink":"https://www.nakjunizm.com/tags/final/"},{"name":"coding convention","slug":"coding-convention","permalink":"https://www.nakjunizm.com/tags/coding-convention/"}]},{"title":"참조 타입 (Reference Type)","slug":"Reference_Type","date":"2017-06-26T11:16:00.000Z","updated":"2021-10-06T15:33:17.434Z","comments":true,"path":"2017/06/26/Reference_Type/","link":"","permalink":"https://www.nakjunizm.com/2017/06/26/Reference_Type/","excerpt":"","text":"JAVA의 자료형에는 흔히 기본형 또는 원시타입 이라고 부르는 Primitive type 과 참조형 또는 래퍼클래스 라고 부르는Reference Type 두 종류가 있습니다. 라고 원시타입 (Primitive Type) 에서 이야기 했었습니다.** 이 포스트 에서는 Reference type 에 대하서 알아보겠습니다. ** # 객체원시타입을 제외한 다른 모든 타입은 참조타입 입니다. 그리고 그들을 우리는 객체 라는 이름으로 부르기도 합니다. 원시타입과 객체의 가장 중요한 차이점은 객체는 null을 참조할 수 있다는 점 입니다. 12int primitiveInt = null; //컴파일 에러 발생Integer referenceInt = null; 위의 첫번째 예에서와 같이 원시타입의 int로 선언된 primitiveInt를 null로 초기화 시키는 코드를 작성하면 컴파일 에러가 발생 합니다. 두번째처럼 int의 Wrapper class인 Integer타입으로 선언된 referenceInt는 null 로 초기화가 가능 합니다. 원시타입은 int a = 100; 이라고 선언되면 100이라는 값이 메모리에 할당 됩니다. 원시타입 (Primitive Type) 에서 열심히 설명 했듯이 a는 `int`이기때문에 32 bits의 크기를 메모리에 고정 크기로 갖고 그 메모리 주소에 100이라는 값이 할당 된다는 말 입니다. 그럼 이 때 int b = a; 와같이 b에 a를 할당한 이후 a의 값을 변경하게 되면 어떤일이 일어날까요?물론 100이 b에 할당 될것인데 이쯤되면 저를 포함해서 그냥 대충 되는대로 변수 선언하고 고민없이 사용하셨던 개발자 분들은 학교에서 배웠던것 같은 Call by reference, Call by value 이런것들이 머릿속을 돌아다니면서 헷갈리기 시작합니다. 오늘 다시 개념을 잡고 가는게 좋을것 같습니다. 1234567@Testpublic void testEntity() &#123; int a = 100; int b = a; a++; assertEquals(a, b);&#125; 위 테스트의 결과는 fail 입니다. a는 101, b는 100으로 다르기 때문 입니다. int b =a; 는 결국 학교에서 배웠던 call by value 의 개념이라고 봐도 무방하겠네요. 1234567@Testpublic void testEntity2() &#123; Integer a = new Integer(100); Integer b = a; a++; assertEquals(a, b);&#125; 위 테스트 역시 fail 입니다. 그 이유는 Integer class는 immutable(값이 변하지 않는)로 만들어져 있습니다. Long, Double, Float 등 숫자를 wrapping 한 클래스들은 모두 immutable 입니다. 그럼 imutable 이 아닌 List 로 다시 테스트 해보겠습니다. 123456789101112@Testpublic void testEntity2() &#123; List&lt;String&gt; list1 = new ArrayList&lt;&gt;(20); list1.add(&quot;a&quot;); assertTrue(list1.size() == 1); List&lt;String&gt; list2 = list1; list2.add(&quot;b&quot;); assertTrue(list1.size() == 2); assertTrue(list1.contains(&quot;b&quot;));&#125; list1 을 만들고 “a”를넣었습니다.list2 를 만들어서 새로운 객체를 생성 하지 않고 list1을 참조하게 만들었고, list2에다가 “b”를 넣었습니다. list2 에다가 “b”를 넣었음에도 불구하고 list1 의 길이도 2로 바뀌었고 “b”를 포함하고 있습니다. 개발 하면서 가끔 하는 실수중에 하나가값을 복사해서 새로운 리스트를 만들고, 그 값을 변경하려는 의도로 위처럼 그냥 할당해 버린 후 변경하는 코드를 작성하는 경우가 있습니다. 이런 경우 의도치 않게 원래 객체의 값도 변경되어 버리니 주의해야 합니다. 1234567891011121314@Testpublic void testEntity2() &#123; List&lt;String&gt; list1 = new ArrayList&lt;&gt;(); list1.add(&quot;a&quot;); assertTrue(list1.size() == 1); List&lt;String&gt; list2 = new ArrayList&lt;&gt;(); list2.addAll(list1); list2.add(&quot;b&quot;); assertTrue(list1.size() == 2); assertTrue(list1.contains(&quot;b&quot;));&#125; 위의 예에서 처럼 새로운 객체를 만들고 모든 객체를 다 추가 시켜주는 식으로 만들어야 원하는대로 한쪽의 수정이 다른 한쪽에 영향을 미치지 않게 됩니다. #JAVA는 항상 Call by value마지막의 list 예를 보고 call by reference 라고 착각 할 수 있는데 java는 무조건 값을 던져줍니다.Stack overflow 에 이 질문에 대한 훌륭한 답변들이 많이 달려있으니 한번 확인 해 보시면 많은 도움이 될 것 입니다.","categories":[{"name":"Development","slug":"Development","permalink":"https://www.nakjunizm.com/categories/Development/"},{"name":"java","slug":"Development/java","permalink":"https://www.nakjunizm.com/categories/Development/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://www.nakjunizm.com/tags/java/"},{"name":"reference type","slug":"reference-type","permalink":"https://www.nakjunizm.com/tags/reference-type/"}]},{"title":"원시타입 (Primitive Type)","slug":"Primitive_Type","date":"2017-06-25T06:26:00.000Z","updated":"2021-10-06T15:33:17.489Z","comments":true,"path":"2017/06/25/Primitive_Type/","link":"","permalink":"https://www.nakjunizm.com/2017/06/25/Primitive_Type/","excerpt":"","text":"JAVA의 자료형에는 흔히 기본형 또는 원시타입 이라고 부르는Primitive type 과 참조형 또는 래퍼클래스 라고 부르는 Reference Type 두 종류가 있습니다. 이 포스트에서는 Primitive Type에 대해서 알아보겠습니다. Primitive Type의 테이터는 변수에 할당 될 때 아래표에 나와있는것과 같이 고정된 크기로 저장되고, 해당 변수가 데이터 값을 보관합니다. # primitive type 타입 크기 범위 최소값 최대값 byte 8 bits -2^7 ~ 2^7-1 -128 127 boolean 1 bit true, false - - short 16 bits -2^15 ~ 2^15-1 -32,768 +32,767 int 32 bits -2^31 ~ 2^31-1 -2,147,483,648 +2,147,483,647 long 64 bits -2^63 ~ 2^63-1 -9,223,372,036,854,775,808 +9,223,372,036,854,775,807 to float 32 bits 2^-149 ~ (2-2^-23)*2^127 1.4 E-45 3.402,823,5 E+38 double 64 bits 2^-1074 ~ (2-2^-52)*2^1023 4.9 E-324 1.797,693,134,862,315,7 E+308 char 16 bits 0 ~ 2^16-1 (모든 Unicode 캐릭터) 0 65,535 자바에서는 위에 나와있는 8가지 + void 를 포함하여 총 9가지를 primitive type으로 정의 합니다. char 타입을 제외하고는 컴파일러에서 해당 값을 상위타입으로 자동으로 변환 (Auto casting) 할 수 있습니다. 예를 들어 위의 표에 나와있는 int 형 변수를 하나 만들고 가질수 있는 최대값인 2,147,483,647을 할당해 봅시다. 1int intValue = 2147483647; //Integer.MAX_VALUE 와 동일 이후에 intValue 에다가 +1을 해버리면 어떻게 될까요? int형이 가질수 있는 최대범위를 넘어가기 때문에 에러가 날것 같은데 한번 테스트 해 보겠습니다. 123456@Testpublic void testAutoCast() &#123; int intValue = 2147483647; //Integer.MAX_VALUE; intValue++; assertEquals(2147483648, intValue); &#125; intValue++; 하는 순간에 오류가 날 것으로 예상했지만 오류는 나지 않았습니다. 에러가 나지 않았으니2147483647에 1을 더한 값인 2147483648과 intValue++ 한 값이 같을것이라고 assertion을 줘 봤는데요 다음과 같은 컴파일 에러가 납니다. “The literal 2147483648 of type int is out of range” 컴파일러는 2147483648이 int의 범위 밖이라는것을 알고 있는데 어째서 intValue++는 허용을 해 줬을까요? 어떤값이 나오는지 출력해서 확인 해 봤습니다. 12//assertEquals(2147483648, intValue);System.out.println(intValue++); 1-2147483648 음수값이 나온것으로 확인 됐습니다. 1씩 더 더하면 어떻게 되는지 확인해 보겠습니다. 1234intValue++;System.out.println(intValue++);intValue++;System.out.println(intValue++); 123-2147483648-2147483646-2147483644 이런 결과를 얻게 된 이유는 short, int, long 타입의 2진수 값 저장소는 메모리에서 2의 보수 값을 사용하는데서 비롯 됩니다. 학교에서 다 배워서 알고있는 10진수의 2진수 변환을 해보면 0은 00000000 1은 00000001 2는 00000010 … 이런식으로 변환되고 -1은 11111111 -2는 11111110 -128은 10000000 이런식으로 변환이 됩니다.그럼 우리가 궁금해 하는 Integer.MAX_VALUE 의 2진수 값은 무엇인지 확인해 보겠습니다. 12345@Testpublic void testAutoCast()&#123; int intValue = 2147483647; //Integer.MAX_VALUE; System.out.println(Integer.toBinaryString(intValue));&#125; 11111111111111111111111111111111 ※ 참고로 Integer.toBinaryString() 함수는 int형의 10진수 숫자를 2진수로 변환한 값을 스트링으로 리턴해 주는 함수 입니다. 그 결과가 양수인 경우 부호비트를 제외한 2^31 만큼만 보여주고 음수인경우 2^32 를 다 보여줍니다. 그래서 int형의 최대값은 1이 31개 있는것을 확인 할 수 있습니다.여기에 1씩 더한값을 또 이진수로 변환해보면 아래와같이 되겠죠 12341111111111111111111111111111111100000000000000000000000000000001000000000000000000000000000000110000000000000000000000000000010 2의 보수로 저장하고 있기 때문에 1씩 더해서 실제로 2^0 자리가 1로 바뀌었지만 0은 1로 1은 0으로 바꾼 이후 +1을 해서 원래값을 만들어야 하므로 +2씩 한것같은 효과를 봤던 것 입니다. 잠깐 딴길로 샜는데 다시 본론으로 돌아와서 AutoCasting에 대해 살펴보겠습니다. 123456@Testpublic void testAutoCast()&#123; int intValue = Integer.MAX_VALUE; //Integer.MAX_VALUE; long longValue = intValue+1; assertEquals(Integer.MAX_VALUE+1, longValue);&#125; int형인 intValue를 Integer 범위의 최대값으로 잡고, long형인 longValue에 intValue+1을 한 값을 저장 했습니다.int형을 그냥 +1 했을때는 음수값이 나오면서 위의 테스트가 실패했었는데 지금은 성공합니다.이와 같이 상위 개념의 타입으로는 값의 정확도를 보장하면서 자동으로 변환을 시켜 주는데 이를 AutoCasting 이라고 합니다. # 퀴즈int value의 절대값을 구하는 함수를 만드시오. 123456789101112public class PrimitiveType &#123; public int absIntegerValue(int intValue)&#123; return Math.abs(intValue); &#125; @Test public void testAbsIntegerValue() &#123; int a = 100000; int b = absIntegerValue(-a); assertEquals(a, b); &#125;&#125; Math.abs() 라는 훌륭한 함수가 있기 때문에 그냥 return 해주면 간단히 해결 됩니다.But!맨처음 표를 보실 때 int의 범위가 -2^31 ~ 2^31-1 였다는걸 기억하신다면 음수가 양수보다 표현할수 있는 숫자가 한개 더 많다는 사실을 눈치 채셨는지 모르겠습니다. 1234567@Testpublic void testAbsIntegerValue() &#123; int b = absIntegerValue(Integer.MIN_VALUE); System.out.println(b);&#125; 1-2147483648 int형으로 표현할 수 있는 최소값은 절대값을 씌웠는데도 그대로 음수 부호를 달고 있습니다?!! 2의 보수표현을 할때 0은 양수로 취급하기 때문에 음수를 표현할 수 있는 값이 양수 보다 한개 더 많은 것 입니다. 12345678910111213141516171819202122232425262728293031//1. 아예 long으로 변환해서 값을 리턴해 주는 경우public class PrimitiveType &#123; public long absIntegerValue(int intValue)&#123; return Math.abs((long)intValue); &#125; @Test public void testAbsIntegerValue() &#123; long b = absIntegerValue(Integer.MIN_VALUE); System.out.println(b); &#125;&#125;//2. MIN_VALUE가 들어오면 Exception을 던져주는 경우public class PrimitiveType &#123; public int absIntegerValue(int intValue)&#123; if (intValue==Integer.MIN_VALUE)&#123; throw new NumberFormatException(); &#125; return Math.abs(intValue); &#125; @Test public void testAbsIntegerValue() &#123; int b = absIntegerValue(Integer.MIN_VALUE); System.out.println(b); &#125;&#125; 위와같이 두가지 경우로 생각해 볼 수 있습니다. 아예 그냥 long으로 변환해서 던져주거나 (물론 이경우에는 호출하는쪽에서 long으로 받아야 하므로 사실상 int의 최소값 이하를 사용하는 경우가 종종 있는 경우에 해당될 것 입니다.) 혹시라도 int의 최소값이 들어오는 경우에는 아예 익셉션을 리턴해 버려서 문제가 있음을 인지시켜 줄 수도 있겠습니다. 익셉션이 안나오고 그냥 절대값을 마이너스로 던져버린 경우 실제 저 코드가 프로그램의 일부로 돌아간다고 했을 때 에러로그도 안찍히고 문제없이 돌아가는것 처럼 보이지만 틀린값이 나오는 끔찍한 프로그램이 될 수 있습니다.","categories":[{"name":"Development","slug":"Development","permalink":"https://www.nakjunizm.com/categories/Development/"},{"name":"java","slug":"Development/java","permalink":"https://www.nakjunizm.com/categories/Development/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://www.nakjunizm.com/tags/java/"},{"name":"primitive type","slug":"primitive-type","permalink":"https://www.nakjunizm.com/tags/primitive-type/"}]},{"title":"Map 과 Set","slug":"Map_And_Set","date":"2017-04-21T07:48:00.000Z","updated":"2021-10-06T15:33:17.441Z","comments":true,"path":"2017/04/21/Map_And_Set/","link":"","permalink":"https://www.nakjunizm.com/2017/04/21/Map_And_Set/","excerpt":"","text":"** 이 포스트 에서는 Map 과 Set 에 대해 알아보도록 하겠습니다 ** Map (Java Platform SE 8 )Set (Java Platform SE 8 ) # 핵심 Map은 Key, Value 쌍을 가지는 오브젝트 입니다. Key는 중복될 수 없습니다. Set은 수학 에서의 집합과 동일한 개념 입니다. 중복되지 않는 값을 갖는 오브젝트 입니다. Map과 Set 모두 순서를 보장하지 않습니다 123456789101112131415161718192021@Testpublic void mapKeyTest() &#123; final Map&lt;Integer, String&gt; player = new HashMap&lt;&gt;(); player.put(1, &quot;Djokovic&quot;); player.put(2, &quot;Murray&quot;); player.put(1, &quot;Murray&quot;); assertEquals(2, player.size()); assertEquals(&quot;Murray&quot;, player.get(1)); assertEquals(&quot;Murray&quot;, player.get(2));&#125;@Testpublic void setValueTest() &#123; final Set&lt;String&gt; player = new HashSet&lt;&gt;(); player.add(&quot;Djokovic&quot;); player.add(&quot;Nadal&quot;); player.add(&quot;Federer&quot;); player.add(&quot;Murray&quot;); player.add(&quot;Djokovic&quot;); assertEquals(4, player.size());&#125; key는 Integer, value는 String인 HashMap의 play라는 변수를 만들고1 에 조코비치, 2 에 머레이를 넣었습니다.다시 1에 머레이를 넣게되면 나중에 들어간 머레이가 조코비치를 덮어써버려서 결국 key 1, 2의 value는 모두 “Murray”가 된것을 확인할 수 있습니다. Set에는 값만 들어있기 때문에 4명의 플레이어의 이름을 넣고, 다섯번째에 “Djokovic”을 한번 더 넣었음에도 불구하고중복값은 허용되지 않기 때문에 player set의 size는 여전히 4인것을 알 수 있습니다. 위의 예에서 사용한 HashMap은 Java에서 Map Interface를 사용하는 가장 일반적인 방식 입니다. ArrayList 와 LinkedList +@ 에서도 잠깐 언급한 적이 있는데 멀티 쓰레드로 개발을 하는 경우는 항상 사용하고자 하는 클래스나 인터페이스가 **Thread safe** 한지 살펴 봐야 합니다. HashMap은 동기화 되어있지 않기 때문에 동시에 여러개의 쓰레드가 동시에 값을 수정할 경우 익셉션이 발생할 수 있으니 필요한 경우 Collections.synchronizedMap 함수를 사용하거나 ConcurrentHashMap을 사용하여 이 문제를 회피할 수 있습니다.(JDK1.5 부터 등장한 ConcurrentHashMap을 사용하는 편이 더 효율적 입니다.) # HashMap에서 Hash는 무슨 역할을 하는가네이버의 helloworld 블로그에 자세한 동작방식이 설명되어 있으니 궁금하신분들은 한번씩 읽어보시면 도움이 될것 같습니다. 요약해서 쉽게 설명을 해 보면 HashMap은 key-value 페어를 담을수 있는 buckets을 가지고 있습니다.put(key,value)메소드를 호출하면 각 key-value 페어가 어느 bucket에 들어갈지 결정할때 바로 hashCode()함수가 사용 됩니다. get(key)를 호출한 경우에도 어느 bucket에서 데이터를 가져올지 결정할때 hashCode()가 사용 됩니다.(내부적으로 이 hashcode의 리턴값으로 shift 연산을 통해 결정된다고 하네요) 어느 bucket인지 알았으면 실제 그버킷에 들어있는 모든 키의 hashcode 값끼리 equals()를 통해 원하는 put이나 get 의 결과를 얻을 수 있게 됩니다. # +@ HashMap VS HashTable Hashtable은 synchronized, HashMap 은 아님 Hashtable 은 null을 key나 value로 가질수 없음, Hashmap은 하나의 null key와 여러개의 null 값을 가질 수 있음 Hashmap을 사용하다가 순서가 중요해 진 경우 단순히 Hashmap의 선언부를 LinkedHashMap으로 변경해주면 나머지 코드는 건드릴 필요가 없으나 Hashtable로 하려면 골치가 아파짐.","categories":[{"name":"Development","slug":"Development","permalink":"https://www.nakjunizm.com/categories/Development/"},{"name":"java","slug":"Development/java","permalink":"https://www.nakjunizm.com/categories/Development/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://www.nakjunizm.com/tags/java/"},{"name":"Map","slug":"Map","permalink":"https://www.nakjunizm.com/tags/Map/"},{"name":"Set","slug":"Set","permalink":"https://www.nakjunizm.com/tags/Set/"}]},{"title":"Thread pool (tuning point!)","slug":"Thread_Pool","date":"2017-03-07T13:19:00.000Z","updated":"2021-10-06T15:33:17.470Z","comments":true,"path":"2017/03/07/Thread_Pool/","link":"","permalink":"https://www.nakjunizm.com/2017/03/07/Thread_Pool/","excerpt":"","text":"** 이 포스트에서 수정하는 설정값 들은 elastic에서는 공식적으로 수정하지 말도록 권장하고 있습니다. 꼭 필요한 경우에만 충분한 테스트를 거쳐서 적용하시기 바랍니다. ** ElasticSearch 에 대량의 데이터를 bulk insert 하는 과정에서 예상했던 값보다 indexing rate가 낮은 경우 데이터를 밀어넣는 클라이언트에 EsRejectedExecutionException 이 발생 하는 경우 여러가지 튜닝 포인트가 있겠지만 그중에서도 Thread pool 은 매우 중요한 값인것 같습니다.공식 홈페이지의 문서를 살펴보면 Thread Pool 노드 안에서 효과적으로 쓰레드 메모리를 소비하기 위해서 노드는 여러개의 쓰레드풀을 가지고 있다. 많은 쓰레드 풀들은 큐들을 가지고 있고 그 큐들로 인해 넘치는 요청들이 버려지는 대신 큐에 담겨질 수 있다. 라고 소개되고 있습니다.여러가지 중요한 Thread pool 들이 소개되어 있지만 개인적으로 특히 더 중요하다고 생각되는 Thread는 아래 세개 입니다. ** index ** : index/delete 연산 용. type은 fixed이고 size는 가용한 프로세서갯수와 동일 합니다. queue_size는 default 200** search ** : count/search/suggest 연산 용. type은 fixed 이고 size는 ((가용한 프로세서갯수 * 3) / 2) + 1 입니다. queue_size는 default 1000** bulk ** : bulk 연산 용. size는 가용한 프로세서갯수와 동일 합니다. queue_size는 default 50여기서 주의 깊게 봐야 할 설정이 바로 queue_size 입니다. 쓰레드풀 자체의 사이즈는 위에서 설명 한것과 같이 가용한 프로세서의 갯수에 의존성이 있기 때문에 튜닝하기 쉽지 않고, queue_size를 늘려줌으로써 EsRejectedExcutionException 이 나는것을 방지 할 수 있습니다. elasticsearch.yml에 다음과같이 설정해 놓고 사용할 수 있습니다만 123threadpool.index.type: fixedthreadpool.index.size: 20threadpool.index.queue_size: 1000 운영중인 클러스터에 elasticsearch.yml을 변경하고 순차적으로 재시작 하는 작업은 부담이 가는것은 사실 입니다.** 좋은소식은 ThreadPool 설정은 dynamic setting 이므로 운영중인 클러스터를 재시작 할 필요 없이 api를 날려서 적용 시킬수 있습니다 ** 먼저 내 클러스터의 쓰레드풀 설정을 살펴봅시다. 12345#내 쓰레드풀에 대한 개요GET _nodes/thread_pool#현재 각 쓰레드풀의 상태GET _nodes/stats/thread_pool 위 명령어는 sense 기준이고 curl로 확인하는 경우 아래와 같이 날려보면 됩니다. 1curl -XGET &#x27;http://myclusterip:port/_nodes/thread_pool&#x27; 이제 다시 맨 처음의 주제로 돌아와서 내 생각보다 bulk insert 되는 속도가 느린것 같거나 자꾸 익셉션이 발생하는 경우bulk queue가 너무 적은것은 아닌가 의심해 볼 수 있습니다.쓰레드풀의 상태를 봤을 때 rejected된 건수가 많이 보이면 bulk queue를 늘려보는게 좋습니다.벌크 인서트할때도 그렇고, 검색할때도 자꾸 밀리는것 같은 느낌이 들어서 다음과 같이 설정을 변경해 봤습니다.(기존 설정은 default값인 bulk.queue_size는 50, search.queue_size는 1000 이었습니다.) 1234567PUT _cluster/settings&#123; &quot;transient&quot; : &#123; &quot;threadpool.bulk.queue_size&quot; : 500, &quot;threadpool.search.queue_size&quot; : 4000 &#125;&#125; 좀 더 지켜봐야겠지만 위와 같이 변경 하고 나서 클라이언트에서 EsRejectedExecutionException 도 더이상 보이지 않고 클러스터가 훨씬 안정적이게 됐습니다.","categories":[{"name":"Operations","slug":"Operations","permalink":"https://www.nakjunizm.com/categories/Operations/"},{"name":"ElasticSearch","slug":"Operations/ElasticSearch","permalink":"https://www.nakjunizm.com/categories/Operations/ElasticSearch/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://www.nakjunizm.com/tags/elasticsearch/"},{"name":"thread pool","slug":"thread-pool","permalink":"https://www.nakjunizm.com/tags/thread-pool/"},{"name":"tuning","slug":"tuning","permalink":"https://www.nakjunizm.com/tags/tuning/"}]},{"title":"Queue 와 Deque(Double ended queue)","slug":"Queue_And_Deque","date":"2017-02-24T11:53:00.000Z","updated":"2021-10-06T15:33:17.431Z","comments":true,"path":"2017/02/24/Queue_And_Deque/","link":"","permalink":"https://www.nakjunizm.com/2017/02/24/Queue_And_Deque/","excerpt":"","text":"** 이 포스트는 ArrayList 와 LinkedList +@의 연장선으로 Queue와 Deque에 대해서 간단하게 살펴보겠습니다. ** 먼저 공식 홈페이지의 설명을 훑어 보고 오겠습니다.Queue (Java Platform SE 8 )Deque (Java Platform SE 8 ) Queue 역시 Collection과 Iterable 인터페이스를 부모로 하고 있는것을 알 수 있고, Deque는 Queue의 sub interface 입니다. All Known Subinterfaces: BlockingDeque, BlockingQueue, Deque, TransferQueue 그리고 ArrayList 와 LinkedList +@에서 살펴봤던 LinkedList는 실제로 Queue를 implementing 했다는 것을 확인 할 수 있습니다. All Known Implementing Classes:AbstractQueue, ArrayBlockingQueue, ArrayDeque, ConcurrentLinkedDeque, ConcurrentLinkedQueue, DelayQueue, LinkedBlockingDeque, LinkedBlockingQueue, LinkedList, LinkedTransferQueue, PriorityBlockingQueue, PriorityQueue, SynchronousQueue 학교다닐때 들어봤음직한 stack, queue, deque를 그림으로 표현해봤습니다. Stack : 입구와 출구가 같습니다 = 먼저 들어온 데이터가 가장 나중에 나갈 수 있습니다 = LIFO (Last In First Out) Queue : 입구와 출구가 다릅니다 = 먼저 들어온 데이터가 가장 먼저 나갑니다 = FIFO (First In First Out) Deque : 입구와 출구가 같아도 되고 달라도 됩니다. #Queue12345678910111213141516171819@Testpublic void queue()&#123; Queue&lt;String&gt; queue = new LinkedList&lt;&gt;(); queue.add(&quot;first&quot;); queue.add(&quot;second&quot;); queue.add(&quot;third&quot;); assertEquals(&quot;first&quot;, queue.remove()); assertEquals(&quot;second&quot;, queue.poll()); assertEquals(&quot;third&quot;, queue.peek()); assertEquals(&quot;third&quot;, queue.poll()); try &#123; queue.remove(); &#125; catch (NoSuchElementException e) &#123; assertNotNull(e); &#125; assertNull(queue.poll());&#125; 먼저 Queue를 살펴 보면 add(), remove(), poll(), peek() 함수를 사용했는데 add는 말 그대로 queue에 값을 넣는것 입니다. remove, poll도 말 그대로 queue에서 값을 제거 하는것 입니다. (제거 하면서 그 값을 return 합니다.) 도 queue에서 값을 뽑아 내는것 입니다 peek 은 값은 return하지만 queue에서 제거하지 않습니다. remove와 poll 모두 값을 제거하면서 return 해 주는데 왜 같은일을 하는 함수를 나눠놨을까요? Retrieves and removes the head of this queue. This method differs from poll only in that it throws an exception if this queue is empty. 위는 remove의 javadoc에 적혀 있는 내용입니다.더이상 queue에서 꺼낼 것이 없는 상황에서 remove를 하게 되면 **NoSuchElementException**을 던집니다. 하지만 더이상 queue에서 꺼낼 것이 없을 때 poll을 하면 null을 return 합니다. 위의 Testcase에서 제가 모든 값을 다 뽑아낸 상태에서 한번도 remove를 하게 해 놓고 NoSuchElementException으로 catch 한 부분을 보시면 assertNotNull(e), 즉 저 테스트 케이스가 pass 하려면 e는 반드시 NoSuchElementException 이어야 합니다.반면에 poll로 뽑아낸 부분을 보시면 assertNull로 체크를 합니다. #Deque1234567891011121314151617181920212223242526272829303132333435363738@Testpublic void deque()&#123; Deque&lt;String&gt; deque = new LinkedList&lt;&gt;(); //queue와 동일하게 FIFO 구조로 사용 가능 deque.add(&quot;first&quot;); //== deque.addLast(); deque.add(&quot;second&quot;); deque.add(&quot;third&quot;); assertEquals(&quot;first&quot;, deque.remove()); //== deque.removeFirst(); assertEquals(&quot;second&quot;, deque.poll()); //== deque.pollFirst(); assertEquals(&quot;third&quot;, deque.peek()); assertEquals(&quot;third&quot;, deque.poll()); //stack 처럼 LIFO 구조로 사용 가능 deque.addLast(&quot;first&quot;); deque.addLast(&quot;second&quot;); deque.addLast(&quot;third&quot;); assertEquals(&quot;third&quot;, deque.removeLast()); assertEquals(&quot;second&quot;, deque.pollLast()); assertEquals(&quot;first&quot;, deque.peekLast()); assertEquals(&quot;first&quot;, deque.pollLast());&#125;@Testpublic void stack()&#123; Deque&lt;String&gt; stack = new ArrayDeque&lt;&gt;(); stack.push(&quot;first&quot;); stack.push(&quot;second&quot;); stack.push(&quot;third&quot;); assertEquals(&quot;third&quot;, stack.pop()); assertEquals(&quot;second&quot;, stack.pop()); assertEquals(&quot;first&quot;, stack.peek()); assertEquals(&quot;first&quot;, stack.pop());&#125; 위는 Deque 으로 구현한 queue와 stack 입니다.Deque는 Queue를 implementing 했기 때문에 queue에서 사용하던 add(), remove(), peek(), poll()을 그대로 사용할 수 있습니다. 그렇게 되면 queue의 특성인 FIFO 를 그대로 따라 갑니다. 하지만 deque은 입구와 출구가 달라도 되기 때문에 기존 함수에 접미사인 First와 Last를 붙인 addFirst(), peekLast()등과 같이 데이터를 넣고 뺄때 명시적으로 TOP에 넣을지 Bottom에 넣을지 정해 줄 수 있습니다. 즉, queue와 stack의 성질을 모두 가질 수 있습니다. 혹은 Stack의 함수인 push()와 pop()을 이용해서 전형적인 stack의 모습으로 구현 하는 것도 가능합니다.","categories":[{"name":"Development","slug":"Development","permalink":"https://www.nakjunizm.com/categories/Development/"},{"name":"java","slug":"Development/java","permalink":"https://www.nakjunizm.com/categories/Development/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://www.nakjunizm.com/tags/java/"},{"name":"Queue","slug":"Queue","permalink":"https://www.nakjunizm.com/tags/Queue/"},{"name":"Deque","slug":"Deque","permalink":"https://www.nakjunizm.com/tags/Deque/"}]},{"title":"ArrayList 와 LinkedList +@","slug":"ArrayList_And_LinkedList","date":"2017-02-19T09:19:00.000Z","updated":"2021-10-06T15:33:17.439Z","comments":true,"path":"2017/02/19/ArrayList_And_LinkedList/","link":"","permalink":"https://www.nakjunizm.com/2017/02/19/ArrayList_And_LinkedList/","excerpt":"","text":"이 포스트에서는 ArrayList와 LinkedList에 대해 알아 보겠습니다.List는 특정 타입 값들이 순차적으로 정렬된 컬렉션Collection 입니다.리스트는 크기 지정에 한계가 없으므로 아래 코드에서와 같이 리스트를 사용하기 전에 크기를 지정할 필요가 없습니다. 123456789@Testpublic void arrayAndList() &#123; // 배열의 명시적 크기 지정 int[] integers = new int[10]; // 배열의 암시적 크기 지정 String[] strings = new String[]&#123;&quot;one&quot;,&quot;two&quot;,&quot;three&quot;&#125;; // 리스트 선언 List&lt;String&gt; stringList = new ArrayList&lt;String&gt;();&#125; 공식 문서는 한번씩 훑어보는 습관을 들이는게 좋습니다.ArrayList (Java Platform SE 8 )LinkedList (Java Platform SE 8 ) 사실 ArrayList와 LinkedList 말고도 List 인터페이스를 implements 한 클래스들은 아래와 같이 더 있습니다 AbstractList, AbstractSequentialList, ArrayList, AttributeList, CopyOnWriteArrayList, LinkedList, RoleList, RoleUnresolvedList, Stack, Vector 하지만 이런것들은 잘 쓰이지 않으니 한번씩 눌러서 훑어 보고 지나가도 좋을것 같습니다.(RoleList, RoleUnresolvedList 는 저런게 있는지도 몰랐네요) 2018-01-11 추가 : CopyOnWriteArrayList의 경우 Concurrent programming에서 많이 쓰이니 나중에 다시 한번 다뤄보도록 하겠습니다. ArrayList와 Linked 리스트의 차이점과 특징ArrayList 는 이름 그대로 Array(배열) 의 특징을 가지고 있는 리스트 입니다. Pros: Random Access 가 가능하다는 점 Cons: ArrayList의 처음이나 중간에 값을 insert 하는 경우메모리 상에서는 insert한 이후의 모든 값들을 뒤로 한칸씩 이동하는 작업이 일어 납니다. 리스트의 크기가 매우 큰 경우 이 작업은 굉장히 비싼 작업이 될 수 있습니다. (내부적으로는 실제로 한칸씩 미루는 작업은 새로운 배열을 만드는 작업으로 이뤄집니다. ) LinkedList는 객체에 이전노드와 다음노드의 주소를 가지고 있는 공간을 추가로 할당해서 가지고 있습니다. Pros: 리스트의 크기가 클 경우 중간에 삽입이나 삭제를 하는 작업이 훨씬 빠르고 임시공간을 필요로 하지 않습니다. Cons: 이전노드와 다음노드의 주소를 가지고 있는 공간 때문에 일반적으로 ArrayList보다 메모리를 더 많이 사용합니다. RandomAccess가 불가 합니다. Java는 기본적으로 Doubly linked 되어 있는 구조를 가져가기 때문에 이전과 다음값 모두의 주소를 가지고 있습니다. 5라는 값을 리스트에서 삭제한 경우 33 이 가지고 있던 다음값의 주소에 7을 넣고, 7이 가지고 있던 이전값의 주소에 33의 주소값을 넣게되면 5는 아무곳에서도 참조되지 않는 쓰레기 객체가 됩니다. 삽입이 일어나는 경우에도 마찬가지로 이전값, 다음값의 주소값만 변경 되기 때문에 ArrayList에서처럼 삽입된 값 이후의 모든 값이 한칸씩 밀릴 필요가 없습니다. 위의 그림과 설명만 봐서는 ArrayList가 LinkedList 보다 나은 점이 없는것 같아 보입니다. ArrayList 는 내부 인덱스를 가지고 있어 Random Access가 가능 하지만LinkedList는 내부 인덱스는 가지고 있지 않으므로 원하는 값을 찾으려면 앞에서 부터 순차적으로다음값의 주소를 찾아가야 합니다. 1234567891011121314151617181920@Testpublic void randomAccess() &#123; List&lt;String&gt; arrayList = new ArrayList&lt;&gt;(); arrayList.add(&quot;first&quot;); arrayList.add(&quot;second&quot;); arrayList.add(&quot;third&quot;); assertEquals(&quot;first&quot;, arrayList.get(0)); assertEquals(&quot;second&quot;, arrayList.get(1)); List&lt;String&gt; linkedList = new LinkedList&lt;&gt;(); linkedList.add(&quot;first&quot;); linkedList.add(&quot;second&quot;); linkedList.add(&quot;third&quot;); assertEquals(&quot;first&quot;, linkedList.get(0)); assertEquals(&quot;second&quot;, linkedList.get(1));&#125; 위 테스트 케이스의 결과를 보면 LinkedList도 RandomAccess가 가능한것 처럼 보입니다. (linkedList.get(0)등을 통해) 하지만 RandomAccess (Java Platform SE 8 ) 페이지를 통해 알 수 있듯이 하지만 위의 문서에 나와 있듯이 Interface RandomAccess All Known Implementing Classes: ArrayList, AttributeList, CopyOnWriteArrayList, RoleList, RoleUnresolvedList, Stack, Vector LinkedList는 RandomAccess를 implementing 하고 있지 않습니다.결국 get(index)를 호출 하더라도 내부적으로는 위에서 설명한 방식대로 순차적으로 탐색하여 그 결과를 가져 옵니다. +@ : VectorVector는 JDK1.0 때부터 존재했던 고전 List 입니다.Vector (Java Platform SE 8 )기본적으로 자바의 배열이 고정 길이를 사용하기 때문에 사이즈를 미리 예측 할 수 없는 자료를 담기 위해 만들어진 클래스 이라고 할 수 있습니다.이후 JDK1.2에서 ArrayList가 소개되면서 Vector는 사실상 사용되지 않는 클래스라고 봐도 무방합니다.Vector는 Serializable을 implementing 하고 있습니다. 그 말인 즉슨 내부적으로 동기화가 되어 있다는 말이고 동기화가 되어 있다는 말은 Thread safe 하다는 말이기도 하지만 동기화를 하고 있기 때문에 속도가 느립니다. 싱글 스레드를 사용하는 프로그램에서는 쓰면 안되겠고, 병렬 프로그래밍을 하더라도 java.util.concurrent 패키지에 포함되어 있는 CopyOnWriteArrayList 등을 사용하는게 바람직 합니다.(이 부분은 나중에 기회가 되면 좀 더 자세히 다루도록 하겠습니다.)","categories":[{"name":"Development","slug":"Development","permalink":"https://www.nakjunizm.com/categories/Development/"},{"name":"java","slug":"Development/java","permalink":"https://www.nakjunizm.com/categories/Development/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://www.nakjunizm.com/tags/java/"},{"name":"Collections","slug":"Collections","permalink":"https://www.nakjunizm.com/tags/Collections/"},{"name":"ArrayList","slug":"ArrayList","permalink":"https://www.nakjunizm.com/tags/ArrayList/"},{"name":"LinkedList","slug":"LinkedList","permalink":"https://www.nakjunizm.com/tags/LinkedList/"}]},{"title":" Comparable과 Comparator","slug":"Comparable_And_Comparator","date":"2017-02-11T09:06:00.000Z","updated":"2021-10-06T15:33:17.495Z","comments":true,"path":"2017/02/11/Comparable_And_Comparator/","link":"","permalink":"https://www.nakjunizm.com/2017/02/11/Comparable_And_Comparator/","excerpt":"","text":"이 포스트 에서는 Comparable 과 Comparator 두 Interface의 차이점에 대해서 알아 보겠습니다. 두 Interface의 가장 큰 차이점은 Comparable 은 자연스러운 순서로 정렬할 때 사용하고, Comparator는 원하는 대로 정렬 순서를 정하고 싶을 때 사용한다는 점 입니다. 가장 정확한 정의를 찾기 위해서는 자바 공식 문서를 찾아보는 습관을 들이는게 좋습니다. Comparable (Java Platform SE 8 )Comparator (Java Platform SE 8 ) int type의 배열을 순서대로 정렬해 보겠습니다.아래 테스트 코드를 돌려보면 자연스러운 순서 (natural ordering) 이라는 말이 무슨 말인지 이해 됩니다. 12345678@Testpublic void sortInteger() &#123; int[] numbers = &#123; -8, -10, 11, 0, 1, 5, -5, 7&#125;; int[] expected = &#123; -10, -8, -5, 0, 1, 5, 7, 11&#125;; Arrays.sort(numbers); assertArrayEquals(expected, numbers);&#125; 여기 에 나와 있듯이 Lists (and arrays) of objects that implement this interface can be sorted automatically by Collections.sort (and Arrays.sort). Lists나 Arrays의 .sort 함수를 사용할 경우 Comparable을 implement한 정렬이 이뤄 집니다. int형 배열을 선언하고Arrays.sort로 정렬 해 보았습니다.작은수 -&gt; 큰수로 정렬이 될것이라 예상하고 expected 배열에 미리 순서대로 적어보고 assertArrayEquals로 검증해 보니Junit test case가 pass 되었습니다. ※이 블로그에 쓰여질 대부분의 소스코드는 Junit을 이용한 테스트 케이스로 진행 할 예정 입니다. 이번에는 Comparator 를 이용하여 역순으로 정렬해 보겠습니다. RevereSort 라는 이름의 Comparator interface를 implements 한 클래스 생성 및 compare method override. testcase를 pass 하는지 확인 12345678910111213import java.util.Comparator;public class ReverseSort implements Comparator&lt;Integer&gt;&#123; @Override public int compare(Integer o1, Integer o2) &#123; //기본적으로 첫번째 인자인 o1이 두번째 인자인 o2보다 크면 음수, //같으면 0, o2가 더 크면 양수를 리턴하는게 규칙 입니다. //저는 역순으로 정렬하고 싶기 때문에 o2 - o1을 리턴 하도록 하겠습니다. return o2 - o1; &#125;&#125; 123456789101112131415@Testpublic void reverseSortInteger() &#123; int[] numbers = &#123; -8, -10, 11, 0, 1, 5, -5, 7&#125;; int[] expected = &#123; 11, 7, 5, 1, 0, -5, -8, -10&#125;; //1.7 이하에서 테스트를 한다면 다음과 같이 numbers와 expected를 List로 만드는게 정신건강에 좋겠습니다. //List&lt;Integer&gt; numbers = Arrays.asList(-8, -10, 11, 0, 1, 5, -5, 7); //List&lt;Integer&gt; expected = Arrays.asList(11, 7, 5, 1, 0, -5, -8, -10); List&lt;Integer&gt; numberlist = Arrays.stream(numbers).boxed().collect(Collectors.toList()); List&lt;Integer&gt; expectedlist = Arrays.stream(expected).boxed().collect(Collectors.toList()); Collections.sort(numberlist, new ReverseSort()); assertEquals(numberlist, expectedlist);&#125; 저는 지금 Java8 환경에서 코딩을 하고 있기 때문에 ReversSort 클래스를 만들지 않고도사실 아래와 같이 간단하게 lamda를 이용할 수도 있습니다. lamda를 이용해 보기 전에 먼저 Java7에서도 위와같이 클래스를 따로 만들지 않고 inline으로 코드를 짜 보면 아래와 같습니다. 1234567891011121314@Testpublic void reverseSortInteger() &#123; List&lt;Integer&gt; numbers = Arrays.asList(-8, -10, 11, 0, 1, 5, -5, 7); List&lt;Integer&gt; expected = Arrays.asList(11, 7, 5, 1, 0, -5, -8, -10); Collections.sort(numberlist, new Comparator&lt;Integer&gt;() &#123; @Override public int compare(Integer arg0, Integer arg1) &#123; return arg1-arg0; &#125; &#125;); assertEquals(numberlist, expectedlist);&#125; 위코드를 lamda를 이용하면 아래와같이 간단하게 표현할 수 있습니다. 1234567891011@Testpublic void reverseSortIntegerWithLamda() &#123; List&lt;Integer&gt; numbers = Arrays.asList(-8, -10, 11, 0, 1, 5, -5, 7); List&lt;Integer&gt; expected = Arrays.asList(11, 7, 5, 1, 0, -5, -8, -10); numbers.sort((o1, o2)-&gt;o2-o1); assertEquals(numbers, expected);&#125; 너무 어렵고 다 귀찮다!!! 고 하면 다음과 같이 reverse 함수를 사용하거나 미리 정의된 Comparator를 사용하는 방법도 있습니다. 123456789101112131415@Testpublic void reverseSortIntegerWithCollections() &#123; List&lt;Integer&gt; numbers = Arrays.asList(-8, -10, 11, 0, 1, 5, -5, 7); List&lt;Integer&gt; expected = Arrays.asList(11, 7, 5, 1, 0, -5, -8, -10); Collections.sort(numbers); /*reverse 함수 사용*/ Collections.reverse(numbers); /*미리 정의된 comparator 사용*/ Collections.sort(numbers, Collections.reverseOrder()); assertEquals(numbers, expected);&#125; 지금까지는 Comparable과 Comparator의 기본적인 사용법을 알아 봤습니다. 실무에서는 위와 같이 사용하는 경우는 List 를 사용하는 경우를 제외하고는 거의 없을것 같습니다.보통의 경우 내가 만든 클래스에 compare를 하는 경우에 많이 쓰이게 될 텐데 아래 예제 코드를 작성 했습니다.","categories":[{"name":"Development","slug":"Development","permalink":"https://www.nakjunizm.com/categories/Development/"},{"name":"java","slug":"Development/java","permalink":"https://www.nakjunizm.com/categories/Development/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://www.nakjunizm.com/tags/java/"},{"name":"comparable","slug":"comparable","permalink":"https://www.nakjunizm.com/tags/comparable/"},{"name":"comparator","slug":"comparator","permalink":"https://www.nakjunizm.com/tags/comparator/"}]}],"categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://www.nakjunizm.com/categories/DevOps/"},{"name":"Kubernetes","slug":"DevOps/Kubernetes","permalink":"https://www.nakjunizm.com/categories/DevOps/Kubernetes/"},{"name":"Operations","slug":"Operations","permalink":"https://www.nakjunizm.com/categories/Operations/"},{"name":"Linux","slug":"Operations/Linux","permalink":"https://www.nakjunizm.com/categories/Operations/Linux/"},{"name":"Zookeeper","slug":"Operations/Zookeeper","permalink":"https://www.nakjunizm.com/categories/Operations/Zookeeper/"},{"name":"Redis","slug":"Operations/Redis","permalink":"https://www.nakjunizm.com/categories/Operations/Redis/"},{"name":"LoadBalancing","slug":"DevOps/LoadBalancing","permalink":"https://www.nakjunizm.com/categories/DevOps/LoadBalancing/"},{"name":"Cloud","slug":"Operations/Cloud","permalink":"https://www.nakjunizm.com/categories/Operations/Cloud/"},{"name":"Docker","slug":"DevOps/Docker","permalink":"https://www.nakjunizm.com/categories/DevOps/Docker/"},{"name":"Swarm","slug":"DevOps/Docker/Swarm","permalink":"https://www.nakjunizm.com/categories/DevOps/Docker/Swarm/"},{"name":"RabbitMQ","slug":"Operations/RabbitMQ","permalink":"https://www.nakjunizm.com/categories/Operations/RabbitMQ/"},{"name":"Development","slug":"Development","permalink":"https://www.nakjunizm.com/categories/Development/"},{"name":"GraphQL","slug":"Development/GraphQL","permalink":"https://www.nakjunizm.com/categories/Development/GraphQL/"},{"name":"node","slug":"Development/node","permalink":"https://www.nakjunizm.com/categories/Development/node/"},{"name":"Ansible","slug":"Operations/Ansible","permalink":"https://www.nakjunizm.com/categories/Operations/Ansible/"},{"name":"ElasticSearch","slug":"Operations/ElasticSearch","permalink":"https://www.nakjunizm.com/categories/Operations/ElasticSearch/"},{"name":"Kafka","slug":"Operations/Kafka","permalink":"https://www.nakjunizm.com/categories/Operations/Kafka/"},{"name":"Windows","slug":"Operations/Windows","permalink":"https://www.nakjunizm.com/categories/Operations/Windows/"},{"name":"java","slug":"Development/java","permalink":"https://www.nakjunizm.com/categories/Development/java/"}],"tags":[{"name":"minikube","slug":"minikube","permalink":"https://www.nakjunizm.com/tags/minikube/"},{"name":"loadbalancer","slug":"loadbalancer","permalink":"https://www.nakjunizm.com/tags/loadbalancer/"},{"name":"find","slug":"find","permalink":"https://www.nakjunizm.com/tags/find/"},{"name":"mtime","slug":"mtime","permalink":"https://www.nakjunizm.com/tags/mtime/"},{"name":"zookeeper","slug":"zookeeper","permalink":"https://www.nakjunizm.com/tags/zookeeper/"},{"name":"autopurge","slug":"autopurge","permalink":"https://www.nakjunizm.com/tags/autopurge/"},{"name":"snapRetain","slug":"snapRetain","permalink":"https://www.nakjunizm.com/tags/snapRetain/"},{"name":"redis","slug":"redis","permalink":"https://www.nakjunizm.com/tags/redis/"},{"name":"monitoring","slug":"monitoring","permalink":"https://www.nakjunizm.com/tags/monitoring/"},{"name":"zabbix","slug":"zabbix","permalink":"https://www.nakjunizm.com/tags/zabbix/"},{"name":"haproxy","slug":"haproxy","permalink":"https://www.nakjunizm.com/tags/haproxy/"},{"name":"keepalived","slug":"keepalived","permalink":"https://www.nakjunizm.com/tags/keepalived/"},{"name":"CIDR","slug":"CIDR","permalink":"https://www.nakjunizm.com/tags/CIDR/"},{"name":"Subnet","slug":"Subnet","permalink":"https://www.nakjunizm.com/tags/Subnet/"},{"name":"Swarm","slug":"Swarm","permalink":"https://www.nakjunizm.com/tags/Swarm/"},{"name":"Docker","slug":"Docker","permalink":"https://www.nakjunizm.com/tags/Docker/"},{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://www.nakjunizm.com/tags/rabbitmq/"},{"name":"ha","slug":"ha","permalink":"https://www.nakjunizm.com/tags/ha/"},{"name":"cluster","slug":"cluster","permalink":"https://www.nakjunizm.com/tags/cluster/"},{"name":"mirror","slug":"mirror","permalink":"https://www.nakjunizm.com/tags/mirror/"},{"name":"GraphQL","slug":"GraphQL","permalink":"https://www.nakjunizm.com/tags/GraphQL/"},{"name":"Schema","slug":"Schema","permalink":"https://www.nakjunizm.com/tags/Schema/"},{"name":"Apollo","slug":"Apollo","permalink":"https://www.nakjunizm.com/tags/Apollo/"},{"name":"node","slug":"node","permalink":"https://www.nakjunizm.com/tags/node/"},{"name":"passport","slug":"passport","permalink":"https://www.nakjunizm.com/tags/passport/"},{"name":"OAuth","slug":"OAuth","permalink":"https://www.nakjunizm.com/tags/OAuth/"},{"name":"ansible","slug":"ansible","permalink":"https://www.nakjunizm.com/tags/ansible/"},{"name":"devops","slug":"devops","permalink":"https://www.nakjunizm.com/tags/devops/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://www.nakjunizm.com/tags/elasticsearch/"},{"name":"versionup","slug":"versionup","permalink":"https://www.nakjunizm.com/tags/versionup/"},{"name":"ES Version up","slug":"ES-Version-up","permalink":"https://www.nakjunizm.com/tags/ES-Version-up/"},{"name":"6.4.0","slug":"6-4-0","permalink":"https://www.nakjunizm.com/tags/6-4-0/"},{"name":"ordinals","slug":"ordinals","permalink":"https://www.nakjunizm.com/tags/ordinals/"},{"name":"eager_global_ordinals","slug":"eager-global-ordinals","permalink":"https://www.nakjunizm.com/tags/eager-global-ordinals/"},{"name":"doc value","slug":"doc-value","permalink":"https://www.nakjunizm.com/tags/doc-value/"},{"name":"kibana","slug":"kibana","permalink":"https://www.nakjunizm.com/tags/kibana/"},{"name":"authentication","slug":"authentication","permalink":"https://www.nakjunizm.com/tags/authentication/"},{"name":"nginx","slug":"nginx","permalink":"https://www.nakjunizm.com/tags/nginx/"},{"name":"read-only","slug":"read-only","permalink":"https://www.nakjunizm.com/tags/read-only/"},{"name":"FORBIDDEN/12/index","slug":"FORBIDDEN-12-index","permalink":"https://www.nakjunizm.com/tags/FORBIDDEN-12-index/"},{"name":"allow_delete","slug":"allow-delete","permalink":"https://www.nakjunizm.com/tags/allow-delete/"},{"name":"watermark","slug":"watermark","permalink":"https://www.nakjunizm.com/tags/watermark/"},{"name":"disk_flood","slug":"disk-flood","permalink":"https://www.nakjunizm.com/tags/disk-flood/"},{"name":"kafka","slug":"kafka","permalink":"https://www.nakjunizm.com/tags/kafka/"},{"name":"offset","slug":"offset","permalink":"https://www.nakjunizm.com/tags/offset/"},{"name":"logstash","slug":"logstash","permalink":"https://www.nakjunizm.com/tags/logstash/"},{"name":"elk","slug":"elk","permalink":"https://www.nakjunizm.com/tags/elk/"},{"name":"visualization","slug":"visualization","permalink":"https://www.nakjunizm.com/tags/visualization/"},{"name":"ingest_node","slug":"ingest-node","permalink":"https://www.nakjunizm.com/tags/ingest-node/"},{"name":"license","slug":"license","permalink":"https://www.nakjunizm.com/tags/license/"},{"name":"windows2012","slug":"windows2012","permalink":"https://www.nakjunizm.com/tags/windows2012/"},{"name":"SENS","slug":"SENS","permalink":"https://www.nakjunizm.com/tags/SENS/"},{"name":"System Event Notification Service","slug":"System-Event-Notification-Service","permalink":"https://www.nakjunizm.com/tags/System-Event-Notification-Service/"},{"name":"java","slug":"java","permalink":"https://www.nakjunizm.com/tags/java/"},{"name":"pattern","slug":"pattern","permalink":"https://www.nakjunizm.com/tags/pattern/"},{"name":"singleton","slug":"singleton","permalink":"https://www.nakjunizm.com/tags/singleton/"},{"name":"apache","slug":"apache","permalink":"https://www.nakjunizm.com/tags/apache/"},{"name":"log","slug":"log","permalink":"https://www.nakjunizm.com/tags/log/"},{"name":"builder","slug":"builder","permalink":"https://www.nakjunizm.com/tags/builder/"},{"name":"thread","slug":"thread","permalink":"https://www.nakjunizm.com/tags/thread/"},{"name":"synchronized","slug":"synchronized","permalink":"https://www.nakjunizm.com/tags/synchronized/"},{"name":"volatile","slug":"volatile","permalink":"https://www.nakjunizm.com/tags/volatile/"},{"name":"serialization","slug":"serialization","permalink":"https://www.nakjunizm.com/tags/serialization/"},{"name":"transient","slug":"transient","permalink":"https://www.nakjunizm.com/tags/transient/"},{"name":"backup","slug":"backup","permalink":"https://www.nakjunizm.com/tags/backup/"},{"name":"restore","slug":"restore","permalink":"https://www.nakjunizm.com/tags/restore/"},{"name":"unassigned","slug":"unassigned","permalink":"https://www.nakjunizm.com/tags/unassigned/"},{"name":"reroute","slug":"reroute","permalink":"https://www.nakjunizm.com/tags/reroute/"},{"name":"heap","slug":"heap","permalink":"https://www.nakjunizm.com/tags/heap/"},{"name":"swapoff","slug":"swapoff","permalink":"https://www.nakjunizm.com/tags/swapoff/"},{"name":"compressedoops","slug":"compressedoops","permalink":"https://www.nakjunizm.com/tags/compressedoops/"},{"name":"shards","slug":"shards","permalink":"https://www.nakjunizm.com/tags/shards/"},{"name":"allocation","slug":"allocation","permalink":"https://www.nakjunizm.com/tags/allocation/"},{"name":"exception","slug":"exception","permalink":"https://www.nakjunizm.com/tags/exception/"},{"name":"try-with-resources","slug":"try-with-resources","permalink":"https://www.nakjunizm.com/tags/try-with-resources/"},{"name":"pending tasks","slug":"pending-tasks","permalink":"https://www.nakjunizm.com/tags/pending-tasks/"},{"name":"hot thread","slug":"hot-thread","permalink":"https://www.nakjunizm.com/tags/hot-thread/"},{"name":"stringpool","slug":"stringpool","permalink":"https://www.nakjunizm.com/tags/stringpool/"},{"name":"스트링풀","slug":"스트링풀","permalink":"https://www.nakjunizm.com/tags/%EC%8A%A4%ED%8A%B8%EB%A7%81%ED%92%80/"},{"name":"final","slug":"final","permalink":"https://www.nakjunizm.com/tags/final/"},{"name":"coding convention","slug":"coding-convention","permalink":"https://www.nakjunizm.com/tags/coding-convention/"},{"name":"reference type","slug":"reference-type","permalink":"https://www.nakjunizm.com/tags/reference-type/"},{"name":"primitive type","slug":"primitive-type","permalink":"https://www.nakjunizm.com/tags/primitive-type/"},{"name":"Map","slug":"Map","permalink":"https://www.nakjunizm.com/tags/Map/"},{"name":"Set","slug":"Set","permalink":"https://www.nakjunizm.com/tags/Set/"},{"name":"thread pool","slug":"thread-pool","permalink":"https://www.nakjunizm.com/tags/thread-pool/"},{"name":"tuning","slug":"tuning","permalink":"https://www.nakjunizm.com/tags/tuning/"},{"name":"Queue","slug":"Queue","permalink":"https://www.nakjunizm.com/tags/Queue/"},{"name":"Deque","slug":"Deque","permalink":"https://www.nakjunizm.com/tags/Deque/"},{"name":"Collections","slug":"Collections","permalink":"https://www.nakjunizm.com/tags/Collections/"},{"name":"ArrayList","slug":"ArrayList","permalink":"https://www.nakjunizm.com/tags/ArrayList/"},{"name":"LinkedList","slug":"LinkedList","permalink":"https://www.nakjunizm.com/tags/LinkedList/"},{"name":"comparable","slug":"comparable","permalink":"https://www.nakjunizm.com/tags/comparable/"},{"name":"comparator","slug":"comparator","permalink":"https://www.nakjunizm.com/tags/comparator/"}]}